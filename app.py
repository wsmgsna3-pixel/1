import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
import time
import gc
import os
from datetime import datetime, timedelta
# å¼•å…¥å¤šçº¿ç¨‹
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="V37.0 ä¿®æ­£åˆä½“ç‰ˆ", layout="wide")

# ==========================================
# 2. ç³»ç»ŸæŽ§åˆ¶å°
# ==========================================
st.sidebar.header("ðŸ› ï¸ ç³»ç»ŸæŽ§åˆ¶å°")
st.sidebar.success("âœ… V37.0 (å¤šçº¿ç¨‹çœŸç­¹ç ä¿®å¤ç‰ˆ)")

if st.sidebar.button("ðŸ”¥ å¼ºåˆ¶é‡å¯ (æ›´æ–°ä»£ç åŽå¿…ç‚¹)", type="primary"):
    st.cache_data.clear()
    st.cache_resource.clear()
    os._exit(0)

# ==========================================
# 3. æ•°æ®å¼•æ“Ž
# ==========================================

@st.cache_resource
def get_pro_api(token):
    if not token: return None
    ts.set_token(token)
    return ts.pro_api(timeout=60) 

# --- æ ¸å¿ƒä¿®å¤ï¼šæ™ºèƒ½æ—¥æœŸå›žæº¯ (ä»ŽV33ç§»æ¤å›žæ¥) ---
def get_latest_trade_date(_pro, curr_date_str):
    """
    è§£å†³ V35 å‚»å‚»åœ°æŸ¥å‘¨å…­å¯¼è‡´æŠ¥é”™çš„é—®é¢˜ã€‚
    """
    try:
        end_dt = pd.to_datetime(curr_date_str)
        start_dt = end_dt - timedelta(days=60)
        df = _pro.trade_cal(exchange='', start_date=start_dt.strftime('%Y%m%d'), 
                            end_date=curr_date_str, is_open='1')
        if df.empty: return curr_date_str
        # å¼ºåˆ¶å€’åºï¼Œå–æœ€è¿‘ä¸€å¤©
        df = df.sort_values('cal_date', ascending=False)
        return df['cal_date'].iloc[0]
    except:
        return curr_date_str

# --- å•æ—¥ä¸‹è½½ä»»åŠ¡ (ä¿ç•™çœŸç­¹ç æŽ¥å£) ---
def fetch_day_task(date, token):
    try:
        ts.set_token(token)
        local_pro = ts.pro_api()
        
        # 1. åŸºç¡€æ•°æ®
        d1 = local_pro.daily(trade_date=date)
        if d1.empty: return None # å¦‚æžœå½“å¤©çœŸçš„æ²¡æ•°æ®ï¼Œç›´æŽ¥è¿”å›ž
        
        d2 = local_pro.daily_basic(trade_date=date, fields='ts_code,turnover_rate,circ_mv,pe_ttm')
        
        # 2. çœŸç­¹ç æ•°æ® (cyq_perf)
        # æ—¢ç„¶æ‚¨æŽ¥å—å›žæµ‹è¾ƒæ…¢ï¼Œæˆ‘ä»¬å°±å¿…é¡»ç”¨è¿™ä¸ªæœ€å‡†çš„æ•°æ®
        d4 = local_pro.cyq_perf(trade_date=date)
        
        return {'date': date, 'daily': d1, 'basic': d2, 'cyq': d4}
    except:
        return None

# --- å¤šçº¿ç¨‹æ‰¹é‡ä¸‹è½½ (å¸¦è¿›åº¦æ¡) ---
@st.cache_data(ttl=3600)
def fetch_data_parallel(dates, token):
    results = {}
    progress_bar = st.progress(0, text="æ­£åœ¨å¯åŠ¨å¤šçº¿ç¨‹å¼•æ“Ž...")
    
    # æ—¢ç„¶æ‚¨è¯´ä¸ä¸€å®šæ˜¯å¤šçº¿ç¨‹çš„é—®é¢˜ï¼Œæˆ‘ä»¬ä¿å®ˆä¸€ç‚¹å¼€ 5 ä¸ªçº¿ç¨‹
    # æ—¢èƒ½åŠ é€Ÿï¼Œåˆæ¯” 10 ä¸ªçº¿ç¨‹ç¨³
    with ThreadPoolExecutor(max_workers=5) as executor:
        future_map = {executor.submit(fetch_day_task, d, token): d for d in dates}
        
        total = len(dates)
        done = 0
        
        for future in as_completed(future_map):
            done += 1
            data = future.result()
            if data:
                results[data['date']] = data
            
            # æ›´æ–°è¿›åº¦
            pct = done / total
            progress_bar.progress(pct, text=f"ðŸ“¥ å¤šçº¿ç¨‹ä¸‹è½½ä¸­: {done}/{total} å¤©")
            
    progress_bar.empty()
    return results

# è¾…åŠ©ï¼šèŽ·å–åç§°
@st.cache_data(ttl=86400)
def get_names(token):
    try:
        ts.set_token(token)
        return ts.pro_api().stock_basic(exchange='', list_status='L', fields='ts_code,name,industry')
    except: return pd.DataFrame()

# ==========================================
# 4. é€»è¾‘å±‚ (Rank 1 çœŸç­¹ç ç‰ˆ)
# ==========================================
def run_strategy_rank1(snapshot, names_df, p_min, p_max, to_max, top_n):
    if not snapshot: return None
    d1 = snapshot.get('daily')
    d2 = snapshot.get('basic')
    d4 = snapshot.get('cyq')
    
    # ä¸¥æ ¼æ£€æŸ¥ï¼Œå› ä¸ºæˆ‘ä»¬è¦ç”¨çœŸæ•°æ®
    if d1 is None or d1.empty: return None
    if d4 is None or d4.empty: return None
    if 'cost_50pct' not in d4.columns: return None
    
    try:
        # åˆå¹¶
        m1 = pd.merge(d1, d2, on='ts_code', how='inner')
        if names_df is not None:
            m1 = pd.merge(m1, names_df, on='ts_code', how='left')
            
        # å…³è”ç­¹ç 
        df = pd.merge(m1, d4[['ts_code', 'cost_50pct', 'winner_rate']], on='ts_code', how='inner')
        
        # è®¡ç®— Bias (çœŸ)
        df['bias'] = (df['close'] - df['cost_50pct']) / df['cost_50pct']
        
        condition = (
            (df['bias'] > -0.30) & (df['bias'] < 0.15) & 
            (df['winner_rate'] < 70) &
            (df['circ_mv'] > 300000) &  
            (df['close'] >= p_min) &       
            (df['close'] <= p_max) &       
            (df['turnover_rate'] < to_max) 
        )
        
        sorted_df = df[condition].sort_values('bias', ascending=True)
        return sorted_df.head(top_n)
    except:
        return None

# ==========================================
# 5. ä¾§è¾¹æ 
# ==========================================
st.sidebar.header("ðŸŽ›ï¸ å°Šäº«æŽ§åˆ¶å°")
token_input = st.sidebar.text_input("Tushare Token", type="password")
pro = get_pro_api(token_input)

st.sidebar.divider()
cfg_position_count = st.sidebar.slider("Top N", 1, 5, 3)
cfg_min_price = st.sidebar.number_input("æœ€ä½Žä»·", 8.1)
cfg_max_price = st.sidebar.number_input("æœ€é«˜ä»·", 20.0)
cfg_max_turnover = st.sidebar.slider("æ¢æ‰‹çŽ‡ä¸Šé™", 0.5, 5.0, 2.1)

st.sidebar.divider()
cfg_stop_loss = st.sidebar.number_input("æ­¢æŸ%", 8.5)
cfg_max_hold = st.sidebar.number_input("æŒè‚¡å¤©", 15)
cfg_trail_start = 0.08
cfg_trail_drop = 0.03
stop_loss_decimal = cfg_stop_loss / 100.0

today = datetime.now()
start_date = st.sidebar.text_input("å¼€å§‹æ—¥æœŸ", value=f"{today.year}0101")
end_date = st.sidebar.text_input("ç»“æŸæ—¥æœŸ", value=today.strftime('%Y%m%d'))

# ==========================================
# 6. ä¸»ç¨‹åº
# ==========================================
st.title("ðŸš€ V37.0 ä¿®æ­£åˆä½“ç‰ˆ (çœŸç­¹ç +æ™ºèƒ½æ—¥æœŸ)")

tab1, tab2 = st.tabs(["ðŸ“¡ æ™ºèƒ½å®žç›˜", "ðŸ§ª å¹¶å‘å›žæµ‹"])

# --- Tab 1: å®žç›˜ (ä¿®å¤äº†â€œä¸æ˜¯äº¤æ˜“æ—¥â€çš„æŠ¥é”™) ---
with tab1:
    col_d, col_b = st.columns([3, 1])
    with col_d:
        # ç”¨æˆ·ä¾ç„¶å¯ä»¥é€‰å‘¨å…­
        scan_date_input = st.date_input("é€‰æ‹©æ—¥æœŸ", value=pd.Timestamp.now())
    scan_date_str = scan_date_input.strftime('%Y%m%d')
    
    if col_b.button("å¼€å§‹æ‰«æ", type="primary"):
        if not pro: st.stop()
        
        with st.spinner("æ­£åœ¨æ ¡å¯¹æ—¥æœŸå¹¶èŽ·å–ç­¹ç æ•°æ®..."):
            # 1. æ™ºèƒ½ä¿®æ­£æ—¥æœŸ (V37 å…³é”®ä¿®å¤)
            real_date_str = get_latest_trade_date(pro, scan_date_str)
            
            if real_date_str != scan_date_str:
                st.info(f"ðŸ“… ä¿®æ­£ï¼šæ‚¨é€‰æ‹©çš„ **{scan_date_str}** éžäº¤æ˜“æ—¥ï¼Œå·²è‡ªåŠ¨åˆ‡æ¢è‡³ï¼š**{real_date_str}**")
            
            # 2. èŽ·å–æ•°æ® (å¤ç”¨ fetch_day_task)
            # è¿™é‡Œæˆ‘ä»¬ä¸ç”¨å¤šçº¿ç¨‹ï¼Œç›´æŽ¥å•æ¬¡è°ƒç”¨ï¼Œå› ä¸ºåªæŸ¥ä¸€å¤©
            data = fetch_day_task(real_date_str, token_input)
            names_df = get_names(token_input)
            
            if data:
                fleet = run_strategy_rank1(data, names_df, cfg_min_price, cfg_max_price, cfg_max_turnover, cfg_position_count)
                if fleet is not None and not fleet.empty:
                    st.success(f"âš“ æˆåŠŸé€‰å‡º {len(fleet)} åªæ ‡çš„ (åŸºäºŽ {real_date_str})")
                    st.dataframe(fleet[['ts_code', 'name', 'close', 'bias', 'turnover_rate', 'winner_rate', 'industry']].style.format({
                        'close': '{:.2f}', 'bias': '{:.4f}', 'turnover_rate': '{:.2f}', 'winner_rate': '{:.1f}'
                    }), hide_index=True)
                else:
                    st.warning(f"åœ¨ {real_date_str} æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ ‡çš„ã€‚")
            else:
                st.error(f"æ— æ³•èŽ·å– {real_date_str} çš„æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–Tokenã€‚")

# --- Tab 2: å›žæµ‹ (ä¿ç•™å¤šçº¿ç¨‹ï¼ŒæŽ¥å— 1 å°æ—¶è€—æ—¶) ---
with tab2:
    st.info("ðŸ’¡ ç³»ç»Ÿå°†å¯åŠ¨ 5 çº¿ç¨‹å¹¶å‘ä¸‹è½½çœŸå®žç­¹ç æ•°æ®ã€‚é¢„è®¡è€—æ—¶ä¼šæ¯”å•çº¿ç¨‹å¿«ï¼Œä½†ä»éœ€è€å¿ƒç­‰å¾…ã€‚")
    
    if st.button("ðŸš€ å¯åŠ¨å¹¶å‘å›žæµ‹", type="primary", use_container_width=True):
        if not token_input:
            st.error("Token æ— æ•ˆ")
            st.stop()
            
        # 1. èŽ·å–æ—¥æœŸ
        try:
            ts.set_token(token_input)
            pro = ts.pro_api()
            cal_df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date, is_open='1')
            dates = sorted(cal_df['cal_date'].tolist())
        except:
            st.error("ç½‘ç»œåˆå§‹åŒ–å¤±è´¥")
            st.stop()
            
        # 2. å¤šçº¿ç¨‹ä¸‹è½½
        memory_db = fetch_data_parallel(dates, token_input)
        names_df = get_names(token_input)
        
        if not memory_db:
            st.error("æ•°æ®ä¸‹è½½å¤±è´¥")
            st.stop()
            
        st.success(f"âœ… æ•°æ®ä¸‹è½½å®Œæˆï¼å†…å­˜å·²åŠ è½½ {len(memory_db)} å¤©çœŸç­¹ç æ•°æ®ã€‚å¼€å§‹å›žæµ‹...")
        
        # 3. å†…å­˜å›žæµ‹
        active_signals = [] 
        finished_signals = [] 
        progress_bar = st.progress(0)
        
        valid_dates = sorted(list(memory_db.keys()))
        
        for i, date in enumerate(valid_dates):
            if i % 5 == 0: progress_bar.progress((i + 1) / len(valid_dates))
            
            snap = memory_db.get(date)
            # ä»·æ ¼è¡¨
            price_map = {}
            if snap and not snap['daily'].empty:
                price_map = snap['daily'].set_index('ts_code')[['open','high','low','close']].to_dict('index')
            
            curr_dt = pd.to_datetime(date)
            next_active = []
            
            # æŒä»“
            for sig in active_signals:
                code = sig['code']
                if curr_dt <= pd.to_datetime(sig['buy_date']):
                    if code in price_map: sig['highest'] = max(sig['highest'], price_map[code]['high'])
                    next_active.append(sig)
                    continue

                if code in price_map:
                    p = price_map[code]
                    ph, pl, pc = p['high'], p['low'], p['close']
                    
                    if ph > sig['highest']: sig['highest'] = ph
                    cost = sig['buy_price']
                    peak = sig['highest']
                    
                    reason = ""
                    sell_p = pc
                    
                    if (pl - cost) / cost <= -stop_loss_decimal:
                        reason = "æ­¢æŸ"
                        sell_p = cost * (1 - stop_loss_decimal)
                    elif (peak - cost)/cost >= cfg_trail_start and (peak - pc)/peak >= cfg_trail_drop:
                        reason = "æ­¢ç›ˆ"
                        sell_p = peak * (1 - cfg_trail_drop)
                    elif (curr_dt - pd.to_datetime(sig['buy_date'])).days >= cfg_max_hold:
                        reason = "è¶…æ—¶"
                    
                    if reason:
                        ret = (sell_p - cost) / cost - 0.0006
                        finished_signals.append({'ret': ret, 'rank': sig.get('rank', 1)})
                    else:
                        next_active.append(sig)
                else:
                    next_active.append(sig)
            active_signals = next_active
            
            # é€‰è‚¡
            fleet = run_strategy_rank1(snap, names_df, cfg_min_price, cfg_max_price, cfg_max_turnover, cfg_position_count)
            if fleet is not None and not fleet.empty:
                for rank_idx, (_, row) in enumerate(fleet.iterrows()):
                    code = row['ts_code']
                    if code in price_map:
                        active_signals.append({
                            'code': code, 'buy_date': date, 
                            'buy_price': price_map[code]['open'], 'highest': price_map[code]['open'],
                            'rank': rank_idx + 1
                        })
        
        progress_bar.empty()
        
        if finished_signals:
            df_res = pd.DataFrame(finished_signals)
            df_res['ret_pct'] = df_res['ret'] * 100
            st.divider()
            c1, c2, c3 = st.columns(3)
            c1.metric("å•ç¬”æœŸæœ›", f"{df_res['ret'].mean()*100:.2f}%")
            c2.metric("èƒœçŽ‡", f"{(df_res['ret']>0).mean()*100:.1f}%")
            c3.metric("äº¤æ˜“æ¬¡æ•°", f"{len(df_res)}")
            
            st.subheader("ðŸ† åˆ†åæ¬¡è¡¨çŽ°")
            rank_stats = df_res.groupby('rank')['ret_pct'].agg(['count', 'mean', 'sum', lambda x: (x>0).mean()*100])
            st.table(rank_stats.style.format("{:.2f}"))
        else:
            st.warning("æ— äº¤æ˜“")
