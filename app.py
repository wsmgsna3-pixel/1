# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V15.3 æ•°æ®ä¿®å¤ç‰ˆï¼šä¿®å¤å¤æƒå› å­æ•°æ®è·å–é—®é¢˜
æ ¸å¿ƒä¿®å¤ï¼š
1. ã€**å¤æƒå› å­ä¿®å¤**ã€‘ï¼šä¿®æ­£adj_factoræ•°æ®è·å–é€»è¾‘ï¼Œç¡®ä¿è·å–å®Œæ•´æ•°æ®
   - ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®è·å–æ–¹å¼
   - ç¡®ä¿è¦†ç›–æ‰€æœ‰è‚¡ç¥¨å’Œæ—¥æœŸ
   
2. ã€**ç¨³å®šæ€§å¢å¼º**ã€‘ï¼šå¢åŠ æ•°æ®éªŒè¯å’Œå›é€€æœºåˆ¶
   - æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
   - æ·»åŠ æ•°æ®éªŒè¯æ­¥éª¤
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import time
warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€å˜é‡åˆå§‹åŒ–
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {}
GLOBAL_STOCK_BASIC = pd.DataFrame()

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V15.3 æ•°æ®ä¿®å¤ç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V15.3 æ•°æ®ä¿®å¤ç‰ˆ")

# ---------------------------
# è¾…åŠ©å‡½æ•°
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    """å®‰å…¨è°ƒç”¨ Tushare API"""
    global pro
    if pro is None:
        return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception as e:
        return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    """è·å– num_days ä¸ªäº¤æ˜“æ—¥ä½œä¸ºé€‰è‚¡æ—¥"""
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 3)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    
    if cal.empty or 'is_open' not in cal.columns:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†")
        return []
    
    trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)
    return trade_days_df['cal_date'].head(num_days).tolist()

# ----------------------------------------------------------------------
# â­ï¸ V15.3 ä¿®å¤ï¼šæ­£ç¡®è·å–å¤æƒå› å­æ•°æ®
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24, show_spinner=False)
def get_all_historical_data_fixed_v2(trade_days_list):
    """
    ä¿®å¤å¤æƒå› å­è·å–é—®é¢˜
    """
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS, GLOBAL_STOCK_BASIC
    
    if not trade_days_list: 
        return False
    
    latest_trade_date = max(trade_days_list) 
    earliest_trade_date = min(trade_days_list)
    
    # è®¡ç®—æ—¥æœŸèŒƒå›´
    start_date_dt = datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=90)
    end_date_dt = datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=10)
    
    start_date = start_date_dt.strftime("%Y%m%d")
    end_date = end_date_dt.strftime("%Y%m%d")
    
    st.info(f"æ­£åœ¨è·å– {start_date} åˆ° {end_date} çš„æ•°æ®...")
    
    # è¿›åº¦æ¡
    progress_bar = st.progress(0, text="åˆå§‹åŒ–...")
    
    # 1. è·å–è‚¡ç¥¨åˆ—è¡¨
    if GLOBAL_STOCK_BASIC.empty:
        progress_bar.progress(0.1, text="è·å–è‚¡ç¥¨åˆ—è¡¨...")
        stock_basic = safe_get('stock_basic', exchange='', list_status='L', 
                              fields='ts_code,name,list_date')
        if stock_basic.empty:
            st.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return False
        
        # è¿‡æ»¤åŒ—äº¤æ‰€å’ŒSTè‚¡
        stock_basic = stock_basic[~stock_basic['ts_code'].str.startswith(('92', '68'))]
        GLOBAL_STOCK_BASIC = stock_basic
    
    progress_bar.progress(0.2, text=f"å·²è·å– {len(GLOBAL_STOCK_BASIC)} åªè‚¡ç¥¨")
    
    # 2. è·å–äº¤æ˜“æ—¥å†
    progress_bar.progress(0.3, text="è·å–äº¤æ˜“æ—¥å†...")
    trade_cal = safe_get('trade_cal', start_date=start_date, end_date=end_date, is_open='1')
    if trade_cal.empty:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†")
        return False
    
    all_trade_dates = trade_cal['cal_date'].tolist()
    
    # 3. â­ï¸ å…³é”®ä¿®å¤ï¼šæ­£ç¡®è·å–å¤æƒå› å­æ•°æ®
    progress_bar.progress(0.4, text="è·å–å¤æƒå› å­æ•°æ®...")
    
    # æ–¹æ³•1ï¼šå…ˆå°è¯•æ‰¹é‡è·å–
    adj_factor_data = safe_get('adj_factor', start_date=start_date, end_date=end_date)
    
    if adj_factor_data.empty or len(adj_factor_data) < 1000:
        # æ–¹æ³•2ï¼šå¦‚æœæ•°æ®å¤ªå°‘ï¼Œå°è¯•åˆ†æ—¥æœŸè·å–
        st.warning("æ‰¹é‡è·å–å¤æƒå› å­æ•°æ®ä¸è¶³ï¼Œå°è¯•åˆ†æ—¥æœŸè·å–...")
        adj_factor_list = []
        
        # åªè·å–å®é™…éœ€è¦æ—¥æœŸçš„æ•°æ®ï¼ˆå‡å°‘æ•°æ®é‡ï¼‰
        needed_dates = all_trade_dates[:min(60, len(all_trade_dates))]  # æœ€å¤šè·å–60å¤©
        
        for i, date in enumerate(needed_dates):
            adj_df = safe_get('adj_factor', trade_date=date)
            if not adj_df.empty:
                adj_factor_list.append(adj_df)
            
            progress_bar.progress(0.4 + (i / len(needed_dates)) * 0.2, 
                                 text=f"è·å–å¤æƒå› å­: {i+1}/{len(needed_dates)}")
        
        if adj_factor_list:
            adj_factor_data = pd.concat(adj_factor_list, ignore_index=True)
        else:
            st.error("æ— æ³•è·å–å¤æƒå› å­æ•°æ®")
            return False
    
    # å¤„ç†å¤æƒå› å­æ•°æ®
    adj_factor_data['adj_factor'] = pd.to_numeric(adj_factor_data['adj_factor'], errors='coerce').fillna(1.0)
    GLOBAL_ADJ_FACTOR = adj_factor_data.set_index(['ts_code', 'trade_date']).sort_index()
    
    # 4. è·å–æ—¥çº¿æ•°æ®
    progress_bar.progress(0.7, text="è·å–æ—¥çº¿æ•°æ®...")
    
    # è·å–å®é™…éœ€è¦çš„æ—¥æœŸï¼ˆå›æµ‹æ—¥åŠå…¶å‰20ä¸ªäº¤æ˜“æ—¥ï¼‰
    needed_daily_dates = []
    for date in all_trade_dates:
        if date <= latest_trade_date:
            needed_daily_dates.append(date)
            if len(needed_daily_dates) >= 50:  # æœ€å¤šè·å–50å¤©
                break
    
    daily_data_list = []
    for i, date in enumerate(needed_daily_dates):
        daily_df = safe_get('daily', trade_date=date)
        if not daily_df.empty:
            daily_data_list.append(daily_df)
        
        progress_bar.progress(0.7 + (i / len(needed_daily_dates)) * 0.2, 
                             text=f"è·å–æ—¥çº¿æ•°æ®: {i+1}/{len(needed_daily_dates)}")
    
    if not daily_data_list:
        st.error("æ— æ³•è·å–æ—¥çº¿æ•°æ®")
        return False
    
    daily_raw_data = pd.concat(daily_data_list, ignore_index=True)
    
    # å¤„ç†æ—¥çº¿æ•°æ®
    progress_bar.progress(0.95, text="å¤„ç†æ•°æ®...")
    daily_raw_data['trade_date'] = pd.to_datetime(daily_raw_data['trade_date'], format='%Y%m%d')
    GLOBAL_DAILY_RAW = daily_raw_data.set_index(['ts_code', 'trade_date']).sort_index()
    
    # 5. éªŒè¯æ•°æ®å®Œæ•´æ€§
    # æ£€æŸ¥å¤æƒå› å­æ•°æ®é‡
    adj_count = len(GLOBAL_ADJ_FACTOR)
    daily_count = len(GLOBAL_DAILY_RAW)
    
    if adj_count < 10000:  # å¤æƒå› å­æ•°æ®å¤ªå°‘
        st.warning(f"âš ï¸ å¤æƒå› å­æ•°æ®è¾ƒå°‘ ({adj_count} æ¡)ï¼Œå¯èƒ½å½±å“è®¡ç®—")
        # å°è¯•å¦ä¸€ç§æ–¹å¼ï¼šä½¿ç”¨é€šç”¨å¤æƒå› å­ï¼ˆæ‰€æœ‰è‚¡ç¥¨ä½¿ç”¨ç›¸åŒçš„åŸºå‡†ï¼‰
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„å¤æƒå› å­è¡¨ï¼Œå‡è®¾æ‰€æœ‰è‚¡ç¥¨éƒ½æ²¡æœ‰é™¤æƒé™¤æ¯
        try:
            unique_stocks = GLOBAL_DAILY_RAW.index.get_level_values('ts_code').unique()
            unique_dates = GLOBAL_DAILY_RAW.index.get_level_values('trade_date').unique()
            
            adj_data = []
            for stock in unique_stocks:
                for date in unique_dates:
                    adj_data.append({'ts_code': stock, 'trade_date': date, 'adj_factor': 1.0})
            
            if adj_data:
                adj_df = pd.DataFrame(adj_data)
                adj_df['trade_date'] = pd.to_datetime(adj_df['trade_date'])
                GLOBAL_ADJ_FACTOR = adj_df.set_index(['ts_code', 'trade_date'])
                st.info("å·²ä½¿ç”¨é€šç”¨å¤æƒå› å­")
        except:
            pass
    
    # 6. è®¾ç½®QFQåŸºå‡†å› å­
    try:
        if not GLOBAL_ADJ_FACTOR.empty:
            # ä½¿ç”¨æœ€æ–°çš„å¤æƒå› å­ä½œä¸ºåŸºå‡†
            latest_dates = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').unique()
            if len(latest_dates) > 0:
                latest_date = sorted(latest_dates)[-1]
                latest_adj = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_date), 'adj_factor']
                if isinstance(latest_adj, pd.Series):
                    GLOBAL_QFQ_BASE_FACTORS = latest_adj.droplevel(1).to_dict()
                    st.success(f"âœ… è®¾ç½®åŸºå‡†å› å­ï¼Œè¦†ç›– {len(GLOBAL_QFQ_BASE_FACTORS)} åªè‚¡ç¥¨")
    except Exception as e:
        st.warning(f"è®¾ç½®åŸºå‡†å› å­æ—¶å‡ºé”™: {e}")
        GLOBAL_QFQ_BASE_FACTORS = {}
    
    progress_bar.progress(1.0, text="æ•°æ®åŠ è½½å®Œæˆï¼")
    time.sleep(1)
    progress_bar.empty()
    
    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
    st.success(f"""
    âœ… æ•°æ®åŠ è½½å®Œæˆï¼
    - æ—¥çº¿æ•°æ®: {len(GLOBAL_DAILY_RAW):,} æ¡è®°å½•
    - å¤æƒå› å­: {len(GLOBAL_ADJ_FACTOR):,} æ¡è®°å½•
    - åŸºå‡†å› å­: {len(GLOBAL_QFQ_BASE_FACTORS)} åªè‚¡ç¥¨
    """)
    
    # æ•°æ®è´¨é‡æ£€æŸ¥
    if len(GLOBAL_ADJ_FACTOR) < 10000:
        st.warning("âš ï¸ å¤æƒå› å­æ•°æ®å¯èƒ½ä¸è¶³ï¼Œå»ºè®®æ£€æŸ¥Tushareæƒé™æˆ–å°è¯•é‡æ–°è¿è¡Œ")
    
    return True

# ----------------------------------------------------------------------
# ç®€åŒ–çš„æ•°æ®è·å–å‡½æ•°
# ----------------------------------------------------------------------
def get_qfq_data_simple(ts_code, start_date, end_date):
    """ç®€åŒ–çš„å‰å¤æƒæ•°æ®è·å–"""
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
    
    if GLOBAL_DAILY_RAW.empty:
        return pd.DataFrame()
    
    try:
        # è½¬æ¢æ—¥æœŸ
        start_dt = datetime.strptime(start_date, "%Y%m%d")
        end_dt = datetime.strptime(end_date, "%Y%m%d")
        
        # è·å–æ—¥çº¿æ•°æ®
        if ts_code in GLOBAL_DAILY_RAW.index.get_level_values('ts_code'):
            daily_data = GLOBAL_DAILY_RAW.loc[ts_code].copy()
            mask = (daily_data.index >= start_dt) & (daily_data.index <= end_dt)
            daily_data = daily_data[mask]
        else:
            return pd.DataFrame()
        
        if daily_data.empty:
            return pd.DataFrame()
        
        # è·å–å¤æƒå› å­
        base_factor = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, 1.0)
        
        # å¦‚æœæœ‰å¤æƒå› å­æ•°æ®
        if ts_code in GLOBAL_ADJ_FACTOR.index.get_level_values('ts_code'):
            adj_data = GLOBAL_ADJ_FACTOR.loc[ts_code].copy()
            adj_data = adj_data[(adj_data.index >= start_dt) & (adj_data.index <= end_dt)]
            
            if not adj_data.empty:
                # åˆå¹¶æ•°æ®å¹¶è®¡ç®—å¤æƒä»·æ ¼
                df = daily_data.merge(adj_data, left_index=True, right_index=True, how='left')
                df['adj_factor'] = df['adj_factor'].fillna(base_factor)
                
                # è®¡ç®—å‰å¤æƒä»·æ ¼
                for col in ['open', 'high', 'low', 'close', 'pre_close']:
                    if col in df.columns:
                        df[col] = df[col] * df['adj_factor'] / base_factor
            else:
                df = daily_data.copy()
                # å¦‚æœæ²¡æœ‰å¤æƒå› å­ï¼Œä½¿ç”¨åŸºå‡†å› å­
                for col in ['open', 'high', 'low', 'close', 'pre_close']:
                    if col in df.columns:
                        df[col] = df[col] * 1.0 / base_factor
        else:
            df = daily_data.copy()
            # å¦‚æœæ²¡æœ‰å¤æƒå› å­ï¼Œä½¿ç”¨åŸºå‡†å› å­
            for col in ['open', 'high', 'low', 'close', 'pre_close']:
                if col in df.columns:
                    df[col] = df[col] * 1.0 / base_factor
        
        return df[['open', 'high', 'low', 'close', 'vol']].reset_index()
        
    except Exception:
        return pd.DataFrame()

# ----------------------------------------------------------------------
# æ ¸å¿ƒè®¡ç®—å‡½æ•°
# ----------------------------------------------------------------------
def compute_basic_indicators(ts_code, end_date):
    """åŸºç¡€æŒ‡æ ‡è®¡ç®—"""
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=40)).strftime("%Y%m%d")
    
    df = get_qfq_data_simple(ts_code, start_date, end_date)
    if df.empty or 'close' not in df.columns:
        return {}
    
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    df['high'] = pd.to_numeric(df['high'], errors='coerce')
    df['low'] = pd.to_numeric(df['low'], errors='coerce')
    
    close = df['close'].dropna()
    if len(close) < 10:
        return {}
    
    res = {'last_close': close.iloc[-1]}
    
    # 1. åŠ¨é‡å› å­ (10æ—¥æ¶¨å¹…)
    if len(close) >= 10:
        res['momentum_10d'] = (close.iloc[-1] / close.iloc[-10] - 1) * 100
    
    # 2. è¶‹åŠ¿å› å­ (ç®€å•å‡çº¿)
    if len(close) >= 5:
        ma5 = close.rolling(5).mean()
        ma10 = close.rolling(10).mean()
        
        trend_score = 0
        if len(ma5) > 0 and len(ma10) > 0 and ma5.iloc[-1] > ma10.iloc[-1]:
            trend_score += 1
        if len(close) > 0 and len(ma5) > 0 and close.iloc[-1] > ma5.iloc[-1]:
            trend_score += 1
        
        res['trend_score'] = (trend_score / 2) * 100
    
    # 3. ä½ç½®å› å­ (20æ—¥ä½ç½®)
    if len(df) >= 20:
        hist_20 = df.tail(20)
        min_low = hist_20['low'].min()
        max_high = hist_20['high'].max()
        current_close = hist_20['close'].iloc[-1]
        
        if max_high > min_low:
            res['position_20d'] = (current_close - min_low) / (max_high - min_low) * 100
        else:
            res['position_20d'] = 50
    
    # 4. æˆäº¤é‡æŒ‡æ ‡
    if 'vol' in df.columns:
        df['vol'] = pd.to_numeric(df['vol'], errors='coerce')
        if len(df) >= 5:
            vol_5ma = df['vol'].rolling(5).mean().iloc[-1] if len(df) >= 5 else 0
            vol_today = df['vol'].iloc[-1] if len(df) > 0 else 0
            if vol_5ma > 0:
                res['volume_ratio'] = vol_today / vol_5ma
    
    # è®¾ç½®é»˜è®¤å€¼
    res.setdefault('momentum_10d', 0)
    res.setdefault('trend_score', 50)
    res.setdefault('position_20d', 50)
    res.setdefault('volume_ratio', 1.0)
    
    return res

def get_future_returns_simple(ts_code, selection_date, selection_price):
    """ç®€åŒ–ç‰ˆæœªæ¥æ”¶ç›Šè®¡ç®—"""
    if pd.isna(selection_price) or selection_price <= 0:
        return {}
    
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    
    # åªè®¡ç®—D+1æ”¶ç›Šï¼ˆç®€åŒ–ï¼‰
    start_date = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_date = (d0 + timedelta(days=5)).strftime("%Y%m%d")
    
    df = get_qfq_data_simple(ts_code, start_date, end_date)
    if df.empty or 'close' not in df.columns:
        return {}
    
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    df = df.dropna(subset=['close'])
    
    results = {}
    
    # D+1
    if len(df) >= 1:
        results['Return_D1 (%)'] = (df.iloc[0]['close'] / selection_price - 1) * 100
    
    # D+3
    if len(df) >= 3:
        results['Return_D3 (%)'] = (df.iloc[2]['close'] / selection_price - 1) * 100
    
    # D+5  
    if len(df) >= 5:
        results['Return_D5 (%)'] = (df.iloc[4]['close'] / selection_price - 1) * 100
    
    return results

# ----------------------------------------------------
# ä¾§è¾¹æ å‚æ•°
# ----------------------------------------------------
with st.sidebar:
    st.header("å›æµ‹è®¾ç½®")
    backtest_date_end = st.date_input("ç»“æŸæ—¥æœŸ", value=datetime.now().date(), max_value=datetime.now().date())
    BACKTEST_DAYS = st.number_input("å›æµ‹å¤©æ•°", value=10, min_value=1, max_value=30)
    
    st.markdown("---")
    st.header("æ ¸å¿ƒå‚æ•°")
    FINAL_POOL = st.number_input("å…¥å›´æ•°é‡", value=30, min_value=10, max_value=100)
    TOP_BACKTEST = st.number_input("Top K", value=3, min_value=1, max_value=10)
    
    st.markdown("---")
    st.header("è¿‡æ»¤æ¡ä»¶")
    MIN_PRICE = st.number_input("æœ€ä½è‚¡ä»·", value=5.0, min_value=1.0)
    MAX_PRICE = st.number_input("æœ€é«˜è‚¡ä»·", value=100.0, min_value=10.0)
    MIN_TURNOVER = st.number_input("æœ€ä½æ¢æ‰‹ç‡%", value=1.0, min_value=0.1, step=0.5)
    MIN_CIRC_MV = st.number_input("æœ€ä½æµé€šå¸‚å€¼(äº¿)", value=20.0, min_value=5.0, step=5.0)

# ---------------------------
# Token è¾“å…¥
# ---------------------------
TS_TOKEN = st.text_input("Tushare Token", type="password", key="token_input")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥Tushare Token")
    st.stop()

ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# éªŒè¯Token
try:
    test = pro.trade_cal(exchange='', start_date='20240101', end_date='20240105', fields='exchange,cal_date,is_open,pretrade_date')
    if test.empty:
        st.error("Tokenæ— æ•ˆæˆ–æƒé™ä¸è¶³")
        st.stop()
    st.success("âœ… TokenéªŒè¯é€šè¿‡")
except Exception as e:
    st.error(f"TokenéªŒè¯å¤±è´¥: {e}")
    st.stop()

# ---------------------------
# ç®€åŒ–çš„å›æµ‹å‡½æ•°
# ---------------------------
def run_single_day_backtest(trade_date):
    """å•ä¸ªäº¤æ˜“æ—¥å›æµ‹"""
    # è·å–å½“æ—¥æ•°æ®
    daily_data = safe_get('daily', trade_date=trade_date)
    if daily_data.empty:
        return pd.DataFrame(), f"æ— æ—¥çº¿æ•°æ®: {trade_date}"
    
    # è·å–åŸºæœ¬é¢æ•°æ®
    daily_basic = safe_get('daily_basic', trade_date=trade_date, 
                          fields='ts_code,turnover_rate,circ_mv')
    
    # åˆå¹¶æ•°æ®
    df = daily_data.copy()
    if not daily_basic.empty:
        df = df.merge(daily_basic, on='ts_code', how='left')
    
    # æ•°æ®æ¸…æ´—
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    df['turnover_rate'] = pd.to_numeric(df.get('turnover_rate', 0), errors='coerce').fillna(0)
    df['circ_mv'] = pd.to_numeric(df.get('circ_mv', 0), errors='coerce').fillna(0) / 10000  # è½¬ä¸ºäº¿å…ƒ
    
    # è¿‡æ»¤
    df = df[
        (df['close'] >= MIN_PRICE) & 
        (df['close'] <= MAX_PRICE) &
        (df['turnover_rate'] >= MIN_TURNOVER) &
        (df['circ_mv'] >= MIN_CIRC_MV)
    ].copy()
    
    if df.empty:
        return pd.DataFrame(), f"è¿‡æ»¤åæ— è‚¡ç¥¨: {trade_date}"
    
    # è®¡ç®—æŒ‡æ ‡å’Œæœªæ¥æ”¶ç›Š
    records = []
    
    for idx, row in df.head(FINAL_POOL).iterrows():  # åªå¤„ç†å‰FINAL_POOLåªè‚¡ç¥¨
        ts_code = row['ts_code']
        
        # è®¡ç®—æŒ‡æ ‡
        indicators = compute_basic_indicators(ts_code, trade_date)
        if not indicators or 'last_close' not in indicators:
            continue
        
        selection_price = indicators['last_close']
        
        # è·å–æœªæ¥æ”¶ç›Š
        future_returns = get_future_returns_simple(ts_code, trade_date, selection_price)
        if not future_returns:
            continue
        
        record = {
            'ts_code': ts_code,
            'name': row.get('name', ts_code[:6]),
            'Close': row['close'],
            'Circ_MV (äº¿)': row['circ_mv'],
            'Pct_Chg (%)': row.get('pct_chg', 0),
            'turnover': row['turnover_rate'],
            'momentum': indicators.get('momentum_10d', 0),
            'trend_score': indicators.get('trend_score', 50),
            'position': indicators.get('position_20d', 50),
            'volume_ratio': indicators.get('volume_ratio', 1.0),
            **future_returns
        }
        
        records.append(record)
    
    if not records:
        return pd.DataFrame(), f"æ— æœ‰æ•ˆæŒ‡æ ‡: {trade_date}"
    
    result_df = pd.DataFrame(records)
    
    # è¯„åˆ†
    def safe_normalize(series):
        if len(series) < 2 or series.max() == series.min():
            return pd.Series([0.5] * len(series), index=series.index)
        return (series - series.min()) / (series.max() - series.min())
    
    # åŠ¨é‡å¾—åˆ†
    if 'momentum' in result_df.columns:
        result_df['s_momentum'] = safe_normalize(result_df['momentum'])
    else:
        result_df['s_momentum'] = 0.5
    
    # è¶‹åŠ¿å¾—åˆ†
    if 'trend_score' in result_df.columns:
        result_df['s_trend'] = safe_normalize(result_df['trend_score'])
    else:
        result_df['s_trend'] = 0.5
    
    # ä½ç½®å¾—åˆ†
    if 'position' in result_df.columns:
        position = result_df['position']
        # 30-70ä¸ºä½³
        position_score = np.where(
            (position >= 30) & (position <= 70),
            1.0,
            np.where(
                position < 30,
                position / 30,
                (100 - position) / 30
            )
        )
        result_df['s_position'] = position_score
    else:
        result_df['s_position'] = 0.5
    
    # ç»¼åˆè¯„åˆ†
    result_df['ç»¼åˆè¯„åˆ†'] = (
        result_df['s_momentum'] * 0.4 +
        result_df['s_trend'] * 0.3 +
        result_df['s_position'] * 0.3
    ) * 100
    
    result_df = result_df.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).head(TOP_BACKTEST)
    return result_df, None

# ---------------------------
# ä¸»è¿è¡Œå—
# ---------------------------
if st.button(f"ğŸš€ å¼€å§‹ {BACKTEST_DAYS} æ—¥å›æµ‹"):
    
    # è·å–äº¤æ˜“æ—¥
    trade_days = get_trade_days(backtest_date_end.strftime("%Y%m%d"), int(BACKTEST_DAYS))
    if not trade_days:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥")
        st.stop()
    
    st.info(f"è·å–åˆ° {len(trade_days)} ä¸ªäº¤æ˜“æ—¥")
    
    # åŠ è½½å†å²æ•°æ®
    st.info("æ­£åœ¨åŠ è½½å†å²æ•°æ®...")
    start_time = time.time()
    
    success = get_all_historical_data_fixed_v2(trade_days)
    if not success:
        st.error("æ•°æ®åŠ è½½å¤±è´¥")
        st.stop()
    
    load_time = time.time() - start_time
    st.success(f"æ•°æ®åŠ è½½å®Œæˆï¼è€—æ—¶: {load_time:.1f}ç§’")
    
    # å¼€å§‹å›æµ‹
    st.header(f"ğŸ“ˆ å›æµ‹ {len(trade_days)} ä¸ªäº¤æ˜“æ—¥")
    
    all_results = []
    valid_days = 0
    
    progress_bar = st.progress(0, text="å›æµ‹è¿›åº¦")
    status_text = st.empty()
    
    for i, trade_date in enumerate(trade_days):
        status_text.text(f"å¤„ç†: {trade_date} ({i+1}/{len(trade_days)})")
        
        result, error = run_single_day_backtest(trade_date)
        
        if error:
            st.warning(f"{trade_date}: {error}")
        elif not result.empty:
            result['Trade_Date'] = trade_date
            all_results.append(result)
            valid_days += 1
            st.info(f"âœ… {trade_date}: æ‰¾åˆ° {len(result)} åªæœ‰æ•ˆè‚¡ç¥¨")
        
        progress_bar.progress((i + 1) / len(trade_days))
    
    progress_bar.empty()
    status_text.text(f"å›æµ‹å®Œæˆï¼æœ‰æ•ˆäº¤æ˜“æ—¥: {valid_days}/{len(trade_days)}")
    
    if not all_results:
        st.error("æ‰€æœ‰äº¤æ˜“æ—¥å›æµ‹å‡å¤±è´¥")
        st.stop()
    
    # åˆå¹¶ç»“æœ
    final_results = pd.concat(all_results, ignore_index=True)
    
    # æ˜¾ç¤ºç»Ÿè®¡
    st.header("ğŸ“Š å›æµ‹ç»Ÿè®¡")
    
    # æ”¶ç›Šç»Ÿè®¡
    for n in [1, 3, 5]:
        col = f'Return_D{n} (%)'
        if col in final_results.columns:
            valid = final_results.dropna(subset=[col])
            if not valid.empty:
                avg_return = valid[col].mean()
                hit_rate = (valid[col] > 0).mean() * 100
                count = len(valid)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric(f"D+{n} å¹³å‡æ”¶ç›Š", f"{avg_return:.2f}%")
                with col2:
                    st.metric(f"D+{n} èƒœç‡", f"{hit_rate:.1f}%")
                with col3:
                    st.metric(f"D+{n} æ ·æœ¬æ•°", count)
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    st.header("ğŸ“‹ è¯¦ç»†ç»“æœ")
    
    display_cols = ['Trade_Date', 'ts_code', 'name', 'ç»¼åˆè¯„åˆ†', 'Close', 
                   'Pct_Chg (%)', 'Circ_MV (äº¿)', 'momentum', 'trend_score']
    
    # æ·»åŠ æ”¶ç›Šåˆ—
    for n in [1, 3, 5]:
        col = f'Return_D{n} (%)'
        if col in final_results.columns:
            display_cols.append(col)
    
    available_cols = [col for col in display_cols if col in final_results.columns]
    
    st.dataframe(
        final_results[available_cols].sort_values('Trade_Date', ascending=False),
        use_container_width=True,
        height=400
    )
    
    # ä¸‹è½½ç»“æœ
    csv = final_results.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½å›æµ‹ç»“æœ",
        data=csv,
        file_name=f"backtest_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )
