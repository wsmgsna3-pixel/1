import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
import altair as alt
import time
import gc
import os
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="V35.0 å°Šäº«æžé€Ÿç‰ˆ", layout="wide")

# ==========================================
# 2. ç³»ç»ŸæŽ§åˆ¶å°
# ==========================================
st.sidebar.header("ðŸ› ï¸ ç³»ç»ŸæŽ§åˆ¶å°")
st.sidebar.success("âœ… V35.0 (å¤šçº¿ç¨‹çœŸç­¹ç ç‰ˆ)")

if st.sidebar.button("ðŸ”¥ å¼ºåˆ¶é‡å¯ (æ›´æ–°ä»£ç åŽå¿…ç‚¹)", type="primary"):
    st.cache_data.clear()
    st.cache_resource.clear()
    os._exit(0)

# ==========================================
# 3. é«˜æ€§èƒ½æ•°æ®å¼•æ“Ž (å¤šçº¿ç¨‹å¹¶å‘)
# ==========================================

@st.cache_resource
def get_pro_api(token):
    if not token: return None
    ts.set_token(token)
    return ts.pro_api(timeout=60) # 60ç§’è¶…æ—¶å®¹é”™

def retry_api_call(func, *args, retries=3, **kwargs):
    for i in range(retries):
        try:
            return func(*args, **kwargs)
        except Exception:
            if i == retries - 1: return pd.DataFrame()
            time.sleep(1)
    return pd.DataFrame()

# --- å•æ—¥æ•°æ®ä¸‹è½½å‡½æ•° (ä¿ç•™çœŸç­¹ç ) ---
def fetch_single_day_data(date, token):
    """
    è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ä¸‹è½½ä»»åŠ¡ï¼Œå°†è¢«åˆ†é…ç»™ä¸åŒçš„çº¿ç¨‹ã€‚
    å¿…é¡»åœ¨è¿™é‡Œé‡æ–°åˆå§‹åŒ– proï¼Œå› ä¸ºçº¿ç¨‹é—´å…±äº«è¿žæŽ¥å¯èƒ½ä¼šæœ‰é—®é¢˜ã€‚
    """
    try:
        ts.set_token(token)
        local_pro = ts.pro_api()
        
        # 1. ä¸‹è½½åŸºç¡€æ•°æ®
        df_daily = retry_api_call(local_pro.daily, trade_date=date)
        if df_daily.empty: return None # å¦‚æžœæ²¡è¡Œæƒ…ï¼Œç›´æŽ¥è·³è¿‡
        
        df_basic = retry_api_call(local_pro.daily_basic, trade_date=date, fields='ts_code,turnover_rate,circ_mv,pe_ttm')
        
        # 2. ä¸‹è½½å°Šè´µçš„ç­¹ç æ•°æ® (cyq_perf)
        # æ‚¨èŠ±é’±ä¹°çš„æƒé™ï¼Œå¿…é¡»ç”¨ä¸Šï¼
        df_cyq = retry_api_call(local_pro.cyq_perf, trade_date=date)
        if df_cyq.empty:
            # ç®€å•å›žæº¯1-2å¤©ï¼Œé˜²æ­¢å½“å¤©æ•°æ®å¶å°”ç¼ºå¤±
             for i in range(1, 3):
                 prev = (pd.to_datetime(date) - pd.Timedelta(days=i)).strftime('%Y%m%d')
                 df_cyq = retry_api_call(local_pro.cyq_perf, trade_date=prev)
                 if not df_cyq.empty: break
        
        # æ‰“åŒ…è¿”å›ž
        return {
            'date': date,
            'daily': df_daily,
            'basic': df_basic,
            'cyq': df_cyq
        }
    except:
        return None

# --- å¤šçº¿ç¨‹æ‰¹é‡ä¸‹è½½æ ¸å¿ƒ ---
@st.cache_data(ttl=3600)
def fetch_data_concurrently(dates, token):
    """
    ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ä¸‹è½½ï¼Œé€Ÿåº¦æå‡ 5-10 å€ã€‚
    """
    results = {}
    
    # è¿›åº¦æ¡
    progress_bar = st.progress(0, text="æ­£åœ¨å¯åŠ¨å¤šçº¿ç¨‹æžé€Ÿä¸‹è½½å¼•æ“Ž...")
    status_text = st.empty()
    
    # é™åˆ¶å¹¶å‘æ•°ä¸º 4-8ï¼Œé˜²æ­¢ Tushare å° IP
    # Tushare é«˜çº§ç”¨æˆ·é€šå¸¸å…è®¸æ¯åˆ†é’Ÿå‡ ç™¾æ¬¡è¯·æ±‚ï¼Œ8çº¿ç¨‹æ˜¯å®‰å…¨çš„
    max_workers = 8 
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_date = {executor.submit(fetch_single_day_data, date, token): date for date in dates}
        
        completed_count = 0
        total_count = len(dates)
        
        for future in as_completed(future_to_date):
            date = future_to_date[future]
            try:
                data = future.result()
                if data:
                    results[data['date']] = data
            except Exception as e:
                print(f"Error fetching {date}: {e}")
            
            completed_count += 1
            # æ›´æ–°è¿›åº¦
            if completed_count % 5 == 0 or completed_count == total_count:
                pct = completed_count / total_count
                progress_bar.progress(pct, text=f"ðŸš€ å¤šçº¿ç¨‹æžé€Ÿä¸‹è½½ä¸­... å·²å®Œæˆ {completed_count}/{total_count} å¤©")
    
    progress_bar.empty()
    status_text.success(f"âœ… ä¸‹è½½å®Œæˆï¼æˆåŠŸèŽ·å– {len(results)} å¤©çš„å®Œæ•´ç­¹ç æ•°æ®ã€‚")
    return results

# è¾…åŠ©ï¼šèŽ·å–é™æ€è‚¡ç¥¨åç§° (ä¸€æ¬¡æ€§)
@st.cache_data(ttl=86400)
def get_stock_names(token):
    try:
        ts.set_token(token)
        pro = ts.pro_api()
        return pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,industry')
    except: return pd.DataFrame()

# è¾…åŠ©ï¼šèŽ·å–å¤§ç›˜
@st.cache_data(ttl=86400)
def get_market_sentiment(start, end, token):
    try:
        ts.set_token(token)
        pro = ts.pro_api()
        real_start = (pd.to_datetime(start) - pd.Timedelta(days=90)).strftime('%Y%m%d')
        df = pro.index_daily(ts_code='000001.SH', start_date=real_start, end_date=end)
        df = df.sort_values('trade_date', ascending=True)
        df['ma20'] = df['close'].rolling(20).mean()
        return df.set_index('trade_date')['close'].gt(df.set_index('trade_date')['ma20']).to_dict()
    except: return {}

# ==========================================
# 4. é€»è¾‘å±‚ (ä½¿ç”¨çœŸç­¹ç )
# ==========================================
def run_strategy_real_cyq(snapshot, names_df, p_min, p_max, to_max, top_n):
    if not snapshot: return None
    
    d1 = snapshot.get('daily')
    d2 = snapshot.get('basic')
    d4 = snapshot.get('cyq') # çœŸç­¹ç 
    
    # åšå¦‚ç£çŸ³çš„é˜²å´©æºƒæ£€æŸ¥
    if d1 is None or d1.empty: return None
    if d2 is None or d2.empty: return None
    if d4 is None or d4.empty: return None # å¿…é¡»æœ‰ç­¹ç 
    
    if 'ts_code' not in d1.columns or 'cost_50pct' not in d4.columns: return None

    # åˆå¹¶
    try:
        m1 = pd.merge(d1, d2, on='ts_code', how='inner')
        if names_df is not None and not names_df.empty:
            m1 = pd.merge(m1, names_df, on='ts_code', how='left')
        
        # å…³é”®ï¼šä½¿ç”¨çœŸç­¹ç æ•°æ®åˆå¹¶
        df = pd.merge(m1, d4[['ts_code', 'cost_50pct', 'winner_rate']], on='ts_code', how='inner')
        
        # è®¡ç®— Bias (çœŸç­¹ç ä¹–ç¦»)
        df['bias'] = (df['close'] - df['cost_50pct']) / df['cost_50pct']
        
        condition = (
            (df['bias'] > -0.03) & (df['bias'] < 0.15) & 
            (df['winner_rate'] < 70) &
            (df['circ_mv'] > 300000) &  
            (df['close'] >= p_min) &       
            (df['close'] <= p_max) &       
            (df['turnover_rate'] < to_max) 
        )
        
        sorted_df = df[condition].sort_values('bias', ascending=True)
        if sorted_df.empty: return None
        return sorted_df.head(top_n)
        
    except: return None

# ==========================================
# 5. ä¾§è¾¹æ 
# ==========================================
st.sidebar.header("ðŸŽ›ï¸ å°Šäº«æŽ§åˆ¶å°")
token_input = st.sidebar.text_input("Tushare Token (å¿…é¡»æ˜¯é«˜çº§ç‰ˆ)", type="password")

st.sidebar.divider()
st.sidebar.subheader("ðŸŽ¯ ä¸Šå¸å‚æ•°")
cfg_min_price = st.sidebar.number_input("æœ€ä½Žä»· (å…ƒ)", value=8.1, step=0.1)
cfg_max_price = st.sidebar.number_input("æœ€é«˜ä»· (å…ƒ)", value=20.0, step=0.5)
cfg_max_turnover = st.sidebar.slider("æœ€å¤§æ¢æ‰‹çŽ‡ (%)", 0.5, 5.0, 2.1, step=0.1)
cfg_position_count = st.sidebar.slider("æ¯æ—¥Top N", 1, 5, 3)

st.sidebar.divider()
cfg_stop_loss = st.sidebar.slider("æ­¢æŸçº¿ (-%)", 3.0, 15.0, 8.5, step=0.5)
cfg_max_hold = st.sidebar.slider("æœ€é•¿æŒè‚¡ (å¤©)", 5, 30, 15)
cfg_trail_start = st.sidebar.slider("æ­¢ç›ˆå¯åŠ¨ (+%)", 5.0, 15.0, 8.0, step=0.5) / 100.0
cfg_trail_drop = st.sidebar.slider("å›žè½å–å‡º (-%)", 1.0, 5.0, 3.0, step=0.5) / 100.0
stop_loss_decimal = cfg_stop_loss / 100.0

today = datetime.now()
start_date = st.sidebar.text_input("å¼€å§‹æ—¥æœŸ", value=f"{today.year}0101")
end_date = st.sidebar.text_input("ç»“æŸæ—¥æœŸ", value=today.strftime('%Y%m%d'))

# ==========================================
# 6. ä¸»ç¨‹åº
# ==========================================
st.title("ðŸš€ V35.0 å°Šäº«æžé€Ÿç‰ˆ (å¤šçº¿ç¨‹ + çœŸç­¹ç )")
st.caption("æ ¸å¿ƒæŠ€æœ¯ï¼šä½¿ç”¨ **8çº¿ç¨‹å¹¶å‘** ä¸‹è½½ Tushare **çœŸå®žç­¹ç æ•°æ®**ã€‚ä¸å¦¥åç²¾åº¦ï¼Œåªæå‡é€Ÿåº¦ã€‚")

tab1, tab2 = st.tabs(["ðŸ“¡ æ™ºèƒ½å®žç›˜", "ðŸ§ª é«˜ç²¾å›žæµ‹"])

# --- Tab 1: å®žç›˜ ---
with tab1:
    col_d, col_b = st.columns([3, 1])
    with col_d:
        scan_date_input = st.date_input("é€‰æ‹©æ—¥æœŸ", value=pd.Timestamp.now())
    scan_date_str = scan_date_input.strftime('%Y%m%d')
    
    if col_b.button("å¼€å§‹æ‰«æ", type="primary"):
        if not token_input:
            st.error("è¯·å…ˆè¾“å…¥ Token")
            st.stop()
        
        # ç®€å•çš„å•æ—¥é€»è¾‘
        with st.spinner("æ­£åœ¨èŽ·å–é«˜ç²¾ç­¹ç æ•°æ®..."):
            # èŽ·å–æœ€è¿‘äº¤æ˜“æ—¥ (å€Ÿç”¨ä¹‹å‰çš„é€»è¾‘ï¼Œç®€åŒ–å†™åœ¨è¿™é‡Œ)
            try:
                ts.set_token(token_input)
                pro = ts.pro_api()
                # ç®€å•å›žæº¯é€»è¾‘
                real_date_str = scan_date_str
                # (æ­¤å¤„ä¸ºäº†ä»£ç ç®€æ´ï¼Œç›´æŽ¥è¯·æ±‚ï¼Œå¦‚æžœéžäº¤æ˜“æ—¥ä¼šè¿”å›žç©ºï¼Œç”¨æˆ·æ‰‹åŠ¨è°ƒæ•´å³å¯ï¼Œæˆ–è€…å¤ç”¨V33çš„é€»è¾‘)
            except: pass
            
            # ç›´æŽ¥è°ƒç”¨å•æ—¥å‡½æ•°
            data = fetch_single_day_data(scan_date_str, token_input)
            names_df = get_stock_names(token_input)
            
            if data:
                fleet = run_strategy_real_cyq(data, names_df, cfg_min_price, cfg_max_price, cfg_max_turnover, cfg_position_count)
                if fleet is not None and not fleet.empty:
                    st.success(f"âš“ æˆåŠŸé€‰å‡º {len(fleet)} åªæ ‡çš„")
                    st.dataframe(fleet[['ts_code', 'name', 'close', 'bias', 'turnover_rate', 'winner_rate', 'industry']].style.format({
                        'close': '{:.2f}', 'bias': '{:.4f}', 'turnover_rate': '{:.2f}', 'winner_rate': '{:.1f}'
                    }), hide_index=True)
            else:
                st.warning("è¯¥æ—¥æœŸæ— æ•°æ®æˆ–éžäº¤æ˜“æ—¥ã€‚")

# --- Tab 2: å›žæµ‹ ---
with tab2:
    if st.button("ðŸš€ å¯åŠ¨é«˜ç²¾å¹¶å‘å›žæµ‹", type="primary"):
        if not token_input:
            st.error("Token æ— æ•ˆ")
            st.stop()
            
        # 1. èŽ·å–æ—¥æœŸåºåˆ—
        try:
            ts.set_token(token_input)
            pro = ts.pro_api()
            cal_df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date, is_open='1')
            dates = sorted(cal_df['cal_date'].tolist())
        except:
            st.error("ç½‘ç»œåˆå§‹åŒ–å¤±è´¥")
            st.stop()
            
        # 2. å¤šçº¿ç¨‹å¹¶å‘ä¸‹è½½ (é€Ÿåº¦çš„å…³é”®ï¼)
        # è¿”å›žçš„æ˜¯ä¸€ä¸ªå¤§å­—å…¸ï¼š{ '20250101': {daily:..., cyq:...}, ... }
        memory_db = fetch_data_concurrently(dates, token_input)
        
        if not memory_db:
            st.error("æœªä¸‹è½½åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥ Token æƒé™æˆ–æ—¥æœŸèŒƒå›´ã€‚")
            st.stop()
            
        # èŽ·å–å…¶ä»–é™æ€æ•°æ®
        names_df = get_stock_names(token_input)
        market_safe_map = get_market_sentiment(start_date, end_date, token_input)
        
        active_signals = [] 
        finished_signals = [] 
        progress_bar = st.progress(0, text="æ­£åœ¨è¿›è¡Œå†…å­˜å›žæµ‹...")
        
        # 3. å†…å­˜å›žæµ‹ (æžå¿«)
        valid_dates = sorted(list(memory_db.keys()))
        
        for i, date in enumerate(valid_dates):
            progress_bar.progress((i + 1) / len(valid_dates), text=f"æ­£åœ¨åˆ†æž: {date}")
            
            # ç›´æŽ¥ä»Žå†…å­˜å–æ•°æ®
            snap = memory_db.get(date)
            
            # æž„å»ºä»·æ ¼è¡¨
            price_map = {}
            if snap and not snap['daily'].empty:
                price_map = snap['daily'].set_index('ts_code')[['open','high','low','close']].to_dict('index')
            
            is_market_safe = market_safe_map.get(date, False)
            
            # --- æŒä»“ ---
            next_active = []
            curr_dt = pd.to_datetime(date)
            
            for sig in active_signals:
                code = sig['code']
                if curr_dt <= pd.to_datetime(sig['buy_date']):
                    if code in price_map: sig['highest'] = max(sig['highest'], price_map[code]['high'])
                    next_active.append(sig)
                    continue

                if code in price_map:
                    p = price_map[code]
                    ph, pl, pc = p['high'], p['low'], p['close']
                    
                    if ph > sig['highest']: sig['highest'] = ph
                    cost = sig['buy_price']
                    peak = sig['highest']
                    
                    reason = ""
                    sell_p = pc
                    
                    if (pl - cost) / cost <= -stop_loss_decimal:
                        reason = "æ­¢æŸ"
                        sell_p = cost * (1 - stop_loss_decimal)
                    elif (peak - cost)/cost >= cfg_trail_start and (peak - pc)/peak >= cfg_trail_drop:
                        reason = "æ­¢ç›ˆ"
                        sell_p = peak * (1 - cfg_trail_drop)
                    elif (curr_dt - pd.to_datetime(sig['buy_date'])).days >= cfg_max_hold:
                        reason = "è¶…æ—¶"
                    
                    if reason:
                        ret = (sell_p - cost) / cost - 0.0006
                        finished_signals.append({'ret': ret, 'rank': sig.get('rank', 1)})
                    else:
                        next_active.append(sig)
                else:
                    next_active.append(sig)
            active_signals = next_active
            
            # --- ä¹°å…¥ ---
            if is_market_safe:
                fleet = run_strategy_real_cyq(snap, names_df, cfg_min_price, cfg_max_price, cfg_max_turnover, cfg_position_count)
                if fleet is not None and not fleet.empty:
                    for rank_idx, (_, row) in enumerate(fleet.iterrows()):
                        code = row['ts_code']
                        if code in price_map:
                            active_signals.append({
                                'code': code, 'buy_date': date, 
                                'buy_price': price_map[code]['open'], 'highest': price_map[code]['open'],
                                'rank': rank_idx + 1
                            })
        
        progress_bar.empty()
        
        if finished_signals:
            df_res = pd.DataFrame(finished_signals)
            df_res['ret_pct'] = df_res['ret'] * 100
            
            st.divider()
            c1, c2, c3 = st.columns(3)
            avg_ret = df_res['ret'].mean() * 100
            win_rate = (df_res['ret']>0).mean() * 100
            c1.metric("å•ç¬”å¹³å‡æœŸæœ›", f"{avg_ret:.2f}%")
            c2.metric("èƒœçŽ‡", f"{win_rate:.1f}%")
            c3.metric("äº¤æ˜“æ¬¡æ•°", f"{len(df_res)}")
            
            st.subheader("ðŸ† å„åæ¬¡è¡¨çŽ° (åŸºäºŽçœŸç­¹ç )")
            rank_stats = df_res.groupby('rank')['ret_pct'].agg(['count', 'mean', 'sum', lambda x: (x>0).mean()*100])
            st.table(rank_stats.style.format("{:.2f}").background_gradient(subset=['mean'], cmap='Greens'))
        else:
            st.warning("æ— äº¤æ˜“")
