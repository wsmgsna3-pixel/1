# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V11.7 (æœ€ç»ˆæé€Ÿä¼˜åŒ–ç‰ˆï¼šç»•å¼€ç¼“å­˜å¤±æ•ˆçš„ç»“æ„æ€§ä¼˜åŒ–)
æ›´æ–°è¯´æ˜ï¼š
1. ã€**æé€Ÿä¼˜åŒ– V11.7**ã€‘ï¼š
   - å½»åº•é‡æ„å†å²æ•°æ®æ‹‰å–é€»è¾‘ã€‚
   - **get_all_history_data** å‡½æ•°ï¼šä¸€æ¬¡æ€§æ‹‰å– M æ”¯è‚¡ç¥¨æ‰€éœ€çš„å…¨éƒ¨æœ€é•¿å†å²æ•°æ®ï¼ˆ120å¤©æŒ‡æ ‡çª—å£ + Nå¤©å›æµ‹å‘¨æœŸï¼‰ï¼Œå¹¶ç¼“å­˜ã€‚
   - **compute_indicators** å‡½æ•°ï¼šä¸å†è°ƒç”¨ Tushareï¼Œè€Œæ˜¯ä»è¿™ä¸ªå¤§çš„ç¼“å­˜ä¸­è¿›è¡Œåˆ‡ç‰‡ã€‚
   - **æ•ˆæœï¼š** å†å²æ•°æ® API è°ƒç”¨æ¬¡æ•°ä» N*M æ¬¡ é™ä¸º M æ¬¡ï¼Œé€Ÿåº¦å°†å¾—åˆ°æ ¹æœ¬æ€§æ”¹å–„ã€‚
2. ã€Bug ä¿®å¤ V11.6/V11.5/V11.4ã€‘ï¼šä¿®å¤äº† NameErrorã€SyntaxErrorã€æ‹¬å·ä¸åŒ¹é…ç­‰æ‰€æœ‰å·²çŸ¥ bugã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import time  
warnings.filterwarnings("ignore")

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V11.7 æœ€ç»ˆå†³æˆ˜ç­–ç•¥ (æé€Ÿç‰ˆ)", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V11.7 æœ€ç»ˆå†³æˆ˜ç­–ç•¥ï¼ˆç»“æ„ä¼˜åŒ–æé€Ÿç‰ˆï¼‰")
st.markdown("ğŸš€ **V11.7 æœ€ç»ˆä¿®æ­£ç‰ˆï¼šå½»åº•è§£å†³äº†å›æµ‹é€Ÿåº¦æ…¢çš„æ ¹æœ¬åŸå› ï¼ˆç¼“å­˜å¤±æ•ˆï¼‰ï¼Œå°†å†å²æ•°æ®è°ƒç”¨æ¬¡æ•°é™åˆ°æœ€ä½ã€‚**")

# ---------------------------
# å…¨å±€å˜é‡åˆå§‹åŒ–
# ---------------------------
pro = None 
MAX_SEARCH_DAYS = 15 # æœ€å¤§å¾€å‰æŸ¥æ‰¾å¤©æ•°
HISTORY_LOOKBACK_DAYS = 120 # è®¡ç®—æŒ‡æ ‡æ‰€éœ€çš„æœ€é•¿å†å²æ•°æ®å¤©æ•°ï¼ˆç”¨äº MACD, 60æ—¥ä½ç½®ç­‰ï¼‰
GLOBAL_HISTORY_DATA = {} # å…¨å±€å†å²æ•°æ®ç¼“å­˜ï¼Œç”¨äº V11.7 ç»“æ„ä¼˜åŒ–

# ---------------------------
# è¾…åŠ©å‡½æ•° 
# ---------------------------
# ğŸš¨ V11.6 é‡æ–°æ·»åŠ ï¼šäº¤æ˜“æ—¥è·å–åŠæ—¥æœŸå›é€€å‡½æ•°
def get_trade_days(end_date_str, num_days, mode="backtest"):
    """
    è·å–äº¤æ˜“æ—¥åˆ—è¡¨ã€‚
    - åœ¨ 'select' æ¨¡å¼ä¸‹ï¼Œå¦‚æœ end_date_str çš„æ•°æ®ç¼ºå¤±ï¼Œåˆ™è‡ªåŠ¨å‘å‰å›é€€ã€‚
    - åœ¨ 'backtest' æ¨¡å¼ä¸‹ï¼Œä¸è¿›è¡Œå›é€€ï¼Œä½¿ç”¨ num_daysã€‚
    """
    
    # 1. è·å–æ—¥å†
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=MAX_SEARCH_DAYS * 2)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    
    if cal.empty or 'is_open' not in cal.columns:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œè¯·æ£€æŸ¥ Token æˆ– Tushare æƒé™ã€‚")
        return []
        
    trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)
    trade_days_df = trade_days_df[trade_days_df['cal_date'] <= end_date_str]
    
    if trade_days_df.empty:
        return []

    # 2. è‡ªåŠ¨å›é€€é€»è¾‘ (ä»…åœ¨é€‰è‚¡æ¨¡å¼æˆ–å•æ—¥å›æµ‹æ—¶ï¼Œä¸”æ•°æ®æ‹‰å–å¤±è´¥æ‰è§¦å‘)
    if mode == "select" or num_days == 1:
        for i in range(min(len(trade_days_df), MAX_SEARCH_DAYS)):
            check_date = trade_days_df['cal_date'].iloc[i]
            
            # å°è¯•æ‹‰å–å½“æ—¥æ•°æ®ï¼Œåˆ¤æ–­æ•°æ®æ˜¯å¦å·²æ›´æ–°
            check_data = safe_get('daily', trade_date=check_date)
            
            if not check_data.empty:
                if check_date != end_date_str:
                    st.warning(f"âš ï¸ åŸå§‹æ—¥æœŸ {end_date_str} æ•°æ®ç¼ºå¤±ï¼Œè‡ªåŠ¨å›é€€åˆ°æœ€æ–°å¯ç”¨äº¤æ˜“æ—¥ï¼š{check_date}ã€‚")
                
                trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)
                trade_days_df = trade_days_df[trade_days_df['cal_date'] <= check_date]
                
                return trade_days_df['cal_date'].head(num_days).tolist()
                
        st.error(f"åœ¨æœ€è¿‘ {MAX_SEARCH_DAYS} ä¸ªäº¤æ˜“æ—¥å†…ï¼Œå‡æ— æ³•è·å–åˆ°ä»»ä½•è‚¡ç¥¨æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®æºæˆ– Tushare æƒé™ã€‚")
        return []
    
    # 3. å¤šæ—¥å›æµ‹æ¨¡å¼ (ç›´æ¥è¿”å›æŒ‡å®šå¤©æ•°)
    return trade_days_df['cal_date'].head(num_days).tolist()

@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    """å®‰å…¨è°ƒç”¨ Tushare API - å·²ç§»é™¤ time.sleep(0.5)"""
    global pro
    if pro is None:
        return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception as e:
        time.sleep(0.1) 
        return pd.DataFrame(columns=['ts_code'])

# è°ƒæ•´ç¼“å­˜æ—¶é—´åˆ° 7 å¤©ï¼ˆ3600*24*7ï¼‰
@st.cache_data(ttl=3600*24*7)
def get_adj_factor(ts_code, start_date, end_date):
    df = safe_get('adj_factor', ts_code=ts_code, start_date=start_date, end_date=end_date)
    if df.empty or 'adj_factor' not in df.columns: return pd.DataFrame()
    df['adj_factor'] = pd.to_numeric(df['adj_factor'], errors='coerce').fillna(0)
    df = df.set_index('trade_date').sort_index() 
    return df['adj_factor']

# ----------------------------------------------------
# ğŸš¨ V11.7 æ ¸å¿ƒä¼˜åŒ–å‡½æ•°ï¼šä¸€æ¬¡æ€§è·å–æ‰€æœ‰è‚¡ç¥¨çš„å…¨éƒ¨æ‰€éœ€å†å²æ•°æ®
@st.cache_data(ttl=3600*12)
def get_all_history_data(trade_days_list, candidate_codes):
    """
    ä¸€æ¬¡æ€§è·å–æ‰€æœ‰è‚¡ç¥¨åœ¨ç»™å®šå›æµ‹çª—å£æ‰€éœ€çš„æœ€å¤§å†å²æ•°æ®ã€‚
    è¿”å›ä¸€ä¸ªå­—å…¸ {ts_code: DataFrame}ã€‚
    """
    if not trade_days_list or not candidate_codes: return {}
    
    # ç¡®å®šæœ€å¤§çš„æ—¶é—´çª—å£
    end_date_str = max(trade_days_list)
    
    # æˆ‘ä»¬éœ€è¦ä»æœ€æ—©å›æµ‹æ—¥å¾€å‰ HISTORY_LOOKBACK_DAYS çš„æ•°æ®
    # ä¸ºäº†ç®€åŒ–å’Œå®‰å…¨ï¼Œæˆ‘ä»¬ç›´æ¥ä»æœ€æ—©å›æµ‹æ—¥æœŸå¾€å‰æ¨ 200 å¤©
    max_start_date = (datetime.strptime(min(trade_days_list), "%Y%m%d") - timedelta(days=200)).strftime("%Y%m%d")
    
    st.info(f"ğŸ’¾ **æ­£åœ¨å»ºç«‹/è¯»å– {len(candidate_codes)} æ”¯è‚¡ç¥¨çš„å®Œæ•´å†å²æ•°æ®ç¼“å­˜ï¼ˆä¸€æ¬¡æ€§è°ƒç”¨ï¼‰ã€‚**\n\nè¯·æ±‚èŒƒå›´ï¼š{max_start_date} è‡³ {end_date_str}")
    
    history_cache = {}
    
    # è¿™é‡Œä¸èƒ½ä½¿ç”¨ st.progressï¼Œå› ä¸ºè¿™ä¸ªå‡½æ•°æœ¬èº«æ˜¯è¢«ç¼“å­˜çš„
    for i, ts_code in enumerate(candidate_codes):
        # ä¸ºäº†è®©ç¼“å­˜é”®å€¼æ›´ç²¾å‡†ï¼Œæˆ‘ä»¬è¿˜æ˜¯ç”¨ get_qfq_data_v4ï¼Œä½†å®ƒçš„å‚æ•°èŒƒå›´æ˜¯æœ€å¤§çš„
        df = get_qfq_data_v4(ts_code, start_date=max_start_date, end_date=end_date_str)
        if not df.empty:
            history_cache[ts_code] = df
            
    st.success("âœ… å®Œæ•´å†å²æ•°æ®ç¼“å­˜å»ºç«‹/è¯»å–æˆåŠŸã€‚")
    return history_cache

# åŸå§‹çš„å‰å¤æƒå‡½æ•°ï¼Œç°åœ¨ç”¨äºè·å–å¤§å—æ•°æ®ï¼Œç¼“å­˜é”®å€¼åŒ…å«å¤§æ—¶é—´èŒƒå›´
@st.cache_data(ttl=3600*12)
def get_qfq_data_v4(ts_code, start_date, end_date):
    """è·å–å‰å¤æƒæ•°æ®ï¼Œç”¨äºä¸€æ¬¡æ€§æ‹‰å–å¤§å—å†å²æ•°æ®"""
    daily_df = safe_get('daily', ts_code=ts_code, start_date=start_date, end_date=end_date)
    if daily_df.empty: return pd.DataFrame()
    daily_df = daily_df.set_index('trade_date').sort_index()
    
    adj_factor_series = get_adj_factor(ts_code, start_date, end_date)
    if adj_factor_series.empty: return pd.DataFrame()
    
    df = daily_df.merge(adj_factor_series.rename('adj_factor'), left_index=True, right_index=True, how='left')
    df = df.dropna(subset=['adj_factor'])
    if df.empty: return pd.DataFrame()
    latest_adj_factor = df['adj_factor'].iloc[-1]
    
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns:
            if latest_adj_factor > 1e-9:
                df[col + '_qfq'] = df[col] * df['adj_factor'] / latest_adj_factor
            else:
                df[col + '_qfq'] = df[col] 
    
    df = df.reset_index().rename(columns={'trade_date': 'trade_date_str'})
    df['trade_date'] = pd.to_datetime(df['trade_date_str'], format='%Y%m%d')
    df = df.sort_values('trade_date').set_index('trade_date_str')
    
    for col in ['open', 'high', 'low', 'close']:
        df[col] = df[col + '_qfq']
        
    return df[['open', 'high', 'low', 'close', 'vol']].copy() 

def get_future_prices(ts_code, selection_date, global_data):
    """ä»å…¨å±€æ•°æ®ä¸­åˆ‡ç‰‡è·å–æœªæ¥ä»·æ ¼"""
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    
    if ts_code not in global_data:
        results = {}
        for n in [1, 3, 5]: results[f'Return_D{n}'] = np.nan
        return results

    full_hist = global_data[ts_code]
    full_hist = full_hist.sort_index() 
    
    # è·å–é€‰è‚¡æ—¥å½“å¤©åŠä¹‹å‰çš„æ•°æ®ï¼ˆç”¨äºåŸºå‡†ä»·æ ¼ï¼‰
    selection_price_df = full_hist.loc[full_hist.index <= selection_date]
    selection_price_adj = selection_price_df['close'].iloc[-1] if not selection_price_df.empty else np.nan
    
    # è·å–é€‰è‚¡æ—¥ä¹‹åçš„æ•°æ®ï¼ˆç”¨äºæœªæ¥ä»·æ ¼ï¼‰
    future_hist = full_hist.loc[full_hist.index > selection_date]
    future_hist = future_hist.reset_index(drop=True) 
    
    results = {}
    for n in [1, 3, 5]:
        col_name = f'Return_D{n}'
        if len(future_hist) >= n:
            future_price = future_hist.iloc[n-1]['close']
            if pd.notna(selection_price_adj) and selection_price_adj > 1e-9:
                results[col_name] = (future_price / selection_price_adj - 1) * 100
            else:
                results[col_name] = np.nan
        else:
            results[col_name] = np.nan
    return results


def compute_indicators(ts_code, end_date, global_data):
    """
    è®¡ç®— MACD, 10æ—¥å›æŠ¥, æ³¢åŠ¨ç‡, 60æ—¥ä½ç½®ç­‰æŒ‡æ ‡ã€‚
    æ•°æ®ä»å…¨å±€ç¼“å­˜ä¸­åˆ‡ç‰‡ï¼Œä¸å†è°ƒç”¨ Tushare APIã€‚
    """
    res = {}
    if ts_code not in global_data: return res
    
    full_df = global_data[ts_code]
    
    # ç¡®å®šåˆ‡ç‰‡çš„èµ·å§‹æ—¥æœŸï¼šend_date å¾€å‰æ¨ 120 ä¸ªäº¤æ˜“æ—¥ï¼ˆç²—ç•¥æ¨ç®—ï¼‰
    end_date_dt = datetime.strptime(end_date, "%Y%m%d")
    
    # æˆ‘ä»¬åªéœ€è¦ end_date åŠä¹‹å‰çš„å†å²æ•°æ®
    hist_df = full_df.loc[full_df.index <= end_date]
    
    if hist_df.empty or len(hist_df) < 3 or 'close' not in hist_df.columns: return res
    
    # ä¸ºäº†ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è®¡ç®—æŒ‡æ ‡ï¼ˆè‡³å°‘éœ€è¦ 120 å¤©ï¼‰ï¼Œæˆ‘ä»¬å–æœ€å 200 ä¸ªäº¤æ˜“æ—¥
    df = hist_df.tail(200) 
    
    df['close'] = pd.to_numeric(df['close'], errors='coerce').astype(float)
    df['low'] = pd.to_numeric(df['low'], errors='coerce').astype(float)
    df['high'] = pd.to_numeric(df['high'], errors='coerce').astype(float)
    df['vol'] = pd.to_numeric(df['vol'], errors='coerce').fillna(0)
    df['pct_chg'] = df['close'].pct_change().fillna(0) * 100 
    close = df['close']
    res['last_close'] = close.iloc[-1]
    
    # MACD è®¡ç®— 
    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        res['macd_val'] = ((diff - dea) * 2).iloc[-1]
    else: res['macd_val'] = np.nan
        
    # é‡æ¯”è®¡ç®—
    vols = df['vol'].tolist()
    if len(vols) >= 6 and vols[-6:-1] and np.mean(vols[-6:-1]) > 1e-9:
        res['vol_ratio'] = vols[-1] / np.mean(vols[-6:-1])
    else: res['vol_ratio'] = np.nan
        
    # 10æ—¥å›æŠ¥ã€æ³¢åŠ¨ç‡è®¡ç®—
    res['10d_return'] = close.iloc[-1]/close.iloc[-10] - 1 if len(close)>=10 and close.iloc[-10]!=0 else 0
    res['volatility'] = df['pct_chg'].tail(10).std() if len(df)>=10 else 0
    
    # 60æ—¥ä½ç½®è®¡ç®—
    if len(df) >= 60:
        hist_60 = df.tail(60)
        min_low = hist_60['low'].min()
        max_high = hist_60['high'].max()
        current_close = hist_60['close'].iloc[-1]
        
        if max_high == min_low: res['position_60d'] = 50.0 
        else: res['position_60d'] = (current_close - min_low) / (max_high - min_low) * 100
    else: res['position_60d'] = np.nan 
    
    return res
# ----------------------------------------------------


# ----------------------------------------------------
# ä¾§è¾¹æ å‚æ•° (å®šä¹‰ BACKTEST_DAYS ç­‰å˜é‡)
# ----------------------------------------------------
with st.sidebar:
    st.header("æ¨¡å¼ä¸æ—¥æœŸé€‰æ‹©")
    
    run_mode = st.radio("é€‰æ‹©è¿è¡Œæ¨¡å¼", 
                        ("ä»Šæ—¥é€‰è‚¡ (è‡ªåŠ¨åŒ¹é…æœ€æ–°å¯ç”¨æ—¥)", "å¤šæ—¥å›æµ‹ (æŒ‡å®šå¤©æ•°)"),
                        key='run_mode', 
                        help="é€‰è‚¡æ¨¡å¼ï¼šè‡ªåŠ¨å¯»æ‰¾æœ€æ–°æœ‰æ•°æ®çš„äº¤æ˜“æ—¥ï¼Œä»…å›æµ‹ 1 å¤©ã€‚å›æµ‹æ¨¡å¼ï¼šæŒ‰æ‚¨æŒ‡å®šçš„æ—¥æœŸå’Œå¤©æ•°å›æµ‹ã€‚")
    
    backtest_date_end = st.date_input("é€‰æ‹©**å›æµ‹/é€‰è‚¡æ—¥æœŸ**", value=datetime.now().date(), max_value=datetime.now().date(), key='end_date')
    
    if run_mode == "å¤šæ—¥å›æµ‹ (æŒ‡å®šå¤©æ•°)":
        BACKTEST_DAYS = int(st.number_input("**è‡ªåŠ¨å›æµ‹å¤©æ•° (N)**", value=20, step=1, min_value=1, max_value=50, key='backtest_days_input', help="ç¨‹åºå°†è‡ªåŠ¨å›æµ‹æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥ã€‚"))
        MODE = "backtest"
    else:
        # é€‰è‚¡æ¨¡å¼ï¼Œå›ºå®šä¸º 1 å¤©ï¼Œä½†æ—¥æœŸä¼šè‡ªåŠ¨å›é€€åˆ°æœ‰æ•°æ®çš„æ—¥å­
        BACKTEST_DAYS = 1
        MODE = "select"
    
    st.markdown("---")
    st.header("æ ¸å¿ƒå‚æ•°")
    # å»ºè®® M >= 100 
    FINAL_POOL = int(st.number_input("æœ€ç»ˆå…¥å›´è¯„åˆ†æ•°é‡ (M)", value=100, step=10, min_value=1, key='final_pool', help="ï¼ˆæ¨è 100 æˆ–æ›´é«˜ï¼Œä»¥å……åˆ†åˆ©ç”¨é«˜æƒé™ï¼‰")) 
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=10, step=1, key='top_display'))
    TOP_BACKTEST = int(st.number_input("å›æµ‹åˆ†æ Top K", value=3, step=1, min_value=1, key='top_backtest')) 
    
    st.markdown("---")
    st.header("ğŸ›’ çµæ´»è¿‡æ»¤æ¡ä»¶")
    MIN_PRICE = st.number_input("æœ€ä½è‚¡ä»· (å…ƒ)", value=10.0, step=0.5, min_value=0.1, key='min_price')
    MAX_PRICE = st.number_input("æœ€é«˜è‚¡ä»· (å…ƒ)", value=300.0, step=5.0, min_value=1.0, key='max_price')
    MIN_TURNOVER = st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=2.0, step=0.5, min_value=0.1, key='min_turnover') 
    MIN_CIRC_MV_BILLIONS = st.number_input("æœ€ä½æµé€šå¸‚å€¼ (äº¿å…ƒ)", value=20.0, step=1.0, min_value=1.0, key='min_circ_mv', help="ä¾‹å¦‚ï¼šè¾“å…¥ 20 ä»£è¡¨æµé€šå¸‚å€¼å¿…é¡»å¤§äºç­‰äº 20 äº¿å…ƒã€‚")
    MIN_AMOUNT_MILLIONS = st.number_input("æœ€ä½æˆäº¤é¢ (äº¿å…ƒ)", value=0.6, step=0.1, min_value=0.1, key='min_amount_mil')
    MIN_AMOUNT = MIN_AMOUNT_MILLIONS * 100000000 

# ---------------------------
# Token è¾“å…¥ä¸åˆå§‹åŒ– 
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password", key='ts_token')
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()
ts.set_token(TS_TOKEN)
pro = ts.pro_api() 

# ---------------------------
# æ ¸å¿ƒå›æµ‹é€»è¾‘å‡½æ•° 
# ---------------------------
def run_backtest_for_a_day(last_trade, TOP_BACKTEST, FINAL_POOL, MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, MIN_CIRC_MV_BILLIONS, global_data):
    """ä¸ºå•ä¸ªäº¤æ˜“æ—¥è¿è¡Œé€‰è‚¡å’Œå›æµ‹é€»è¾‘ (V11.7 ä½¿ç”¨ global_data)"""
    
    # 1. æ‹‰å–å…¨å¸‚åœº Daily æ•°æ®
    daily_all = safe_get('daily', trade_date=last_trade) 
    if daily_all.empty or 'ts_code' not in daily_all.columns: 
        return pd.DataFrame(), f"æ•°æ®ç¼ºå¤±æˆ–æ‹‰å–å¤±è´¥ï¼š{last_trade}"

    pool_raw = daily_all.reset_index(drop=True) 
    stock_basic = safe_get('stock_basic', list_status='L', fields='ts_code,name,list_date') 
    REQUIRED_BASIC_COLS = ['ts_code','turnover_rate','amount','total_mv','circ_mv'] 
    daily_basic = safe_get('daily_basic', trade_date=last_trade, fields=','.join(REQUIRED_BASIC_COLS))
    mf_raw = safe_get('moneyflow', trade_date=last_trade)
    pool_merged = pool_raw.copy()

    if not stock_basic.empty and 'name' in stock_basic.columns:
        pool_merged = pool_merged.merge(stock_basic[['ts_code','name','list_date']], on='ts_code', how='left')
    else:
        pool_merged['name'] = pool_merged['ts_code']
        pool_merged['list_date'] = '20000101'
        
    if not daily_basic.empty:
        cols_to_merge = [c for c in REQUIRED_BASIC_COLS if c in daily_basic.columns]
        if 'amount' in pool_merged.columns and 'amount' in cols_to_merge: 
            pool_merged = pool_merged.drop(columns=['amount'])
        pool_merged = pool_merged.merge(daily_basic[cols_to_merge], on='ts_code', how='left')
    
    # --- èµ„é‡‘æµæ•°æ®å¤„ç† FIX START ---
    moneyflow_to_merge = pd.DataFrame()
    if not mf_raw.empty:
        possible = ['net_mf','net_mf_amount','net_mf_in']
        for c in possible:
            if c in mf_raw.columns:
                moneyflow_to_merge = mf_raw[['ts_code', c]].rename(columns={c:'net_mf'})
                break            
    
    if not moneyflow_to_merge.empty:
        pool_merged = pool_merged.merge(moneyflow_to_merge, on='ts_code', how='left')
        
    if 'net_mf' not in pool_merged.columns:
        pool_merged['net_mf'] = np.nan 
        
    pool_merged['net_mf'] = pd.to_numeric(pool_merged['net_mf'], errors='coerce').fillna(0) 
    # --- èµ„é‡‘æµæ•°æ®å¤„ç† FIX END ---

    pool_merged['turnover_rate'] = pool_merged['turnover_rate'].fillna(0) 
   
  
    # 3. æ‰§è¡Œç¡¬æ€§æ¡ä»¶è¿‡æ»¤
    df = pool_merged.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce') 
    df['turnover_rate'] = pd.to_numeric(df['turnover_rate'], errors='coerce').fillna(0)
    df['amount'] = pd.to_numeric(df['amount'], errors='coerce').fillna(0) * 1000 # è½¬æ¢ä¸ºä¸‡å…ƒ
    df['circ_mv_billion'] = pd.to_numeric(df['circ_mv'], errors='coerce').fillna(0) / 10000 
    df['name'] = df['name'].astype(str)
    
    # è¿‡æ»¤ ST è‚¡/é€€å¸‚è‚¡/åŒ—äº¤æ‰€/æ¬¡æ–°è‚¡
    mask_st = df['name'].str.contains('ST|é€€', case=False, na=False)
    df = df[~mask_st]
    mask_bj = df['ts_code'].str.startswith('92') 
    df = df[~mask_bj]
    TODAY = datetime.strptime(last_trade, "%Y%m%d")
    MIN_LIST_DAYS = 120 
    df['list_date_dt'] = pd.to_datetime(df['list_date'], format='%Y%m%d', errors='coerce')
    df['days_listed'] = (TODAY - df['list_date_dt']).dt.days
    mask_cyb_kcb = df['ts_code'].str.startswith(('30','68'))
    mask_new = df['days_listed'] < MIN_LIST_DAYS
    df = df[~((mask_cyb_kcb) & (mask_new))]

    # è¿‡æ»¤ä»·æ ¼
    mask_price = (df['close'] >= MIN_PRICE) & (df['close'] <= MAX_PRICE)
    df = df[mask_price]
    # è¿‡æ»¤æµé€šå¸‚å€¼
    mask_circ_mv = df['circ_mv_billion'] >= MIN_CIRC_MV_BILLIONS
    df = df[mask_circ_mv] 
    # è¿‡æ»¤æ¢æ‰‹ç‡
    mask_turn = df['turnover_rate'] >= MIN_TURNOVER 
    df = df[mask_turn]
    # è¿‡æ»¤æˆäº¤é¢
    mask_amt = df['amount'] * 1000 >= MIN_AMOUNT
    df = df[mask_amt]
    
    df = df.reset_index(drop=True)

    if len(df) == 0: return pd.DataFrame(), f"è¿‡æ»¤åæ— è‚¡ç¥¨ï¼š{last_trade}"

    # 4. é´é€‰å†³èµ›åå• (åŸºäºå½“æ—¥æ¶¨å¹…å’Œæ¢æ‰‹ç‡çš„æ··åˆåˆç­›)
    limit_pct = int(FINAL_POOL * 0.7)
    df_pct = df.sort_values('pct_chg', ascending=False).head(limit_pct).copy()
    limit_turn = FINAL_POOL - len(df_pct)
    existing_codes = set(df_pct['ts_code'])
    df_turn = df[~df['ts_code'].isin(existing_codes)].sort_values('turnover_rate', ascending=False).head(limit_turn).copy()
    final_candidates = pd.concat([df_pct, df_turn]).reset_index(drop=True)

 
    # 5. æ·±åº¦è¯„åˆ† 
    records = []
    for row in final_candidates.itertuples():
        ts_code = row.ts_code
        
        rec = {
            'ts_code': ts_code, 'name': getattr(row, 'name', ts_code),
            'Close': getattr(row, 'close', np.nan),
            'Circ_MV (äº¿)': getattr(row, 'circ_mv_billion', np.nan),
            'Pct_Chg (%)': getattr(row, 'pct_chg', 0), 
            'turnover': getattr(row, 'turnover_rate', 0),
            'net_mf': getattr(row, 'net_mf', 0)
        }
        
        # ğŸš¨ V11.7: ä¼ å…¥ global_dataï¼Œä»ç¼“å­˜ä¸­åˆ‡ç‰‡
        ind = compute_indicators(ts_code, last_trade, global_data)
        rec.update({
            'vol_ratio': ind.get('vol_ratio', 0), 'macd': ind.get('macd_val', 0),
            '10d_return': ind.get('10d_return', 0),
            'volatility': ind.get('volatility', 0), 'position_60d': ind.get('position_60d', np.nan)
        })
        
        # åªæœ‰åœ¨å¤šæ—¥å›æµ‹æ—¶æ‰éœ€è¦æœªæ¥æ”¶ç›Š
        if MODE == 'backtest':
            # ğŸš¨ V11.7: ä¼ å…¥ global_dataï¼Œä»ç¼“å­˜ä¸­åˆ‡ç‰‡
            future_returns = get_future_prices(ts_code, last_trade, global_data)
            rec.update({
                'Return_D1 (%)': future_returns.get('Return_D1', np.nan),
                'Return_D3 (%)': future_returns.get('Return_D3', np.nan),
                'Return_D5 (%)': future_returns.get('Return_D5', np.nan),
            })
        else:
             rec.update({
                'Return_D1 (%)': np.nan,
                'Return_D3 (%)': np.nan,
                'Return_D5 (%)': np.nan,
            })


        records.append(rec)
    
    fdf = pd.DataFrame(records)
    if fdf.empty: return pd.DataFrame(), f"è¯„åˆ†åˆ—è¡¨ä¸ºç©ºï¼š{last_trade}"

    # 6. å½’ä¸€åŒ–ä¸ V11.0 ç­–ç•¥ç²¾è°ƒè¯„åˆ† 
    def normalize(series):
        series_nn = series.dropna() 
        if series_nn.max() == series_nn.min(): return pd.Series([0.5] * len(series), index=series.index)
        return (series - series_nn.min()) / (series_nn.max() - series_nn.min() + 1e-9)

 
    fdf['s_pct'] = normalize(fdf['Pct_Chg (%)'])
    fdf['s_turn'] = normalize(fdf['turnover'])
    fdf['s_vol'] = normalize(fdf['vol_ratio'])
    fdf['s_mf'] = normalize(fdf['net_mf'])
    fdf['s_macd'] = normalize(fdf['macd'])
    fdf['s_trend'] = normalize(fdf['10d_return'])
    fdf['s_volatility'] = normalize(fdf['volatility'])
    fdf['s_position'] = fdf['position_60d'] / 100 
    
    # ----------------------------------------------------------------------------------
    # ğŸš¨ V11.0 æœ€ç»ˆå†³æˆ˜ç­–ç•¥ï¼šV9.0 æ¡†æ¶ + å¼ºåŒ– MACD è¶‹åŠ¿å…±æŒ¯ç‰ˆ
    
    # æ ¸å¿ƒæƒé‡ï¼šèµ„é‡‘æµï¼Œå æ¯” 35%
    w_mf = 0.35            
    # åŠ¨èƒ½æƒé‡ï¼šå½“æ—¥åŠ¨èƒ½ï¼Œå æ¯” 20%
    w_pct = 0.10            
    w_turn = 0.10           
    # é˜²å¾¡æƒé‡ï¼šå®‰å…¨è¾¹é™…ä¸æ³¢åŠ¨æ§åˆ¶ï¼Œå æ¯” 25%
    w_position = 0.15       
    w_volatility = 0.10     
    # è¶‹åŠ¿æƒé‡ï¼šä¸­æœŸè¶‹åŠ¿ï¼Œå æ¯” 20%
    w_macd = 0.20           
    # å½»åº•å½’é›¶é¡¹
    w_vol = 0.00            
    w_trend = 0.00          
    
    # Sum: 0.35+0.10+0.10+0.15+0.10+0.20 = 1.00
    
  
    score = (
        fdf['s_pct'] * w_pct + fdf['s_turn'] * w_turn + 
        fdf['s_mf'] * w_mf + 
        fdf['s_macd'] * w_macd + 
        
        # å¼•å…¥é˜²å¾¡ï¼š60æ—¥ä½ç½®è¶Šä½è¶Šå¥½ (1-s_position)ï¼Œæ³¢åŠ¨ç‡è¶Šä½è¶Šå¥½ (1-s_volatility)
        (1 - fdf['s_position']) * w_position + 
        (1 - fdf['s_volatility']) * w_volatility + 
        
 
        # å½’é›¶é¡¹
        fdf['s_vol'] * w_vol + 
        fdf['s_trend'] * w_trend     
    )
    fdf['ç»¼åˆè¯„åˆ†'] = score * 100
    fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
    fdf.index += 1
    # ----------------------------------------------------------------------------------


    return fdf.head(TOP_BACKTEST).copy(), None

# ---------------------------
# ä¸»è¿è¡Œå— 
# ---------------------------

# å°†æ‰€æœ‰è¿è¡Œé€»è¾‘åŒ…è£…åœ¨ä¸€ä¸ªå‡½æ•°ä¸­
def execute_run(mode, backtest_days):
    
    if mode == "select":
        st.header(f"ğŸš€ æ­£åœ¨è¿›è¡Œ 1 ä¸ªäº¤æ˜“æ—¥çš„**é€‰è‚¡**...")
    else:
        st.header(f"ğŸ“ˆ æ­£åœ¨è¿›è¡Œ {backtest_days} ä¸ªäº¤æ˜“æ—¥çš„**å›æµ‹**...")

    trade_days_str = get_trade_days(backtest_date_end.strftime("%Y%m%d"), backtest_days, mode=mode)
    
    if not trade_days_str:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥æ—¥æœŸæˆ– Tokenã€‚")
        st.stop()
    
    
    # 1. å¯åŠ¨å…¨å±€æ•°æ®æ‹‰å–å’Œç¼“å­˜ (V11.7 æ ¸å¿ƒæ­¥éª¤)
    # æˆ‘ä»¬éœ€è¦æ‰¾åˆ°æ‰€æœ‰å¯èƒ½å…¥å›´çš„è‚¡ç¥¨ä»£ç ï¼Œä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬æ‹‰å–æ‰€æœ‰å½“æ—¥æœ‰æ•°æ®çš„è‚¡ç¥¨
    # ä»…è·å– end_date çš„æ•°æ®ï¼Œä»¥ä¿è¯æ‹‰å–çš„æ˜¯æœ€æ–°çš„äº¤æ˜“æ—¥æ•°æ®
    initial_daily_data = safe_get('daily', trade_date=max(trade_days_str))
    
    if initial_daily_data.empty:
        st.error(f"æ— æ³•è·å–æ—¥æœŸ {max(trade_days_str)} çš„æ—¥çº¿æ•°æ®ï¼Œè¯·æ£€æŸ¥ Tushare Tokenã€‚")
        st.stop()
        
    candidate_codes = initial_daily_data['ts_code'].tolist()
    
    # è¿è¡Œä¸€æ¬¡ï¼Œå°†æ‰€æœ‰å†å²æ•°æ®ç¼“å­˜èµ·æ¥
    global_data = get_all_history_data(trade_days_str, candidate_codes)
    
    if not global_data:
        st.error("æ— æ³•æ‹‰å–æˆ–å»ºç«‹å†å²æ•°æ®ç¼“å­˜ï¼Œè¯·æ£€æŸ¥ Tushare æƒé™ã€‚")
        st.stop()

    
    results_list = []
    total_days = len(trade_days_str)
    
    progress_text = st.empty()
    my_bar = st.progress(0)
    
    start_time = time.time() 
    
    for i, trade_date in enumerate(trade_days_str):
        
        progress_text.text(f"ğŸš€ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{total_days} ä¸ªäº¤æ˜“æ—¥ï¼š{trade_date} (æ•°æ®å·²ä»æœ¬åœ°ç¼“å­˜ä¸­åˆ‡ç‰‡)")
            
        daily_result_df, error = run_backtest_for_a_day(
            trade_date, TOP_BACKTEST, FINAL_POOL, MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, MIN_CIRC_MV_BILLIONS, global_data
        )
        
        if error:
            st.warning(f"è·³è¿‡ {trade_date}ï¼š{error}")
        elif not daily_result_df.empty:
            daily_result_df['Trade_Date'] = trade_date
            results_list.append(daily_result_df)
            
        my_bar.progress((i + 1) / total_days)

    end_time = time.time()
    total_duration = end_time - start_time
    
    progress_text.text(f"âœ… è¿è¡Œå®Œæˆï¼Œæ­£åœ¨æ±‡æ€»ç»“æœ... æ€»è€—æ—¶: {total_duration:.2f} ç§’")
    my_bar.empty()
    
    if not results_list:
        st.error("æ‰€æœ‰äº¤æ˜“æ—¥çš„å›æµ‹å‡å¤±è´¥æˆ–æ— ç»“æœã€‚")
        st.stop()
        
    all_results = pd.concat(results_list)
    
    # åŒºåˆ†æ˜¾ç¤ºé€‰è‚¡ç»“æœå’Œå›æµ‹ç»“æœ
    if mode == "select":
        st.success(f"ğŸ‰ **ã€ä»Šæ—¥é€‰è‚¡ç»“æœã€‘**ï¼šå·²æˆåŠŸä½¿ç”¨æœ€æ–°å¯ç”¨æ•°æ®ï¼ˆ{trade_days_str[0]}ï¼‰è¿›è¡Œé€‰è‚¡ï¼")
        st.header(f"ğŸ“‹ é€‰è‚¡æ¨èç»“æœ (Top {TOP_BACKTEST})")
        display_cols = ['Trade_Date', 'name', 'ts_code', 'ç»¼åˆè¯„åˆ†', 
                        'Close', 'Pct_Chg (%)', 'Circ_MV (äº¿)']
        
    else: # å¤šæ—¥å›æµ‹
        st.header(f"ğŸ“Š æœ€ç»ˆå¹³å‡å›æµ‹ç»“æœ (Top {TOP_BACKTEST}ï¼Œå…± {total_days} ä¸ªäº¤æ˜“æ—¥)")
        
        for n in [1, 3, 5]:
            col = f'Return_D{n} (%)' 
            
            filtered_returns = all_results.copy()
            valid_returns = filtered_returns.dropna(subset=[col])

            if not valid_returns.empty:
                avg_return = valid_returns[col].mean()
                hit_rate = (valid_returns[col] > 0).sum() / len(valid_returns) * 100 if len(valid_returns) > 0 else 0.0
                total_count = len(valid_returns)
            else:
                avg_return = np.nan
                hit_rate = 0.0
                total_count = 0
                
            st.metric(f"Top {TOP_BACKTEST}ï¼šD+{n} å¹³å‡æ”¶ç›Š / å‡†ç¡®ç‡", 
                      f"{avg_return:.2f}% / {hit_rate:.1f}%", 
                      help=f"æ€»æœ‰æ•ˆæ ·æœ¬æ•°ï¼š{total_count}ã€‚**V11.0 å·²åº”ç”¨ V9.0 æ¡†æ¶ + å¼ºåŒ– MACD è¶‹åŠ¿å…±æŒ¯ç­–ç•¥ã€‚**")

        st.header("ğŸ“‹ æ¯æ—¥å›æµ‹è¯¦æƒ… (Top K æ˜ç»†)")
        display_cols = ['Trade_Date', 'name', 'ts_code', 'ç»¼åˆè¯„åˆ†', 
                        'Close', 'Pct_Chg (%)', 'Circ_MV (äº¿)',
                        'Return_D1 (%)', 'Return_D3 (%)', 'Return_D5 (%)']
    
    st.dataframe(all_results[display_cols].sort_values('ç»¼åˆè¯„åˆ†', ascending=False).head(TOP_DISPLAY), use_container_width=True)

# ---------------------------
# ä¸»ç•Œé¢æŒ‰é’®è§¦å‘
# ---------------------------
st.markdown("---")
col1, col2 = st.columns(2)

with col1:
    if st.button("ğŸš€ ä»Šæ—¥é€‰è‚¡ (1æ—¥)", key='select_button', help="ä½¿ç”¨æœ€æ–°çš„å¯ç”¨äº¤æ˜“æ—¥æ•°æ®è¿›è¡Œé€‰è‚¡ã€‚"):
        st.warning("âš ï¸ **V11.7 æœ€ç»ˆæé€Ÿç‰ˆå·²ä¸Šçº¿ã€‚è¯·ä½¿ç”¨æ­¤ç‰ˆæœ¬è¿›è¡Œæµ‹è¯•ã€‚**")
        execute_run("select", 1)

with col2:
    if st.button(f"â³ å¼€å§‹ {BACKTEST_DAYS} æ—¥è‡ªåŠ¨å›æµ‹", key='backtest_button', help="ä½¿ç”¨æŒ‡å®šæ—¥æœŸå’Œå¤©æ•°è¿›è¡Œå†å²å›æµ‹ã€‚"):
        st.warning("âš ï¸ **V11.7 æœ€ç»ˆæé€Ÿç‰ˆå·²ä¸Šçº¿ã€‚è¯·ä½¿ç”¨æ­¤ç‰ˆæœ¬è¿›è¡Œæµ‹è¯•ã€‚**")
        execute_run("backtest", BACKTEST_DAYS)
