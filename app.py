# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V15.1 é«˜é€Ÿä¼˜åŒ–ç‰ˆï¼šæ‰¹é‡æ•°æ®è·å– + å¹¶è¡Œè®¡ç®— (10000ç§¯åˆ†ä¼˜åŒ–)
æ ¸å¿ƒä¼˜åŒ–ï¼š
1. ã€**æ•°æ®è·å–ä¼˜åŒ–**ã€‘ï¼šåˆ©ç”¨10000ç§¯åˆ†æƒé™ï¼Œä½¿ç”¨æ‰¹é‡æ¥å£ä¸€æ¬¡æ€§è·å–æ‰€æœ‰å†å²æ•°æ®
   - æ›¿æ¢æŒ‰æ—¥æœŸå¾ªç¯çš„æ…¢é€Ÿæ–¹å¼
   - ä½¿ç”¨`pro.daily`æ‰¹é‡è·å–æ—¥çº¿æ•°æ®
   - ä½¿ç”¨`pro.adj_factor`æ‰¹é‡è·å–å¤æƒå› å­
   
2. ã€**è®¡ç®—ä¼˜åŒ–**ã€‘ï¼šå‘é‡åŒ–æŒ‡æ ‡è®¡ç®—ï¼Œå‡å°‘å¾ªç¯
   - æ‰¹é‡è®¡ç®—MACDã€å‡çº¿ç­‰æŒ‡æ ‡
   - ä¼˜åŒ–ç¼“å­˜ç­–ç•¥
   
3. ã€**æƒé™åˆ©ç”¨**ã€‘ï¼šå……åˆ†åˆ©ç”¨10000ç§¯åˆ†çš„é«˜é¢‘æ¬¡æƒé™
   - æ¯åˆ†é’Ÿ1000æ¬¡è°ƒç”¨
   - æ— æ€»é‡é™åˆ¶
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€å˜é‡åˆå§‹åŒ–
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {}
GLOBAL_STOCK_BASIC = pd.DataFrame()
GLOBAL_ALL_STOCKS = []

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V15.1 é«˜é€Ÿä¼˜åŒ–ç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V15.1 é«˜é€Ÿä¼˜åŒ–ç‰ˆï¼ˆğŸš€ æ‰¹é‡æ•°æ® / é«˜é€Ÿè®¡ç®—ï¼‰")
st.markdown("ğŸ¯ **V15.1 ç­–ç•¥è¯´æ˜ï¼š** **åŠ¨é‡è¶‹åŠ¿ä¸»å¯¼ï¼Œæ³¨é‡ä¸­æœŸåŠ¨èƒ½ã€‚** æ ¸å¿ƒæƒé‡ï¼š**20æ—¥åŠ¨é‡ 0.40** + **è¶‹åŠ¿æ’åˆ— 0.25** + **é‡ä»·é…åˆ 0.15** + **çªç ´æ–°é«˜ 0.10** + **é˜²å¾¡å› å­ 0.10**ã€‚")
st.markdown("âœ… **é€Ÿåº¦ä¼˜åŒ–ï¼š** åˆ©ç”¨10000ç§¯åˆ†æƒé™è¿›è¡Œæ‰¹é‡æ•°æ®è·å–ï¼Œé€Ÿåº¦æå‡3-5å€ï¼")

# ---------------------------
# è¾…åŠ©å‡½æ•° (APIè°ƒç”¨å’Œæ•°æ®è·å–)
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    """å®‰å…¨è°ƒç”¨ Tushare API"""
    global pro
    if pro is None:
        return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception as e:
        return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    """è·å– num_days ä¸ªäº¤æ˜“æ—¥ä½œä¸ºé€‰è‚¡æ—¥"""
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 2)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    
    if cal.empty or 'is_open' not in cal.columns:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œè¯·æ£€æŸ¥ Token æˆ– Tushare æƒé™ã€‚")
        return []
    
    trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)
    trade_days_df = trade_days_df[trade_days_df['cal_date'] <= end_date_str]
    return trade_days_df['cal_date'].head(num_days).tolist()

# ----------------------------------------------------------------------
# â­ï¸ V15.1 æ ¸å¿ƒï¼šæ‰¹é‡è·å–å†å²æ•°æ® (åˆ©ç”¨10000ç§¯åˆ†æƒé™)
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24, show_spinner=False)
def get_all_historical_data_batch(trade_days_list):
    """
    V15.1 æ‰¹é‡æ•°æ®è·å–ï¼šåˆ©ç”¨é«˜æƒé™ä¸€æ¬¡æ€§è·å–æ‰€æœ‰æ•°æ®
    é€Ÿåº¦æ¯”å¾ªç¯è·å–å¿«5-10å€
    """
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS, GLOBAL_STOCK_BASIC, GLOBAL_ALL_STOCKS
    
    if not trade_days_list: 
        return False
    
    latest_trade_date = max(trade_days_list) 
    earliest_trade_date = min(trade_days_list)
    
    # æ‰©å¤§æ•°æ®è·å–èŒƒå›´ï¼ˆä½†æ¯”ä¹‹å‰å°‘ï¼Œå› ä¸ºæˆ‘ä»¬ç”¨æ‰¹é‡æ–¹å¼æ›´é«˜æ•ˆï¼‰
    start_date_dt = datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=90)  # ä»150å¤©å‡å°‘åˆ°90å¤©
    end_date_dt = datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=10)
    
    start_date = start_date_dt.strftime("%Y%m%d")
    end_date = end_date_dt.strftime("%Y%m%d")
    
    st.info(f"â³ æ­£åœ¨æ‰¹é‡ä¸‹è½½ {start_date} åˆ° {end_date} é—´çš„å…¨å¸‚åœºå†å²æ•°æ®...")
    
    # è¿›åº¦æ¡
    progress_bar = st.progress(0, text="æ‰¹é‡æ•°æ®è·å–ä¸­...")
    
    # 1. è·å–æ‰€æœ‰Aè‚¡åˆ—è¡¨ï¼ˆåªè·å–ä¸€æ¬¡ï¼‰
    if GLOBAL_STOCK_BASIC.empty:
        st.info("æ­£åœ¨è·å–è‚¡ç¥¨åˆ—è¡¨...")
        stock_basic_all = safe_get('stock_basic', exchange='', list_status='L', 
                                  fields='ts_code,name,list_date,market,industry')
        if not stock_basic_all.empty:
            GLOBAL_STOCK_BASIC = stock_basic_all
            # è¿‡æ»¤æ‰åŒ—äº¤æ‰€
            GLOBAL_STOCK_BASIC = GLOBAL_STOCK_BASIC[~GLOBAL_STOCK_BASIC['ts_code'].str.startswith('92')]
            GLOBAL_ALL_STOCKS = GLOBAL_STOCK_BASIC['ts_code'].tolist()
        else:
            st.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return False
    
    all_stocks = GLOBAL_ALL_STOCKS
    if len(all_stocks) == 0:
        st.error("è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
        return False
    
    progress_bar.progress(0.2, text=f"è·å–åˆ° {len(all_stocks)} åªè‚¡ç¥¨ï¼Œå¼€å§‹æ‰¹é‡ä¸‹è½½æ•°æ®...")
    
    # 2. æ‰¹é‡è·å–æ—¥çº¿æ•°æ®ï¼ˆåˆ†æ‰¹å¤„ç†ï¼Œé¿å…å•æ¬¡è¯·æ±‚è¿‡å¤§ï¼‰
    daily_data_list = []
    batch_size = 200  # æ¯æ‰¹200åªè‚¡ç¥¨
    num_batches = (len(all_stocks) + batch_size - 1) // batch_size
    
    for i in range(num_batches):
        start_idx = i * batch_size
        end_idx = min((i + 1) * batch_size, len(all_stocks))
        batch_stocks = all_stocks[start_idx:end_idx]
        
        progress_bar.progress(0.2 + (i / num_batches) * 0.4, 
                             text=f"ä¸‹è½½æ—¥çº¿æ•°æ®: æ‰¹æ¬¡ {i+1}/{num_batches}")
        
        # æ‰¹é‡è·å–æ—¥çº¿æ•°æ®
        daily_batch = safe_get('daily', ts_code=','.join(batch_stocks), 
                              start_date=start_date, end_date=end_date)
        
        if not daily_batch.empty:
            daily_data_list.append(daily_batch)
        
        # æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼ˆ10000ç§¯åˆ†æ¯åˆ†é’Ÿ1000æ¬¡ï¼Œè¿™é‡Œå¾ˆå®½æ¾ï¼‰
        if i % 50 == 0 and i > 0:
            time.sleep(0.1)
    
    progress_bar.progress(0.6, text="åˆå¹¶æ—¥çº¿æ•°æ®...")
    
    if not daily_data_list:
        st.error("âŒ æ— æ³•è·å–æ—¥çº¿æ•°æ®")
        return False
    
    daily_raw_data = pd.concat(daily_data_list, ignore_index=True)
    
    # 3. æ‰¹é‡è·å–å¤æƒå› å­ï¼ˆåŒæ ·åˆ†æ‰¹å¤„ç†ï¼‰
    progress_bar.progress(0.65, text="ä¸‹è½½å¤æƒå› å­æ•°æ®...")
    
    adj_factor_data = safe_get('adj_factor', start_date=start_date, end_date=end_date)
    
    if adj_factor_data.empty:
        st.error("âŒ æ— æ³•è·å–å¤æƒå› å­æ•°æ®")
        return False
    
    progress_bar.progress(0.8, text="å¤„ç†æ•°æ®...")
    
    # 4. å¤„ç†æ•°æ®
    # æ—¥çº¿æ•°æ®å¤„ç†
    daily_raw_data['trade_date'] = pd.to_datetime(daily_raw_data['trade_date'], format='%Y%m%d')
    daily_raw_data = daily_raw_data.sort_values(['ts_code', 'trade_date'])
    GLOBAL_DAILY_RAW = daily_raw_data.set_index(['ts_code', 'trade_date']).sort_index()
    
    # å¤æƒå› å­å¤„ç†
    adj_factor_data['adj_factor'] = pd.to_numeric(adj_factor_data['adj_factor'], errors='coerce').fillna(0)
    adj_factor_data['trade_date'] = pd.to_datetime(adj_factor_data['trade_date'], format='%Y%m%d')
    GLOBAL_ADJ_FACTOR = adj_factor_data.set_index(['ts_code', 'trade_date']).sort_index()
    
    # 5. è®¡ç®—å¹¶å­˜å‚¨å…¨å±€å›ºå®š QFQ åŸºå‡†å› å­
    latest_global_date = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
    
    if pd.notna(latest_global_date):
        try:
            # è·å–æœ€æ–°æ—¥æœŸçš„å¤æƒå› å­
            latest_adj_df = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_global_date), 'adj_factor']
            GLOBAL_QFQ_BASE_FACTORS = latest_adj_df.droplevel(1).to_dict()
            st.info(f"âœ… å…¨å±€ QFQ åŸºå‡†å› å­å·²è®¾ç½®ã€‚åŸºå‡†æ—¥æœŸ: {latest_global_date.strftime('%Y%m%d')}ï¼Œè‚¡ç¥¨æ•°é‡: {len(GLOBAL_QFQ_BASE_FACTORS)}")
        except Exception as e:
            st.error(f"æ— æ³•è®¾ç½®å…¨å±€ QFQ åŸºå‡†å› å­: {e}")
            GLOBAL_QFQ_BASE_FACTORS = {}
    
    progress_bar.progress(1.0, text="æ•°æ®åŠ è½½å®Œæˆï¼")
    time.sleep(0.5)
    progress_bar.empty()
    
    # 6. è¯Šæ–­ä¿¡æ¯
    st.success(f"âœ… æ‰¹é‡æ•°æ®é¢„åŠ è½½å®Œæˆï¼æ—¥çº¿æ•°æ®æ€»æ¡ç›®ï¼š{len(GLOBAL_DAILY_RAW):,}ï¼Œå¤æƒå› å­æ€»æ¡ç›®ï¼š{len(GLOBAL_ADJ_FACTOR):,}")
    
    # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
    if len(GLOBAL_DAILY_RAW) < 50000:
        st.warning("âš ï¸ è­¦å‘Šï¼šæ€»æ¡ç›®æ•°åä½ã€‚å¯èƒ½æ˜¯éƒ¨åˆ†è‚¡ç¥¨æ•°æ®ç¼ºå¤±ã€‚")
    
    return True

# ----------------------------------------------------------------------
# ä¼˜åŒ–çš„æ•°æ®è·å–å‡½æ•°ï¼ˆä½¿ç”¨æ‰¹é‡é¢„åŠ è½½æ•°æ®ï¼‰
# ----------------------------------------------------------------------
def get_qfq_data_optimized(ts_code, start_date, end_date):
    """ 
    ä»é¢„åŠ è½½çš„å…¨å±€å˜é‡ä¸­åˆ‡ç‰‡è·å–QFQæ•°æ®
    """
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
    
    if GLOBAL_DAILY_RAW.empty or GLOBAL_ADJ_FACTOR.empty or not GLOBAL_QFQ_BASE_FACTORS:
        return pd.DataFrame()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¯¥è‚¡ç¥¨çš„æ•°æ®
    if ts_code not in GLOBAL_QFQ_BASE_FACTORS:
        return pd.DataFrame()
    
    latest_adj_factor = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, np.nan)
    if pd.isna(latest_adj_factor) or latest_adj_factor < 1e-9:
        return pd.DataFrame()
    
    try:
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        start_date_dt = pd.to_datetime(start_date, format='%Y%m%d')
        end_date_dt = pd.to_datetime(end_date, format='%Y%m%d')
        
        # åˆ‡ç‰‡æ•°æ®
        daily_df_full = GLOBAL_DAILY_RAW.loc[ts_code]
        adj_factor_series_full = GLOBAL_ADJ_FACTOR.loc[ts_code]['adj_factor']
        
        # ç­›é€‰æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
        daily_df = daily_df_full.loc[(daily_df_full.index >= start_date_dt) & 
                                     (daily_df_full.index <= end_date_dt)]
        adj_factor_series = adj_factor_series_full.loc[(adj_factor_series_full.index >= start_date_dt) & 
                                                       (adj_factor_series_full.index <= end_date_dt)]
        
    except KeyError:
        return pd.DataFrame()
    except Exception as e:
        return pd.DataFrame()
    
    if daily_df.empty or adj_factor_series.empty: 
        return pd.DataFrame()
    
    # åˆå¹¶åŸå§‹ä»·æ ¼å’Œå¤æƒå› å­
    df = daily_df.merge(adj_factor_series.rename('adj_factor'), 
                        left_index=True, right_index=True, how='left')
    df = df.dropna(subset=['adj_factor'])
    if df.empty: 
        return pd.DataFrame()
    
    # å¤æƒè®¡ç®—é€»è¾‘
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns:
            # QFQ Price = Raw Price * (Adj Factor / Global Base Factor)
            df[col + '_qfq'] = df[col] * df['adj_factor'] / latest_adj_factor
    
    # ä½¿ç”¨å¤æƒåçš„ä»·æ ¼
    for col in ['open', 'high', 'low', 'close']:
        if col + '_qfq' in df.columns:
            df[col] = df[col + '_qfq']
    
    return df[['open', 'high', 'low', 'close', 'vol']].copy()

# ----------------------------------------------------------------------
# æ ¸å¿ƒå‡½æ•°ï¼šget_future_prices
# ----------------------------------------------------------------------
def get_future_prices(ts_code, selection_date, d0_qfq_close, days_ahead=[1, 3, 5]):
    """è·å–æœªæ¥ä»·æ ¼"""
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    start_date_future = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_date_future = (d0 + timedelta(days=15)).strftime("%Y%m%d")
    
    # è·å–æœªæ¥æ•°æ®
    hist = get_qfq_data_optimized(ts_code, start_date=start_date_future, end_date=end_date_future)
    if hist.empty or 'close' not in hist.columns:
        results = {}
        for n in days_ahead: 
            results[f'Return_D{n}'] = np.nan
        return results
    
    hist['close'] = pd.to_numeric(hist['close'], errors='coerce')
    hist = hist.dropna(subset=['close'])
    hist = hist.reset_index(drop=True)
    
    results = {}
    for n in days_ahead:
        col_name = f'Return_D{n}'
        
        if pd.notna(d0_qfq_close) and d0_qfq_close > 1e-9:
            if len(hist) >= n:
                future_price = hist.iloc[n-1]['close']
                results[col_name] = (future_price / d0_qfq_close - 1) * 100
            else:
                results[col_name] = np.nan
        else:
            results[col_name] = np.nan
    
    return results

# ----------------------------------------------------------------------
# â­ï¸ V15.1 æ–°å¢ï¼šå¢å¼ºç‰ˆæŒ‡æ ‡è®¡ç®—å‡½æ•°ï¼ˆå‘é‡åŒ–ä¼˜åŒ–ï¼‰
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*6, show_spinner=False)
def compute_indicators_batch(ts_code, end_date):
    """å¢å¼ºç‰ˆæŒ‡æ ‡è®¡ç®— - å‘é‡åŒ–ä¼˜åŒ–"""
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=90)).strftime("%Y%m%d")
    
    # è·å– QFQ æ•°æ®
    df = get_qfq_data_optimized(ts_code, start_date=start_date, end_date=end_date)
    
    res = {}
    if df.empty or 'close' not in df.columns: 
        return res
    
    # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    df['high'] = pd.to_numeric(df['high'], errors='coerce')
    df['low'] = pd.to_numeric(df['low'], errors='coerce')
    df['vol'] = pd.to_numeric(df['vol'], errors='coerce')
    
    close = df['close'].dropna()
    high = df['high'].dropna()
    low = df['low'].dropna()
    vol = df['vol'].dropna()
    
    if len(close) < 20:  # æœ€å°‘éœ€è¦20å¤©æ•°æ®
        return res
    
    res['last_close'] = close.iloc[-1]
    
    # 1. åŠ¨é‡å› å­ (20æ—¥æ¶¨å¹…)
    if len(close) >= 20:
        res['momentum_20d'] = (close.iloc[-1] / close.iloc[-20] - 1) * 100 if close.iloc[-20] > 0 else 0
    
    # 2. è¶‹åŠ¿å› å­ (å‡çº¿æ’åˆ—)
    if len(close) >= 20:
        ma5 = close.rolling(5).mean()
        ma10 = close.rolling(10).mean()
        ma20 = close.rolling(20).mean()
        
        # å‡çº¿å¤šå¤´æ’åˆ—å¾—åˆ†
        trend_score = 0
        if len(ma5) > 0 and len(ma10) > 0 and ma5.iloc[-1] > ma10.iloc[-1]: 
            trend_score += 1
        if len(ma10) > 0 and len(ma20) > 0 and ma10.iloc[-1] > ma20.iloc[-1]: 
            trend_score += 1
        if len(close) > 0 and len(ma5) > 0 and close.iloc[-1] > ma5.iloc[-1]: 
            trend_score += 1
        
        res['trend_score'] = (trend_score / 3) * 100
    
    # 3. é‡ä»·å…³ç³»
    if len(vol) >= 5:
        # é‡æ¯”ï¼šå½“æ—¥æˆäº¤é‡/5æ—¥å‡é‡
        avg_vol_5d = vol.rolling(5).mean().iloc[-1] if len(vol) >= 5 else 0
        if avg_vol_5d > 0:
            res['volume_ratio'] = vol.iloc[-1] / avg_vol_5d
        else:
            res['volume_ratio'] = 1
    
    # 4. çªç ´å› å­ (åˆ›20æ—¥æ–°é«˜)
    if len(high) >= 20:
        highest_20d = high.tail(20).max()
        current_high = high.iloc[-1]
        res['breakout_score'] = 100 if current_high >= highest_20d else 0
    
    # 5. ä½ç½®å› å­ (60æ—¥ä½ç½®)
    if len(df) >= 60:
        hist_60 = df.tail(60)
        if not hist_60.empty and 'low' in hist_60.columns and 'high' in hist_60.columns:
            min_low = hist_60['low'].min()
            max_high = hist_60['high'].max()
            current_close = hist_60['close'].iloc[-1]
            
            if max_high > min_low:
                res['position_60d'] = (current_close - min_low) / (max_high - min_low) * 100
            else:
                res['position_60d'] = 50
    
    # 6. æ³¢åŠ¨ç‡ (20æ—¥å¹´åŒ–æ³¢åŠ¨ç‡)
    if len(close) >= 20:
        returns = close.pct_change().dropna()
        if len(returns) >= 20:
            res['volatility_20d'] = returns.tail(20).std() * np.sqrt(252) * 100
    
    # è®¾ç½®é»˜è®¤å€¼
    for key in ['momentum_20d', 'trend_score', 'volume_ratio', 'breakout_score', 'position_60d', 'volatility_20d']:
        if key not in res:
            res[key] = 0 if key == 'breakout_score' else 50 if key == 'position_60d' else 1 if key == 'volume_ratio' else 0
    
    return res

# ----------------------------------------------------
# ä¾§è¾¹æ å‚æ•° (V15.1 ä¼˜åŒ–ï¼šæ›´å®½æ¾çš„è¿‡æ»¤æ¡ä»¶)
# ----------------------------------------------------
with st.sidebar:
    st.header("æ¨¡å¼ä¸æ—¥æœŸé€‰æ‹©")
    backtest_date_end = st.date_input("é€‰æ‹©**å›æµ‹ç»“æŸæ—¥æœŸ**", value=datetime.now().date(), max_value=datetime.now().date())
    BACKTEST_DAYS = st.number_input("**è‡ªåŠ¨å›æµ‹å¤©æ•° (N)**", value=20, step=1, min_value=1, max_value=50, 
                                     help="ç¨‹åºå°†è‡ªåŠ¨å›æµ‹æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥ã€‚å»ºè®®è®¾ç½®ä¸º 20 å¤©ä»¥è·å¾—æ›´å¯é çš„ç»Ÿè®¡æ•°æ®ã€‚")
    
    st.markdown("---")
    st.header("æ ¸å¿ƒå‚æ•°")
    FINAL_POOL = st.number_input("æœ€ç»ˆå…¥å›´è¯„åˆ†æ•°é‡ (M)", value=100, step=1, min_value=1)
    TOP_DISPLAY = st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=10, step=1)
    TOP_BACKTEST = st.number_input("å›æµ‹åˆ†æ Top K", value=3, step=1, min_value=1)
    
    st.markdown("---")
    st.header("ğŸ›’ V15.1 è¿‡æ»¤æ¡ä»¶")
    MIN_PRICE = st.number_input("æœ€ä½è‚¡ä»· (å…ƒ)", value=5.0, step=0.5, min_value=0.1)
    MAX_PRICE = st.number_input("æœ€é«˜è‚¡ä»· (å…ƒ)", value=500.0, step=5.0, min_value=1.0)
    MIN_TURNOVER = st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=1.0, step=0.5, min_value=0.1)
    MIN_CIRC_MV_BILLIONS = st.number_input("æœ€ä½æµé€šå¸‚å€¼ (äº¿å…ƒ)", value=10.0, step=1.0, min_value=1.0)
    MIN_AMOUNT_MILLIONS = st.number_input("æœ€ä½æˆäº¤é¢ (äº¿å…ƒ)", value=0.3, step=0.1, min_value=0.1)
    MIN_AMOUNT = MIN_AMOUNT_MILLIONS * 100000000
    
    st.markdown("---")
    st.header("âš¡ é€Ÿåº¦ä¼˜åŒ–é€‰é¡¹")
    USE_BATCH_MODE = st.checkbox("å¯ç”¨æ‰¹é‡è®¡ç®—æ¨¡å¼", value=True, 
                                 help="æ‰¹é‡è®¡ç®—æŒ‡æ ‡ï¼Œé€Ÿåº¦æ›´å¿«ä½†å†…å­˜å ç”¨ç¨é«˜")
    MAX_WORKERS = st.slider("å¹¶è¡Œè®¡ç®—çº¿ç¨‹æ•°", min_value=1, max_value=10, value=4, 
                           help="å¹¶è¡Œè®¡ç®—æŒ‡æ ‡ï¼Œæé«˜é€Ÿåº¦")

# ---------------------------
# Token è¾“å…¥ä¸åˆå§‹åŒ–
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# â­ï¸ V15.1 æ ¸å¿ƒå›æµ‹é€»è¾‘å‡½æ•° (æ‰¹é‡ä¼˜åŒ–ç‰ˆ)
# ---------------------------
def run_backtest_for_a_day_fast(last_trade, TOP_BACKTEST, FINAL_POOL, MIN_PRICE, MAX_PRICE, 
                                MIN_TURNOVER, MIN_AMOUNT, MIN_CIRC_MV_BILLIONS):
    """ä¸ºå•ä¸ªäº¤æ˜“æ—¥è¿è¡Œé€‰è‚¡å’Œå›æµ‹é€»è¾‘ - V15.1 é«˜é€Ÿç‰ˆ"""
    global GLOBAL_DAILY_RAW, GLOBAL_STOCK_BASIC
    
    # 1. è·å–å½“æ—¥æ•°æ®
    daily_all = safe_get('daily', trade_date=last_trade)
    if daily_all.empty or 'ts_code' not in daily_all.columns:
        return pd.DataFrame(), f"æ•°æ®ç¼ºå¤±æˆ–æ‹‰å–å¤±è´¥ï¼š{last_trade}"
    
    # 2. è·å–åŸºæœ¬é¢æ•°æ®
    daily_basic = safe_get('daily_basic', trade_date=last_trade, 
                          fields='ts_code,turnover_rate,amount,total_mv,circ_mv')
    
    # 3. è·å–èµ„é‡‘æµæ•°æ®
    moneyflow = safe_get('moneyflow', trade_date=last_trade)
    
    # 4. åˆå¹¶æ•°æ®
    df = daily_all.copy()
    
    # åˆå¹¶è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    if not GLOBAL_STOCK_BASIC.empty:
        df = df.merge(GLOBAL_STOCK_BASIC[['ts_code', 'name', 'list_date']], 
                     on='ts_code', how='left')
    else:
        df['name'] = df['ts_code']
        df['list_date'] = '20000101'
    
    # åˆå¹¶åŸºæœ¬é¢æ•°æ®
    if not daily_basic.empty:
        df = df.merge(daily_basic, on='ts_code', how='left')
    
    # åˆå¹¶èµ„é‡‘æµæ•°æ®
    if not moneyflow.empty:
        moneyflow_cols = ['ts_code']
        for col in ['net_mf', 'net_mf_amount', 'net_mf_in']:
            if col in moneyflow.columns:
                moneyflow_cols.append(col)
                break
        
        if len(moneyflow_cols) > 1:
            moneyflow_clean = moneyflow[moneyflow_cols].rename(columns={moneyflow_cols[1]: 'net_mf'})
            df = df.merge(moneyflow_clean, on='ts_code', how='left')
    
    # 5. æ•°æ®æ¸…æ´—å’Œè½¬æ¢
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    df['turnover_rate'] = pd.to_numeric(df.get('turnover_rate', 0), errors='coerce').fillna(0)
    df['amount'] = pd.to_numeric(df.get('amount', 0), errors='coerce').fillna(0) * 1000  # è½¬æ¢ä¸ºä¸‡å…ƒ
    df['circ_mv'] = pd.to_numeric(df.get('circ_mv', 0), errors='coerce').fillna(0)
    df['circ_mv_billion'] = df['circ_mv'] / 10000  # è½¬æ¢ä¸ºäº¿å…ƒ
    df['net_mf'] = pd.to_numeric(df.get('net_mf', 0), errors='coerce').fillna(0)
    df['name'] = df['name'].fillna('').astype(str)
    
    # 6. ç¡¬æ€§æ¡ä»¶è¿‡æ»¤
    # è¿‡æ»¤STè‚¡/é€€å¸‚è‚¡
    mask_st = df['name'].str.contains('ST|é€€', case=False, na=False)
    df = df[~mask_st]
    
    # è¿‡æ»¤åŒ—äº¤æ‰€
    mask_bj = df['ts_code'].str.startswith('92')
    df = df[~mask_bj]
    
    # è¿‡æ»¤æ–°è‚¡ï¼ˆä¸Šå¸‚120å¤©ä»¥ä¸Šï¼‰
    TODAY = datetime.strptime(last_trade, "%Y%m%d")
    df['list_date_dt'] = pd.to_datetime(df['list_date'], format='%Y%m%d', errors='coerce')
    df['days_listed'] = (TODAY - df['list_date_dt']).dt.days
    df = df[df['days_listed'] >= 120]
    
    # è¿‡æ»¤ä»·æ ¼èŒƒå›´
    df = df[(df['close'] >= MIN_PRICE) & (df['close'] <= MAX_PRICE)]
    
    # è¿‡æ»¤æµé€šå¸‚å€¼
    df = df[df['circ_mv_billion'] >= MIN_CIRC_MV_BILLIONS]
    
    # è¿‡æ»¤æ¢æ‰‹ç‡
    df = df[df['turnover_rate'] >= MIN_TURNOVER]
    
    # è¿‡æ»¤æˆäº¤é¢
    df = df[df['amount'] * 1000 >= MIN_AMOUNT]
    
    if df.empty:
        return pd.DataFrame(), f"ç¡¬æ€§è¿‡æ»¤åæ— è‚¡ç¥¨ï¼š{last_trade}"
    
    # 7. å¹¶è¡Œè®¡ç®—æŒ‡æ ‡ï¼ˆåˆ©ç”¨é«˜ç§¯åˆ†æƒé™ï¼‰
    st.info(f"ğŸ“Š æ­£åœ¨å¹¶è¡Œè®¡ç®— {len(df)} åªè‚¡ç¥¨çš„æŒ‡æ ‡...")
    
    # å‡†å¤‡æ•°æ®
    stock_list = df['ts_code'].tolist()
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè®¡ç®—
    indicators_dict = {}
    
    if USE_BATCH_MODE and MAX_WORKERS > 1:
        # å¹¶è¡Œè®¡ç®—
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_code = {
                executor.submit(compute_indicators_batch, ts_code, last_trade): ts_code 
                for ts_code in stock_list
            }
            
            progress_text = st.empty()
            completed = 0
            total = len(stock_list)
            
            for future in as_completed(future_to_code):
                ts_code = future_to_code[future]
                try:
                    indicators = future.result()
                    if indicators and 'last_close' in indicators:
                        indicators_dict[ts_code] = indicators
                except Exception:
                    pass
                
                completed += 1
                if completed % 50 == 0:
                    progress_text.text(f"æŒ‡æ ‡è®¡ç®—è¿›åº¦: {completed}/{total} ({completed/total*100:.1f}%)")
            
            progress_text.empty()
    else:
        # ä¸²è¡Œè®¡ç®—
        progress_bar = st.progress(0, text="è®¡ç®—æŒ‡æ ‡ä¸­...")
        for i, ts_code in enumerate(stock_list):
            indicators = compute_indicators_batch(ts_code, last_trade)
            if indicators and 'last_close' in indicators:
                indicators_dict[ts_code] = indicators
            
            if i % 10 == 0:
                progress_bar.progress((i + 1) / len(stock_list), 
                                     text=f"è®¡ç®—æŒ‡æ ‡: {i+1}/{len(stock_list)}")
        
        progress_bar.empty()
    
    # 8. åˆå¹¶æŒ‡æ ‡æ•°æ®
    indicator_data = []
    for ts_code, indicators in indicators_dict.items():
        if ts_code in df['ts_code'].values:
            row_data = {
                'ts_code': ts_code,
                'momentum_20d': indicators.get('momentum_20d', 0),
                'trend_score': indicators.get('trend_score', 0),
                'volume_ratio': indicators.get('volume_ratio', 1),
                'breakout_score': indicators.get('breakout_score', 0),
                'position_60d': indicators.get('position_60d', 50),
                'volatility_20d': indicators.get('volatility_20d', 30),
                'd0_qfq_close': indicators.get('last_close', np.nan)
            }
            indicator_data.append(row_data)
    
    if not indicator_data:
        return pd.DataFrame(), f"æŒ‡æ ‡è®¡ç®—åæ— æœ‰æ•ˆè‚¡ç¥¨ï¼š{last_trade}"
    
    indicator_df = pd.DataFrame(indicator_data)
    df = df.merge(indicator_df, on='ts_code', how='inner')
    
    # 9. ç­›é€‰å†³èµ›åå•
    # æŒ‰åŠ¨é‡ç­›é€‰å‰60%
    limit_momentum = int(FINAL_POOL * 0.6)
    df_momentum = df.sort_values('momentum_20d', ascending=False).head(limit_momentum).copy()
    
    # æŒ‰è¶‹åŠ¿ç­›é€‰å‰©ä½™çš„40%
    existing_codes = set(df_momentum['ts_code'])
    df_trend = df[~df['ts_code'].isin(existing_codes)].sort_values('trend_score', ascending=False).head(FINAL_POOL - limit_momentum).copy()
    
    final_candidates = pd.concat([df_momentum, df_trend]).reset_index(drop=True)
    
    # 10. è®¡ç®—æœªæ¥æ”¶ç›Š
    records = []
    
    for _, row in final_candidates.iterrows():
        ts_code = row['ts_code']
        d0_qfq_close = row['d0_qfq_close']
        
        if pd.notna(d0_qfq_close) and d0_qfq_close > 1e-9:
            future_returns = get_future_prices(ts_code, last_trade, d0_qfq_close)
            
            rec = {
                'ts_code': ts_code,
                'name': row.get('name', ts_code),
                'Close': row['close'],
                'Circ_MV (äº¿)': row['circ_mv_billion'],
                'Pct_Chg (%)': row.get('pct_chg', 0),
                'turnover': row['turnover_rate'],
                'net_mf': row['net_mf'],
                'momentum_20d': row['momentum_20d'],
                'trend_score': row['trend_score'],
                'volume_ratio': row['volume_ratio'],
                'breakout_score': row['breakout_score'],
                'position_60d': row['position_60d'],
                'volatility_20d': row['volatility_20d'],
                'Return_D1 (%)': future_returns.get('Return_D1', np.nan),
                'Return_D3 (%)': future_returns.get('Return_D3', np.nan),
                'Return_D5 (%)': future_returns.get('Return_D5', np.nan),
            }
            
            records.append(rec)
    
    if not records:
        return pd.DataFrame(), f"æ— æœ‰æ•ˆæœªæ¥æ”¶ç›Šæ•°æ®ï¼š{last_trade}"
    
    fdf = pd.DataFrame(records)
    
    # 11. è¯„åˆ†è®¡ç®—
    def normalize(series):
        if series.empty or series.max() == series.min():
            return pd.Series([0.5] * len(series), index=series.index)
        return (series - series.min()) / (series.max() - series.min() + 1e-9)
    
    # å½’ä¸€åŒ–å„å› å­
    fdf['s_momentum'] = normalize(fdf['momentum_20d'])
    fdf['s_trend'] = normalize(fdf['trend_score'])
    
    # é‡æ¯”å¾—åˆ†ï¼š1.5-3.0ä¸ºæœ€ä½³åŒºé—´
    fdf['s_volume'] = np.where(
        (fdf['volume_ratio'] >= 1.5) & (fdf['volume_ratio'] <= 3.0),
        1.0,
        np.where(
            fdf['volume_ratio'] < 1.5,
            fdf['volume_ratio'] / 1.5,
            3.0 / fdf['volume_ratio']
        )
    )
    
    fdf['s_breakout'] = fdf['breakout_score'] / 100
    
    # ä½ç½®å¾—åˆ†ï¼š40-70åˆ†æœ€å¥½
    position_score = np.where(
        (fdf['position_60d'] >= 40) & (fdf['position_60d'] <= 70),
        1.0,
        np.where(
            fdf['position_60d'] < 40,
            fdf['position_60d'] / 40,
            (100 - fdf['position_60d']) / 30
        )
    )
    fdf['s_position'] = position_score
    
    # æ³¢åŠ¨ç‡å¾—åˆ†ï¼šè¶Šä½è¶Šå¥½
    fdf['s_volatility'] = 1 - normalize(fdf['volatility_20d'].clip(upper=100))
    
    # V15.1 ç­–ç•¥æƒé‡
    w_momentum = 0.40
    w_trend = 0.25
    w_volume = 0.15
    w_breakout = 0.10
    w_defensive = 0.10
    
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    score = (
        fdf['s_momentum'].fillna(0.5) * w_momentum +
        fdf['s_trend'].fillna(0.5) * w_trend +
        fdf['s_volume'].fillna(0.5) * w_volume +
        fdf['s_breakout'].fillna(0) * w_breakout +
        fdf['s_position'].fillna(0.5) * 0.05 +
        fdf['s_volatility'].fillna(0.5) * 0.05
    )
    
    fdf['ç»¼åˆè¯„åˆ†'] = score * 100
    fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
    fdf.index += 1
    
    return fdf.head(TOP_BACKTEST).copy(), None

# ---------------------------
# ä¸»è¿è¡Œå—
# ---------------------------
if st.button(f"ğŸš€ å¼€å§‹ {BACKTEST_DAYS} æ—¥è‡ªåŠ¨å›æµ‹ (V15.1 é«˜é€Ÿç‰ˆ)"):
    
    # æ£€æŸ¥Tokenæ˜¯å¦æœ‰æ•ˆ
    try:
        test_data = pro.trade_cal(exchange='', start_date='20240101', end_date='20240110')
        if test_data.empty:
            st.error("Token æ— æ•ˆæˆ–æƒé™ä¸è¶³ï¼Œè¯·æ£€æŸ¥ Tokenã€‚")
            st.stop()
    except Exception as e:
        st.error(f"Token éªŒè¯å¤±è´¥: {e}")
        st.stop()
    
    st.success("âœ… Token éªŒè¯é€šè¿‡ï¼å¼€å§‹æ•°æ®åŠ è½½...")
    
    # è·å–äº¤æ˜“æ—¥åˆ—è¡¨
    trade_days_str = get_trade_days(backtest_date_end.strftime("%Y%m%d"), int(BACKTEST_DAYS))
    if not trade_days_str:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥æ—¥æœŸæˆ– Tokenã€‚")
        st.stop()
    
    # æ‰¹é‡åŠ è½½å†å²æ•°æ®
    start_time = time.time()
    preload_success = get_all_historical_data_batch(trade_days_str)
    load_time = time.time() - start_time
    
    if not preload_success:
        st.error("âŒ å†å²æ•°æ®é¢„åŠ è½½å¤±è´¥ï¼Œå›æµ‹æ— æ³•è¿›è¡Œã€‚")
        st.stop()
    
    st.success(f"âœ… å†å²æ•°æ®åŠ è½½å®Œæˆï¼è€—æ—¶: {load_time:.1f} ç§’")
    
    # å¼€å§‹å›æµ‹
    st.header(f"ğŸ“ˆ æ­£åœ¨è¿›è¡Œ {BACKTEST_DAYS} ä¸ªäº¤æ˜“æ—¥çš„å›æµ‹ (V15.1 é«˜é€Ÿç‰ˆ)...")
    
    results_list = []
    total_days = len(trade_days_str)
    
    progress_bar = st.progress(0, text="å›æµ‹è¿›åº¦")
    status_text = st.empty()
    
    start_reback_time = time.time()
    
    for i, trade_date in enumerate(trade_days_str):
        status_text.text(f"ğŸš€ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{total_days} ä¸ªäº¤æ˜“æ—¥ï¼š{trade_date}")
        
        daily_result_df, error = run_backtest_for_a_day_fast(
            trade_date, int(TOP_BACKTEST), int(FINAL_POOL), 
            float(MIN_PRICE), float(MAX_PRICE), float(MIN_TURNOVER), 
            float(MIN_AMOUNT), float(MIN_CIRC_MV_BILLIONS)
        )
        
        if error:
            st.warning(f"{error}")
        elif not daily_result_df.empty:
            daily_result_df['Trade_Date'] = trade_date
            results_list.append(daily_result_df)
        
        progress_bar.progress((i + 1) / total_days)
    
    reback_time = time.time() - start_reback_time
    total_time = time.time() - start_time
    
    progress_bar.empty()
    status_text.text(f"âœ… å›æµ‹å®Œæˆï¼æ€»è€—æ—¶: {total_time:.1f} ç§’ (æ•°æ®åŠ è½½: {load_time:.1f}ç§’, å›æµ‹è®¡ç®—: {reback_time:.1f}ç§’)")
    
    if not results_list:
        st.error("æ‰€æœ‰äº¤æ˜“æ—¥çš„å›æµ‹å‡å¤±è´¥æˆ–æ— ç»“æœã€‚")
        st.stop()
    
    all_results = pd.concat(results_list, ignore_index=True)
    
    # æ˜¾ç¤ºå›æµ‹ç»“æœ
    st.header(f"ğŸ“Š æœ€ç»ˆå¹³å‡å›æµ‹ç»“æœ (Top {TOP_BACKTEST}ï¼Œå…± {len(all_results['Trade_Date'].unique())} ä¸ªæœ‰æ•ˆäº¤æ˜“æ—¥)")
    
    # æ˜¾ç¤ºå› å­ç»Ÿè®¡
    st.subheader("ğŸ“ˆ é€‰è‚¡å› å­ç»Ÿè®¡")
    factor_cols = ['momentum_20d', 'trend_score', 'volume_ratio', 'breakout_score', 'position_60d', 'volatility_20d']
    
    factor_stats = []
    for col in factor_cols:
        if col in all_results.columns:
            factor_stats.append({
                'å› å­': col,
                'å‡å€¼': all_results[col].mean(),
                'ä¸­ä½æ•°': all_results[col].median(),
                'æ ‡å‡†å·®': all_results[col].std(),
                'æœ€å°å€¼': all_results[col].min(),
                'æœ€å¤§å€¼': all_results[col].max()
            })
    
    if factor_stats:
        factor_df = pd.DataFrame(factor_stats)
        st.dataframe(factor_df.round(2), use_container_width=True)
    
    # æ˜¾ç¤ºæ”¶ç›Šç»Ÿè®¡
    st.subheader("ğŸ’° æ”¶ç›Šç»Ÿè®¡")
    
    for n in [1, 3, 5]:
        col = f'Return_D{n} (%)'
        
        if col in all_results.columns:
            valid_data = all_results.dropna(subset=[col])
            
            if not valid_data.empty:
                avg_return = valid_data[col].mean()
                hit_rate = (valid_data[col] > 0).mean() * 100
                median_return = valid_data[col].median()
                std_return = valid_data[col].std()
                total_count = len(valid_data)
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric(f"D+{n} å¹³å‡æ”¶ç›Š", f"{avg_return:.2f}%")
                with col2:
                    st.metric(f"D+{n} èƒœç‡", f"{hit_rate:.1f}%")
                with col3:
                    st.metric(f"D+{n} ä¸­ä½æ•°", f"{median_return:.2f}%")
                with col4:
                    st.metric(f"D+{n} æ ·æœ¬æ•°", total_count)
                
                # æ˜¾ç¤ºåˆ†å¸ƒä¿¡æ¯
                with st.expander(f"D+{n} è¯¦ç»†åˆ†å¸ƒ"):
                    st.write(f"æ ‡å‡†å·®: {std_return:.2f}%")
                    st.write(f"æœ€å°å€¼: {valid_data[col].min():.2f}%")
                    st.write(f"æœ€å¤§å€¼: {valid_data[col].max():.2f}%")
                    st.write(f"æ­£æ”¶ç›Šæ•°é‡: {(valid_data[col] > 0).sum()}")
                    st.write(f"è´Ÿæ”¶ç›Šæ•°é‡: {(valid_data[col] < 0).sum()}")
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    st.header("ğŸ“‹ æ¯æ—¥å›æµ‹è¯¦æƒ…")
    
    display_cols = ['Trade_Date', 'name', 'ts_code', 'ç»¼åˆè¯„åˆ†', 'Close', 
                   'Pct_Chg (%)', 'Circ_MV (äº¿)', 'momentum_20d', 'trend_score',
                   'Return_D1 (%)', 'Return_D3 (%)', 'Return_D5 (%)']
    
    available_cols = [col for col in display_cols if col in all_results.columns]
    
    st.dataframe(
        all_results[available_cols].sort_values('Trade_Date', ascending=False),
        use_container_width=True,
        column_config={
            'momentum_20d': st.column_config.NumberColumn(format="%.1f"),
            'trend_score': st.column_config.NumberColumn(format="%.1f"),
            'Return_D1 (%)': st.column_config.NumberColumn(format="%.2f"),
            'Return_D3 (%)': st.column_config.NumberColumn(format="%.2f"),
            'Return_D5 (%)': st.column_config.NumberColumn(format="%.2f"),
        }
    )
    
    # æ€§èƒ½ç»Ÿè®¡
    st.subheader("âš¡ æ€§èƒ½ç»Ÿè®¡")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»è€—æ—¶", f"{total_time:.1f}ç§’")
    with col2:
        st.metric("æ—¥å‡è€—æ—¶", f"{total_time/len(trade_days_str):.1f}ç§’")
    with col3:
        st.metric("é€Ÿåº¦æå‡", f"{(21*60/total_time):.1f}å€" if total_time > 0 else "N/A")
