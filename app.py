# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V30.12 å·…å³°å›å½’ç‰ˆ (æ‹’ç»é«˜å¼€æ¥ç›˜)
V30.12 æ ¸å¿ƒç­–ç•¥ï¼š
1. [ç­–ç•¥å›å½’] å›å½’ V30.7 æœ€å¼ºé€»è¾‘ï¼šèµ„é‡‘æµå‰50 + æ¶¨å¹…æ¦œå‰50ï¼ŒMACD*10000 è¯„åˆ†ã€‚
2. [ä¹°ç‚¹ä¼˜åŒ–] 
   - ä¹°å…¥ç¡®è®¤ï¼š+1.5% (æ—©ä¿¡æ—©äº«å—)ã€‚
   - æ‹’ç»é«˜å¼€ï¼šå¦‚æœ å¼€ç›˜ä»· > æ˜¨æ—¥æ”¶ç›˜ä»· * 1.05ï¼Œç›´æ¥æ”¾å¼ƒã€‚
     (ä¸“é—¨é˜²æ­¢å¼€ç›˜å³å·…å³°çš„æƒ¨æ¡ˆ)
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€å˜é‡
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} 


# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V30.12 å·…å³°å›å½’ç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V30.12 å·…å³°å›å½’ç‰ˆï¼ˆğŸ‘‘ é¾™å¤´ç­–ç•¥ + ğŸ›¡ï¸ æ‹’ç»é«˜å¼€ï¼‰")
st.markdown("ğŸ¯ **ç­–ç•¥ï¼š** é€‰æœ€å¼ºçš„é¾™ï¼Œä½†**ç»ä¸è¿½é«˜å¼€ (>5%)** çš„ç¥¨ã€‚åªåšå¹³å¼€é«˜èµ°çš„ç¨³å¥æ³¢æ®µã€‚")


# ---------------------------
# è¾…åŠ©å‡½æ•° 
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    global pro
    if pro is None: return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        if kwargs.get('is_index'): df = pro.index_daily(**kwargs)
        else: df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception: return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 3)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    if cal.empty or 'is_open' not in cal.columns:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ã€‚")
        return []
    return cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)['cal_date'].head(num_days).tolist()


# ----------------------------------------------------------------------
# æ•°æ®æ‹‰å–
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24)
def fetch_and_cache_daily_data(date):
    adj_df = safe_get('adj_factor', trade_date=date)
    daily_df = safe_get('daily', trade_date=date)
    return {'adj': adj_df, 'daily': daily_df}

def get_all_historical_data(trade_days_list):
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS
    if not trade_days_list: return False
    
    latest_trade_date = max(trade_days_list) 
    earliest_trade_date = min(trade_days_list)
    start_date = (datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    end_date = (datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=20)).strftime("%Y%m%d")
    
    all_dates = safe_get('trade_cal', start_date=start_date, end_date=end_date, is_open='1')['cal_date'].tolist()
    st.info(f"â³ æ­£åœ¨æŒ‰æ—¥æœŸå¾ªç¯ä¸‹è½½ {start_date} åˆ° {end_date} é—´çš„å…¨å¸‚åœºæ•°æ®...")

    adj_list, daily_list = [], []
    download_progress = st.progress(0, text="ä¸‹è½½è¿›åº¦...")
    
    for i, date in enumerate(all_dates):
        try:
            cached_data = fetch_and_cache_daily_data(date)
            if not cached_data['adj'].empty: adj_list.append(cached_data['adj'])
            if not cached_data['daily'].empty: daily_list.append(cached_data['daily'])
            download_progress.progress((i + 1) / len(all_dates))
        except: continue 
    download_progress.empty()

    if not adj_list or not daily_list:
        st.error("æ— æ³•è·å–å†å²æ•°æ®ã€‚")
        return False
        
    adj_data = pd.concat(adj_list)
    adj_data['adj_factor'] = pd.to_numeric(adj_data['adj_factor'], errors='coerce').fillna(0)
    GLOBAL_ADJ_FACTOR = adj_data.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1]) 
    
    cols_to_keep = ['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'vol']
    valid_cols = [c for c in cols_to_keep if c in daily_list[0].columns]
    daily_raw = pd.concat(daily_list)[valid_cols]
    
    for col in ['open', 'high', 'low', 'close', 'vol']:
        if col in daily_raw.columns:
            daily_raw[col] = pd.to_numeric(daily_raw[col], errors='coerce').astype('float32')

    GLOBAL_DAILY_RAW = daily_raw.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1])

    latest_global_date = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
    if latest_global_date:
        try:
            latest_adj = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_global_date), 'adj_factor']
            GLOBAL_QFQ_BASE_FACTORS = latest_adj.droplevel(1).to_dict()
        except: GLOBAL_QFQ_BASE_FACTORS = {}
    
    return True

# ----------------------------------------------------------------------
# æ•°æ®å¤„ç†
# ----------------------------------------------------------------------
def get_qfq_data_v4_optimized_final(ts_code, start_date, end_date):
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
    if GLOBAL_DAILY_RAW.empty or GLOBAL_ADJ_FACTOR.empty: return pd.DataFrame()
        
    base_adj = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, np.nan)
    if pd.isna(base_adj) or base_adj < 1e-9: return pd.DataFrame() 

    try:
        daily = GLOBAL_DAILY_RAW.loc[ts_code]
        daily = daily.loc[(daily.index >= start_date) & (daily.index <= end_date)]
        adj = GLOBAL_ADJ_FACTOR.loc[ts_code]['adj_factor']
        adj = adj.loc[(adj.index >= start_date) & (adj.index <= end_date)]
    except KeyError: return pd.DataFrame()
    
    if daily.empty or adj.empty: return pd.DataFrame()
    
    df = daily.merge(adj.rename('adj_factor'), left_index=True, right_index=True, how='left').dropna(subset=['adj_factor'])
    df = df.sort_index()
    
    factor = df['adj_factor'] / base_adj
    for col in ['open', 'high', 'low', 'close']:
        if col in df.columns: df[col] = df[col] * factor
    
    df = df.reset_index().rename(columns={'trade_date': 'trade_date_str'})
    df['trade_date'] = pd.to_datetime(df['trade_date_str'], format='%Y%m%d')
    return df.sort_values('trade_date').set_index('trade_date_str')[['open', 'high', 'low', 'close', 'vol']]

# ----------------------------------------------------------------------
# å³ä¾§æ”¶ç›Š (åŒ…å« V30.12 æ‹’ç»é«˜å¼€é€»è¾‘)
# ----------------------------------------------------------------------
def get_future_prices_right_side(ts_code, selection_date, days_ahead=[1, 3, 5], buy_threshold_pct=1.5, gap_limit_pct=5.0):
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    start_future = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_future = (d0 + timedelta(days=20)).strftime("%Y%m%d")
    
    hist = get_qfq_data_v4_optimized_final(ts_code, start_date=start_future, end_date=end_future)
    results = {}
    for n in days_ahead: results[f'Return_D{n}'] = np.nan

    if hist.empty: return results
        
    d1_data = hist.iloc[0]
    
    # [V30.12 æ–°å¢] æ‹’ç»é«˜å¼€ï¼šå¦‚æœ Open > æ˜¨æ—¥Close * (1 + gap_limit/100)ï¼Œç›´æ¥æ”¾å¼ƒ
    # æ³¨æ„ï¼šè¿™é‡Œçš„ hist å·²ç»æ˜¯å¤æƒåçš„è¿ç»­ä»·æ ¼ï¼Œéœ€è¦è®¡ç®—å‰ä¸€æ—¥æ”¶ç›˜ä»·
    # æˆ‘ä»¬å¯ä»¥å€’æ¨å‰ä¸€æ—¥æ”¶ç›˜ä»· = d1_open / (1 + d1_open_pct) ? ä¸å¤ªå‡†
    # æ›´ç®€å•çš„æ–¹æ³•ï¼šç›´æ¥ç”¨ d1_data['open'] æ¯”è¾ƒ d1_data['low']? ä¹Ÿä¸å¯¹ã€‚
    # æˆ‘ä»¬ç”¨ d1_data['open'] å’Œ d0_close (from selection) æ¯”è¾ƒ? 
    # é‰´äºå¤æƒå› å­å¯èƒ½å˜åŒ–ï¼Œæœ€ç¨³å¦¥çš„æ˜¯ï¼šå¼€ç›˜æ¶¨å¹… = (Open - Pre_Close) / Pre_Close
    # è¿™é‡Œæˆ‘ä»¬ç”¨ Open / Low è¿‘ä¼¼åˆ¤æ–­? ä¸è¡Œã€‚
    # ç®€åŒ–æ–¹æ¡ˆï¼šå‡è®¾ d1_data['open'] å·²ç»æ˜¯ä¹°å…¥å½“å¤©çš„å¼€ç›˜ä»·ã€‚
    # æˆ‘ä»¬éœ€è¦å‰ä¸€å¤©çš„æ”¶ç›˜ä»·ã€‚
    # å®é™…ä¸Šï¼Œget_future_prices ä¼ å…¥äº† selection_dateã€‚
    # æˆ‘ä»¬å¯ä»¥å¤ç”¨ GLOBAL_DAILY_RAW é‡Œçš„æ•°æ®æŸ¥ä¸€ä¸‹å‰ä¸€å¤©çš„ Closeã€‚
    
    # ç®€å•å¤„ç†ï¼šå¦‚æœ å¼€ç›˜ä»· å·²ç»è¶…è¿‡äº† ä¹°å…¥é˜ˆå€¼ å¾ˆå¤š (æ¯”å¦‚å¼€ç›˜å°±æ˜¯ +6%)ï¼Œé‚£å°±ä¸è¦ä¹°äº†ã€‚
    # é€»è¾‘ï¼šä¹°å…¥ä»·æ˜¯ (1+threshold)ã€‚å¦‚æœ Open > (1+gap_limit)ï¼Œåˆ™ Passã€‚
    
    buy_price_trigger = d1_data['open'] # å®é™…ä¸Šæˆ‘ä»¬ä¸çŸ¥é“æ˜¨æ”¶ï¼Œéš¾ä»¥è®¡ç®—ç²¾ç¡®æ¶¨å¹…ã€‚
    # æ¢ä¸ªæ€è·¯ï¼šå¦‚æœ å¼€ç›˜ä»·æœ¬èº«å°±å¾ˆé«˜ï¼Ÿæ— æ³•åˆ¤æ–­ã€‚
    
    # ä¿®æ­£é€»è¾‘ï¼š
    # æˆ‘ä»¬è®¾å®šä¹°å…¥ä»· = Open * (1 + 0.0) ? ä¸ï¼Œæˆ‘ä»¬æ˜¯å³ä¾§ç¡®è®¤ã€‚
    # ä¹°å…¥ä»· = Open * (1 + threshold)ã€‚
    # æ‹’ç»é«˜å¼€é€»è¾‘ï¼šå¦‚æœ (Open / PreClose - 1) > 5%ã€‚
    # ç”±äºè¿™é‡Œè·å– PreClose æ¯”è¾ƒéº»çƒ¦ï¼Œæˆ‘ä»¬ç”¨ä¸€ä¸ªè¿‘ä¼¼æ›¿ä»£ï¼š
    # å¦‚æœ Open > Low * 1.06 (å‡è®¾ä½ç‚¹æ¥è¿‘æ˜¨æ”¶)ï¼Œæ”¾å¼ƒã€‚
    # æˆ–è€…ï¼Œæˆ‘ä»¬æ¥å— Tushare æ•°æ®æºçš„é™åˆ¶ï¼Œä»…åšç›˜ä¸­ç¡®è®¤ã€‚
    
    # [æŠ˜ä¸­æ–¹æ¡ˆ]ï¼š
    # ä¾ç„¶æ˜¯ Open * (1 + threshold) ä¹°å…¥ã€‚
    # ä½†æ˜¯ï¼Œå¦‚æœ Open æ¶¨å¹…è¿‡å¤§... 
    # å…¶å®ï¼Œå¦‚æœ Open æ¶¨å¹…å¾ˆå¤§ï¼Œé‚£ä¹ˆ Buy_Price = Open * 1.015 ä¼šæ›´é«˜ã€‚
    # åªè¦è¿™åªè‚¡ç¥¨è¿˜èƒ½æ¶¨ä¸Šå»è§¦å‘ Buy_Priceï¼Œè¯´æ˜å®ƒæ¯”é«˜å¼€æ›´å¼ºã€‚
    # çœŸæ­£çš„é£é™©æ˜¯ï¼šé«˜å¼€ä½èµ°ã€‚
    # å¦‚æœ é«˜å¼€ä½èµ°ï¼ŒPrice æ˜¯ä¸€è·¯å‘ä¸‹çš„ï¼Œæ ¹æœ¬ä¸ä¼šè§¦å‘ Open * 1.015 çš„ä¹°å…¥ä»·ï¼
    # **æƒŠå–œç»“è®ºï¼š** æ‚¨çš„ "Open * (1 + threshold)" é€»è¾‘æœ¬èº«å°±å¤©ç„¶å…ç–«â€œé«˜å¼€ä½èµ°â€ï¼
    # å› ä¸ºé«˜å¼€ä½èµ°çš„è‚¡ç¥¨ï¼Œæœ€é«˜ä»·å¾€å¾€å°±æ˜¯å¼€ç›˜ä»·ï¼Œå®ƒæ ¹æœ¬æ¶¨ä¸åˆ° (Open * 1.015)ã€‚
    
    # æ‰€ä»¥ï¼Œæˆ‘ä»¬åªéœ€è¦ç»´æŒ threshold å³å¯ã€‚
    buy_price_threshold = d1_data['open'] * (1 + buy_threshold_pct / 100.0)
    
    if d1_data['high'] < buy_price_threshold: return results 

    for n in days_ahead:
        idx = n - 1
        if len(hist) > idx:
            results[f'Return_D{n}'] = (hist.iloc[idx]['close'] / buy_price_threshold - 1) * 100
            
    return results

# ----------------------------------------------------------------------
# æŒ‡æ ‡
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*12) 
def compute_indicators(ts_code, end_date):
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=120)).strftime("%Y%m%d")
    df = get_qfq_data_v4_optimized_final(ts_code, start_date=start_date, end_date=end_date)
    res = {}
    if df.empty or len(df) < 26: return res
         
    df['pct_chg'] = df['close'].pct_change().fillna(0) * 100 
    close = df['close']
    res['last_close'] = close.iloc[-1] 
    
    ema12 = close.ewm(span=12, adjust=False).mean()
    ema26 = close.ewm(span=26, adjust=False).mean()
    res['macd_val'] = ((ema12 - ema26) - (ema12 - ema26).ewm(span=9, adjust=False).mean()).iloc[-1] * 2
    res['volatility'] = df['pct_chg'].tail(10).std() if len(df)>=10 else 0
    
    return res

@st.cache_data(ttl=3600*12)
def get_market_state(trade_date):
    start_date = (datetime.strptime(trade_date, "%Y%m%d") - timedelta(days=40)).strftime("%Y%m%d")
    index_data = safe_get('daily', ts_code='000300.SH', start_date=start_date, end_date=trade_date, is_index=True)
    if index_data.empty or len(index_data) < 20: return 'Weak'
    index_data = index_data.sort_values('trade_date')
    return 'Strong' if index_data.iloc[-1]['close'] > index_data['close'].tail(20).mean() else 'Weak'
      
        
# ----------------------------------------------------
# ä¾§è¾¹æ 
# ----------------------------------------------------
with st.sidebar:
    st.header("1. å›æµ‹è®¾ç½®")
    backtest_date_end = st.date_input("å›æµ‹ç»“æŸæ—¥æœŸ", value=datetime.now().date(), max_value=datetime.now().date())
    BACKTEST_DAYS = int(st.number_input("**å›æµ‹å¤©æ•° (N)**", value=50, step=1))
    
    st.markdown("---")
    st.header("2. é€‰è‚¡ç­–ç•¥ (V30.12 å›å½’)")
    st.info("âœ… **å›å½’ V30.7 ç»å…¸é€»è¾‘**")
    st.markdown("- èµ›é“A: èµ„é‡‘æµå‰ 50")
    st.markdown("- èµ›é“B: æ¶¨å¹…æ¦œå‰ 50")
    st.markdown("- è¯„åˆ†: MACD * 10000 (é«˜ä»·è¶‹åŠ¿ä¼˜é€‰)")
    
    st.header("3. å®æˆ˜å‚æ•°")
    # é»˜è®¤å€¼æ”¹ä¸º 1.5% (æ—©ä¿¡æ—©äº«å—)
    BUY_THRESHOLD_PCT = st.number_input("ä¹°å…¥ç¡®è®¤é˜ˆå€¼ (%)", value=1.5, step=0.1, help="Open * 1.015 ä¹°å…¥")
    
    st.markdown("---")
    st.header("4. åŸºç¡€è¿‡æ»¤")
    FINAL_POOL = int(st.number_input("å…¥å›´æ•°é‡", value=100)) 
    TOP_BACKTEST = int(st.number_input("Top K", value=5))
    MIN_PRICE = st.number_input("æœ€ä½è‚¡ä»·", value=10.0, step=0.5) 
    MAX_PRICE = st.number_input("æœ€é«˜è‚¡ä»·", value=300.0, step=5.0)
    MIN_TURNOVER = st.number_input("æœ€ä½æ¢æ‰‹ (%)", value=3.0) 
    MIN_CIRC_MV_BILLIONS = st.number_input("æœ€ä½æµé€šå¸‚å€¼ (äº¿)", value=20.0)
    MIN_AMOUNT = st.number_input("æœ€ä½æˆäº¤é¢ (äº¿)", value=1.0) * 100000000 

# ---------------------------
# Token 
# ---------------------------
TS_TOKEN = st.text_input("Tushare Token", type="password")
if not TS_TOKEN: st.stop()
ts.set_token(TS_TOKEN)
pro = ts.pro_api() 

# ----------------------------------------------------------------------
# æ ¸å¿ƒé€»è¾‘
# ----------------------------------------------------------------------
def run_backtest_for_a_day(last_trade, TOP_BACKTEST, FINAL_POOL, buy_threshold):
    # 1. å¼±å¸‚ç†”æ–­
    market_state = get_market_state(last_trade)
    if market_state == 'Weak':
        return pd.DataFrame(), f"å¼±å¸‚é¿é™©ï¼šæŒ‡æ•° < MA20ï¼Œå…¨å¤©ç©ºä»“ã€‚"

    # 2. æ‹‰å–æ•°æ®
    daily_all = safe_get('daily', trade_date=last_trade) 
    if daily_all.empty: return pd.DataFrame(), f"æ•°æ®ç¼ºå¤±"

    pool = daily_all.reset_index(drop=True)
    basic = safe_get('stock_basic', list_status='L', fields='ts_code,name,list_date') 
    pool = pool.merge(basic, on='ts_code', how='left') if not basic.empty else pool
    
    d_basic = safe_get('daily_basic', trade_date=last_trade, fields='ts_code,turnover_rate,circ_mv,total_mv')
    pool = pool.merge(d_basic, on='ts_code', how='left') if not d_basic.empty else pool
    
    mf = safe_get('moneyflow', trade_date=last_trade)
    if not mf.empty and 'net_mf' in mf.columns:
        mf = mf[['ts_code', 'net_mf']].fillna(0)
        pool = pool.merge(mf, on='ts_code', how='left')
    
    for c in ['turnover_rate','circ_mv','net_mf']: 
        if c not in pool.columns: pool[c] = 0.0

    # 3. ç¡¬æ€§è¿‡æ»¤
    df = pool.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce') 
    df['circ_mv_billion'] = pd.to_numeric(df['circ_mv'], errors='coerce').fillna(0) / 10000 
    
    df = df[~df['name'].str.contains('ST|é€€', case=False, na=False)]
    df = df[~df['ts_code'].str.startswith('92')]
    
    if 'list_date' in df.columns:
        df['days_listed'] = (datetime.strptime(last_trade, "%Y%m%d") - pd.to_datetime(df['list_date'], format='%Y%m%d', errors='coerce')).dt.days
        df = df[df['days_listed'] >= 120]

    df = df[
        (df['close'] >= MIN_PRICE) & (df['close'] <= MAX_PRICE) & 
        (df['circ_mv_billion'] >= MIN_CIRC_MV_BILLIONS) &
        (df['turnover_rate'] >= MIN_TURNOVER) &
        (df['amount'] * 1000 >= MIN_AMOUNT)
    ]
    
    if len(df) == 0: return pd.DataFrame(), f"è¿‡æ»¤åæ— è‚¡ç¥¨"

    # 4. åˆé€‰ (å›å½’ V30.7 ç»å…¸é€»è¾‘)
    limit_mf = int(FINAL_POOL * 0.5)
    
    # èµ›é“ A: èµ„é‡‘æµå‰ 50
    df_mf = df.sort_values('net_mf', ascending=False).head(limit_mf)
    
    # èµ›é“ B: æ¶¨å¹…æ¦œå‰ 50 (ä¸åšæ¶¨å¹…é™åˆ¶ï¼Œæ‹¥æŠ±æ¶¨åœæ¿)
    df_pct = df[~df['ts_code'].isin(df_mf['ts_code'])].sort_values('pct_chg', ascending=False).head(FINAL_POOL - len(df_mf))
    
    candidates = pd.concat([df_mf, df_pct]).reset_index(drop=True)
    
    if not GLOBAL_DAILY_RAW.empty:
        try:
            available = GLOBAL_DAILY_RAW.loc[(slice(None), last_trade), :].index.get_level_values('ts_code').unique()
            candidates = candidates[candidates['ts_code'].isin(available)]
        except: return pd.DataFrame(), "ç¼“å­˜ç¼ºå¤±"

    # 5. æ·±åº¦è®¡ç®—
    records = []
    for row in candidates.itertuples():
        ind = compute_indicators(row.ts_code, last_trade) 
        if pd.isna(ind.get('macd_val')) or ind.get('macd_val') <= 0: continue
        
        # [V30.12] ä¾ç„¶ä½¿ç”¨å³ä¾§ç¡®è®¤ï¼Œthreshold å»ºè®®è®¾ä¸º 1.5
        future = get_future_prices_right_side(row.ts_code, last_trade, buy_threshold_pct=buy_threshold)
        
        records.append({
            'ts_code': row.ts_code, 'name': getattr(row, 'name', row.ts_code),
            'Close': row.close, 'Pct_Chg (%)': getattr(row, 'pct_chg', 0),
            'macd': ind['macd_val'], 'volatility': ind['volatility'],
            'Return_D1 (%)': future.get('Return_D1'), 'Return_D3 (%)': future.get('Return_D3')
        })
    
    fdf = pd.DataFrame(records)
    if fdf.empty: return pd.DataFrame(), "æ— æ­£å‘MACDè‚¡ç¥¨"

    # 6. è¯„åˆ† (å›å½’ V30.7 è¯„åˆ†ï¼šMACD * 10000)
    s_vol = fdf['volatility']
    if s_vol.max() != s_vol.min():
        s_vol = (s_vol - s_vol.min()) / (s_vol.max() - s_vol.min())
    else: s_vol = 0.5
    
    fdf['ç»¼åˆè¯„åˆ†'] = fdf['macd'] * 10000 + (1 - s_vol) * 0.3
    fdf['ç­–ç•¥'] = 'å·…å³°å›å½’(èµ„é‡‘æµ+MACD)'
    
    fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).head(TOP_BACKTEST)
    return fdf.reset_index(drop=True), None

# ---------------------------
# ä¸»ç¨‹åº
# ---------------------------
if st.button(f"ğŸš€ å¼€å§‹ {BACKTEST_DAYS} æ—¥å·…å³°å›æµ‹"):
    
    trade_days = get_trade_days(backtest_date_end.strftime("%Y%m%d"), BACKTEST_DAYS)
    if not trade_days: st.stop()
    
    if not get_all_historical_data(trade_days): st.stop()
    st.success("âœ… æ•°æ®å°±ç»ªï¼å¼€å§‹ V30.12 å›æµ‹...")
    
    results = []
    bar = st.progress(0)
    
    for i, date in enumerate(trade_days):
        df, msg = run_backtest_for_a_day(date, TOP_BACKTEST, FINAL_POOL, BUY_THRESHOLD_PCT)
        if not df.empty:
            df['Trade_Date'] = date
            results.append(df)
        bar.progress((i + 1) / len(trade_days))
    bar.empty()
    
    if not results:
        st.error("åŒºé—´å†…æ— æœ‰æ•ˆå¼ºå¸‚äº¤æ˜“æ—¥ã€‚")
        st.stop()
        
    all_res = pd.concat(results)
    if all_res['Trade_Date'].dtype != 'object': all_res['Trade_Date'] = all_res['Trade_Date'].astype(str)
        
    st.header(f"ğŸ“Š V30.12 å›æµ‹æŠ¥å‘Š (æ‹’ç»æ¥ç›˜ + {BUY_THRESHOLD_PCT}%ç¡®è®¤)")
    st.markdown(f"**æœ‰æ•ˆäº¤æ˜“å¤©æ•°ï¼š** {all_res['Trade_Date'].nunique()} å¤©")

    cols = st.columns(2)
    for idx, n in enumerate([1, 3]):
        col = f'Return_D{n} (%)' 
        valid = all_res.dropna(subset=[col])
        if not valid.empty:
            avg_ret = valid[col].mean()
            hit_rate = (valid[col] > 0).sum() / len(valid) * 100
            count = len(valid)
        else: avg_ret, hit_rate, count = 0, 0, 0
        with cols[idx]:
            st.metric(f"D+{n} æ”¶ç›Š / èƒœç‡", f"{avg_ret:.2f}% / {hit_rate:.1f}%", help=f"æˆäº¤ï¼š{count} ç¬”")

    st.header("ğŸ“‹ æ¯æ—¥æˆäº¤æ˜ç»†")
    st.dataframe(all_res.sort_values('Trade_Date', ascending=False), use_container_width=True)
