# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆBC æ··åˆå¢å¼ºç‰ˆï¼‰Â· æé€Ÿç‰ˆ
è¯´æ˜ï¼š
- ã€æœ¬æ¬¡ä¿®å¤ã€‘**æ ‡é¢˜ç²¾ç®€**ï¼ˆè§£å†³ç§»åŠ¨ç«¯æ˜¾ç¤ºé—®é¢˜ï¼‰ï¼Œ**ä¿®å¤äº†å›æµ‹æ—¶çš„ UnhashableParamError** (ç¼“å­˜é”™è¯¯)ã€‚
- **å›æµ‹æ¨¡å—é›†æˆ**ï¼šå°†é€‰è‚¡æ ¸å¿ƒé€»è¾‘å°è£…ï¼Œç”¨äºè¿è¡Œå½“æ—¥é€‰è‚¡å’Œå†å²å›æµ‹ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings("ignore")

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· 10000æ——èˆ°ï¼ˆBCå¢å¼ºï¼‰Â· æé€Ÿç‰ˆ", layout="wide")

# æ ‡é¢˜ä¼˜åŒ–ï¼šä½¿ç”¨ Markdown H2 å‡å°å­—å·ï¼Œå¹¶ç²¾ç®€åç§°
st.markdown("## é€‰è‚¡ç‹ï¼ˆBC å¢å¼ºæé€Ÿç‰ˆï¼‰")
st.markdown("è¾“å…¥ä½ çš„ Tushare Tokenï¼ˆä»…æœ¬æ¬¡è¿è¡Œä½¿ç”¨ï¼‰ã€‚è‹¥æœ‰æƒé™ç¼ºå¤±ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨é™çº§å¹¶ç»§ç»­è¿è¡Œã€‚")

# ---------------------------
# ä¾§è¾¹æ å‚æ•°ï¼ˆå®æ—¶å¯æ”¹ï¼‰
# ---------------------------
with st.sidebar:
    st.header("å¯è°ƒå‚æ•°ï¼ˆå®æ—¶ï¼‰")
    # [span_0](start_span)Tushare æ¥å£å­—æ®µçš„é»˜è®¤å€¼å‚è€ƒ crjsb.py.txt[span_0](end_span)
    INITIAL_TOP_N = int(st.number_input("åˆç­›ï¼šæ¶¨å¹…æ¦œå–å‰ N", value=1000, step=100))
    FINAL_POOL = int(st.number_input("æ¸…æ´—åå–å‰ M è¿›å…¥è¯„åˆ†", value=500, step=50))
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=30, step=5))
    [span_1](start_span)MIN_PRICE = float(st.number_input("æœ€ä½ä»·æ ¼ (å…ƒ)", value=10.0, step=1.0))[span_1](end_span)
    MAX_PRICE = float(st.number_input("æœ€é«˜ä»·æ ¼ (å…ƒ)", value=200.0, step=10.0))
    MIN_TURNOVER = float(st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=3.0, step=0.5))
    [span_2](start_span)MIN_AMOUNT = float(st.number_input("æœ€ä½æˆäº¤é¢ (å…ƒ)", value=200_000_000.0, step=50_000_000.0))[span_2](end_span)
    [span_3](start_span)VOL_SPIKE_MULT = float(st.number_input("æ”¾é‡å€æ•°é˜ˆå€¼ (vol_last > vol_ma5 * x)", value=1.7, step=0.1))[span_3](end_span)
    [span_4](start_span)VOLATILITY_MAX = float(st.number_input("è¿‡å»10æ—¥æ³¢åŠ¨ std é˜ˆå€¼ (%)", value=8.0, step=0.5))[span_4](end_span)
    [span_5](start_span)HIGH_PCT_THRESHOLD = float(st.number_input("è§†ä¸ºå¤§é˜³çº¿ pct_chg (%)", value=6.0, step=0.5))[span_5](end_span)
    st.markdown("---")
    
    st.header("ğŸ” å›æµ‹è®¾ç½® (T+1 ç®€å•å›æµ‹)")
    BACKTEST_DAYS = int(st.number_input("å›æµ‹ï¼šæœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥", value=10, step=1))
    st.markdown("---")
    st.caption("æç¤ºï¼šä¿å®ˆâ†’é™ä½é˜ˆå€¼ï¼›æ¿€è¿›â†’æé«˜é˜ˆå€¼ã€‚")

# ---------------------------
# Token è¾“å…¥ï¼ˆä¸»åŒºï¼‰
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

# åˆå§‹åŒ– tushare
ts.set_token(TS_TOKEN)
pro = ts.pro_api() # å…¨å±€ pro å¯¹è±¡

# ----------------------------------------------------
# æŒ‰é’®æ§åˆ¶æ¨¡å—
# ----------------------------------------------------
st.subheader("âš¡ è¿è¡Œæ¨¡å¼é€‰æ‹©")
if 'run_selection' not in st.session_state:
    st.session_state['run_selection'] = False
if 'run_backtest' not in st.session_state:
    st.session_state['run_backtest'] = False
    
col1, col2 = st.columns(2)

with col1:
    if st.button("è¿è¡Œå½“æ—¥é€‰è‚¡", use_container_width=True):
        st.session_state['run_selection'] = True
        st.session_state['run_backtest'] = False
        st.rerun()
        
with col2:
    if st.button(f"è¿è¡Œå›æµ‹ (æœ€è¿‘ {BACKTEST_DAYS} æ—¥)", use_container_width=True):
        st.session_state['run_backtest'] = True
        st.session_state['run_selection'] = False
        st.rerun()

st.markdown("---")


# ---------------------------
# [span_6](start_span)å®‰å…¨è°ƒç”¨ & ç¼“å­˜è¾…åŠ© (ä½¿ç”¨å…¨å±€ pro å¯¹è±¡)[span_6](end_span)
# ---------------------------
def safe_get(func, **kwargs):
    """Call API and return DataFrame or empty df on any error."""
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=600)
def find_last_trade_day(max_days=20):
    today = datetime.now().date()
    for i in range(max_days):
        [span_7](start_span)d = today - timedelta(days=i)[span_7](end_span)
        ds = d.strftime("%Y%m%d")
        # ä½¿ç”¨å…¨å±€ pro
        df = safe_get(pro.daily, trade_date=ds)
        if not df.empty:
            return ds
    return None

@st.cache_data(ttl=600)
def get_hist(ts_code, end_date, days=60):
    """è·å–å†å²æ•°æ®ï¼Œä½¿ç”¨å…¨å±€ pro"""
    try:
        [span_8](start_span)start = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=days*2)).strftime("%Y%m%d")[span_8](end_span)
        # ä½¿ç”¨å…¨å±€ pro
        df = safe_get(pro.daily, ts_code=ts_code, start_date=start, end_date=end_date)
        if df.empty:
            return pd.DataFrame()
        df = df.sort_values('trade_date').reset_index(drop=True)
        return df
    except:
        return pd.DataFrame()

def compute_indicators(df):
    """æŒ‡æ ‡è®¡ç®—é€»è¾‘ï¼ˆä¸å˜ï¼‰"""
    res = {}
    if df.empty or len(df) < 3: return res
    [span_9](start_span)close = df['close'].astype(float); high = df['high'].astype(float); low = df['low'].astype(float)[span_9](end_span)
    try: res['last_close'] = close.iloc[-1]
    except: res['last_close'] = np.nan
    for n in (5,10,20):
        if len(close) >= n: res[f'ma{n}'] = close.rolling(window=n).mean().iloc[-1]
        else: res[f'ma{n}'] = np.nan
    if len(close) >= 26:
        [span_10](start_span)ema12 = close.ewm(span=12, adjust=False).mean()[span_10](end_span)
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        macd_val = (diff - dea) * 2
        [span_11](start_span)res['macd'] = macd_val.iloc[-1]; res['diff'] = diff.iloc[-1]; res['dea'] = dea.iloc[-1][span_11](end_span)
    else: res['macd'] = res['diff'] = res['dea'] = np.nan
    n = 9
    if len(close) >= n:
        low_n = low.rolling(window=n).min()
        high_n = high.rolling(window=n).max()
        rsv = (close - low_n) / (high_n - low_n + 1e-9) * 100
        rsv = rsv.fillna(50)
        [span_12](start_span)k = rsv.ewm(alpha=1/3, adjust=False).mean()[span_12](end_span)
        d = k.ewm(alpha=1/3, adjust=False).mean()
        j = 3*k - 2*d
        [span_13](start_span)res['k'] = k.iloc[-1]; res['d'] = d.iloc[-1]; res['j'] = j.iloc[-1][span_13](end_span)
    else: res['k'] = res['d'] = res['j'] = np.nan
    vols = df['vol'].astype(float).tolist()
    if len(vols) >= 6:
        avg_prev5 = np.mean(vols[-6:-1])
        res['vol_ratio'] = vols[-1] / (avg_prev5 + 1e-9)
        res['vol_last'] = vols[-1]; res['vol_ma5'] = avg_prev5
    [span_14](start_span)else: res['vol_ratio'] = res['vol_last'] = res['vol_ma5'] = np.nan[span_14](end_span)
    if len(close) >= 10: res['10d_return'] = close.iloc[-1] / close.iloc[-10] - 1
    else: res['10d_return'] = np.nan
    if 'pct_chg' in df.columns and len(df) >= 4:
        [span_15](start_span)try: res['prev3_sum'] = df['pct_chg'].astype(float).iloc[-4:-1].sum()[span_15](end_span)
        except: res['prev3_sum'] = np.nan
    else: res['prev3_sum'] = np.nan
    try:
        if 'pct_chg' in df.columns and len(df) >= 10:
            res['volatility_10'] = df['pct_chg'].astype(float).tail(10).std()
        [span_16](start_span)else: res['volatility_10'] = np.nan[span_16](end_span)
    except: res['volatility_10'] = np.nan
    return res

def safe_merge_pool(pool_df, other_df, cols):
    """ç¨³å¥åˆå¹¶é€»è¾‘ï¼ˆä¸å˜ï¼‰"""
    pool = pool_df.set_index('ts_code').copy()
    [span_17](start_span)if other_df is None or other_df.empty:[span_17](end_span)
        for c in cols: pool[c] = np.nan
        return pool.reset_index()
    if 'ts_code' not in other_df.columns:
        try: other_df = other_df.reset_index()
        except:
            [span_18](start_span)for c in cols: pool[c] = np.nan[span_18](end_span)
            return pool.reset_index()
    for c in cols:
        if c not in other_df.columns: other_df[c] = np.nan
    try: joined = pool.join(other_df.set_index('ts_code')[cols], how='left')
    except Exception:
        [span_19](start_span)for c in cols: pool[c] = np.nan[span_19](end_span)
        return pool.reset_index()
    for c in cols:
        if c not in joined.columns: joined[c] = np.nan
    return joined.reset_index()

def norm_col(s):
    """å½’ä¸€åŒ–é€»è¾‘ï¼ˆä¸å˜ï¼‰"""
    s = s.fillna(0.0).replace([np.inf,-np.inf], np.nan).fillna(0.0)
    [span_20](start_span)mn = s.min(); mx = s.max()[span_20](end_span)
    if mx - mn < 1e-9: return pd.Series([0.5]*len(s), index=s.index)
    return (s - mn) / (mx - mn)

# ----------------------------------------------------
# æ ¸å¿ƒè¯„åˆ†å‡½æ•° (ç¼“å­˜ï¼Œ**å·²ç§»é™¤ pro_api å‚æ•°**)
# å‚æ•° `params_tuple` å¿…é¡»æ˜¯å¯å“ˆå¸Œçš„å…ƒç»„ï¼Œç”¨äº Streamlit ç¼“å­˜é”®
# ----------------------------------------------------
@st.cache_data(ttl=600)
def run_scoring_for_date(trade_date, params_tuple):
    # å°†å…ƒç»„å‚æ•°è§£åŒ…å›å­—å…¸
    (INITIAL_TOP_N, FINAL_POOL, TOP_DISPLAY, MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, VOL_SPIKE_MULT, VOLATILITY_MAX, HIGH_PCT_THRESHOLD) = params_tuple
    
    params = {
        'INITIAL_TOP_N': INITIAL_TOP_N, 'FINAL_POOL': FINAL_POOL, 'TOP_DISPLAY': TOP_DISPLAY,
        'MIN_PRICE': MIN_PRICE, 'MAX_PRICE': MAX_PRICE, 'MIN_TURNOVER': MIN_TURNOVER,
        'MIN_AMOUNT': MIN_AMOUNT, 'VOL_SPIKE_MULT': VOL_SPIKE_MULT, 'VOLATILITY_MAX': VOLATILITY_MAX,
        'HIGH_PCT_THRESHOLD': HIGH_PCT_THRESHOLD
    }
    
    # 1. æ‹‰å–å½“æ—¥æ¶¨å¹…æ¦œåˆç­›ï¼ˆä½¿ç”¨å…¨å±€ proï¼‰
    daily_all = safe_get(pro.daily, trade_date=trade_date)
    if daily_all.empty: return pd.DataFrame()
    
    daily_all = daily_all.sort_values("pct_chg", ascending=False).reset_index(drop=True)
    [span_21](start_span)pool0 = daily_all.head(int(params['INITIAL_TOP_N'])).copy().reset_index(drop=True)[span_21](end_span)

    # 2. æ‹‰å–å’Œåˆå¹¶é«˜çº§æ¥å£æ•°æ®ï¼ˆä½¿ç”¨å…¨å±€ proï¼‰
    stock_basic = safe_get(pro.stock_basic, list_status='L', fields='ts_code,name,industry,total_mv,circ_mv')
    daily_basic = safe_get(pro.daily_basic, trade_date=trade_date, fields='ts_code,turnover_rate,amount,total_mv,circ_mv')
    mf_raw = safe_get(pro.moneyflow, trade_date=trade_date)
    
    moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])
    if not mf_raw.empty:
        [span_22](start_span)possible = ['net_mf','net_mf_amount','net_mf_in','net_mf_out'][span_22](end_span)
        col = next((c for c in possible if c in mf_raw.columns), None)
        if col: moneyflow = mf_raw[['ts_code', col]].rename(columns={col:'net_mf'}).fillna(0)
    
    # merge stock_basic
    if not stock_basic.empty:
        keep = [c for c in ['ts_code','name','industry','total_mv','circ_mv'] if c in stock_basic.columns]
        try: pool0 = pool0.merge(stock_basic[keep], on='ts_code', how='left')
        [span_23](start_span)except Exception: pool0['name'] = pool0['ts_code']; pool0['industry'] = ''[span_23](end_span)
    else: pool0['name'] = pool0['ts_code']; pool0['industry'] = ''
        
    pool_merged = safe_merge_pool(pool0, daily_basic, ['turnover_rate','amount','total_mv','circ_mv'])
    
    if moneyflow.empty: moneyflow = pd.DataFrame({'ts_code': pool_merged['ts_code'].tolist(), 'net_mf': [0.0]*len(pool_merged)})
    try: pool_merged = pool_merged.set_index('ts_code').join(moneyflow.set_index('ts_code'), how='left').reset_index()
    except: pool_merged['net_mf'] = 0.0
    pool_merged['net_mf'] = pool_merged['net_mf'].fillna(0.0)
    
    # 3. [span_24](start_span)æ¸…æ´—[span_24](end_span)
    clean_list = []
    
    MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, HIGH_PCT_THRESHOLD = \
        params['MIN_PRICE'], params['MAX_PRICE'], params['MIN_TURNOVER'], params['MIN_AMOUNT'], params['HIGH_PCT_THRESHOLD']
        
    for r in pool_merged.itertuples():
        ts_code = getattr(r, 'ts_code')
        vol = getattr(r, 'vol', np.nan)
        close = getattr(r, 'close', np.nan)
        open_p = getattr(r, 'open', np.nan)
        [span_25](start_span)pre_close = getattr(r, 'pre_close', np.nan)[span_25](end_span)
        pct = getattr(r, 'pct_chg', np.nan)
        amount = getattr(r, 'amount', np.nan)
        turnover = getattr(r, 'turnover_rate', np.nan)
        total_mv = getattr(r, 'total_mv', np.nan)
        name = getattr(r, 'name', ts_code)

        [span_26](start_span)if (pd.isna(vol) or vol == 0) and (pd.isna(amount) or amount == 0): continue[span_26](end_span)
        [span_27](start_span)if pd.isna(close) or (close < MIN_PRICE) or (close > MAX_PRICE): continue[span_27](end_span)
        [span_28](start_span)if isinstance(name, str) and (('ST' in name.upper()) or ('é€€' in name)): continue[span_28](end_span)
        try:
            [span_29](start_span)high = getattr(r, 'high', np.nan); low = getattr(r, 'low', np.nan)[span_29](end_span)
            [span_30](start_span)if (not pd.isna(open_p) and not pd.isna(high) and not pd.isna(low) and not pd.isna(pre_close)) and (open_p == high == low == pre_close): continue[span_30](end_span)
        except: pass
        try:
            tv = total_mv; tv_yuan = tv * 10000.0 if not pd.isna(tv) and tv > 1e6 else tv;
            [span_31](start_span)if not pd.isna(tv_yuan) and tv_yuan > 2000 * 1e8: continue[span_31](end_span)
        except: pass
        [span_32](start_span)if not pd.isna(turnover) and float(turnover) < MIN_TURNOVER: continue[span_32](end_span)
        if not pd.isna(amount):
            amt = amount;
            if amt > 0 and amt < 1e5: amt = amt * 10000.0
            [span_33](start_span)if amt < MIN_AMOUNT: continue[span_33](end_span)
        [span_34](start_span)if not pd.isna(pct) and float(pct) < 0: continue[span_34](end_span)
        
        clean_list.append(r)
    
    clean_df = pd.DataFrame([dict(zip(r._fields, r)) for r in clean_list])
    if clean_df.empty: return pd.DataFrame()

    score_pool_n = min(int(params['FINAL_POOL']), 300)
    clean_df = clean_df.sort_values('pct_chg', ascending=False).head(score_pool_n).reset_index(drop=True)
    
    # 4. æŒ‡æ ‡è®¡ç®—ä¸è¯„åˆ†
    records = []
    for row in clean_df.itertuples():
        ts_code = getattr(row, 'ts_code'); pct_chg = getattr(row, 'pct_chg', 0.0);
        [span_35](start_span)turnover_rate = getattr(row, 'turnover_rate', np.nan)[span_35](end_span); net_mf = float(getattr(row, 'net_mf', 0.0));
        amount_raw = getattr(row, 'amount', np.nan)
        amount = amount_raw * 10000.0 if not pd.isna(amount_raw) and amount_raw > 0 and amount_raw < 1e5 else amount_raw
        amount = amount if not pd.isna(amount) else 0.0

        hist = get_hist(ts_code, trade_date, days=60)
        ind = compute_indicators(hist)

        vol_ratio, ten_return, macd, k, d, j, vol_last, vol_ma5, prev3_sum, volatility_10, ma20, last_close = \
            ind.get('vol_ratio', np.nan), ind.get('10d_return', np.nan), ind.get('macd', np.nan), \
            ind.get('k', np.nan), ind.get('d', np.nan), ind.get('j', np.nan), \
            [span_36](start_span)ind.get('vol_last', np.nan), ind.get('vol_ma5', np.nan)[span_36](end_span)[span_37](start_span), ind.get('prev3_sum', np.nan)[span_37](end_span), ind.get('volatility_10', np.nan), ind.get('ma20', np.nan), ind.get('last_close', np.nan)

        try: proxy_money = (abs(pct_chg) + 1e-9) * (vol_ratio if not pd.isna(vol_ratio) else 0.0) * (turnover_rate if not pd.isna(turnover_rate) else 0.0)
        except: proxy_money = 0.0

        [span_38](start_span)rec = {'ts_code': ts_code, 'pct_chg': pct_chg, 'turnover_rate': turnover_rate, 'net_mf': net_mf, 'amount': amount[span_38](end_span),
               'vol_ratio': vol_ratio, '10d_return': ten_return, 'macd': macd, 'k': k, 'd': d, 'j': j,
               'vol_last': vol_last, 'vol_ma5': vol_ma5, 'prev3_sum': prev3_sum, 'volatility_10': volatility_10,
               'proxy_money': proxy_money, 'name': getattr(row, 'name', ts_code),
               'last_close': last_close, 'ma20': ma20}
        records.append(rec)

    fdf = pd.DataFrame(records)
    if fdf.empty: return pd.DataFrame()

    # 5. é£é™©è¿‡æ»¤ 
    VOL_SPIKE_MULT, VOLATILITY_MAX, HIGH_PCT_THRESHOLD = params['VOL_SPIKE_MULT'], params['VOLATILITY_MAX'], params['HIGH_PCT_THRESHOLD']
    
    if all(c in fdf.columns for c in ['ma20','last_close','pct_chg']):
        [span_39](start_span)fdf = fdf[~((fdf['last_close'] > fdf['ma20'] * 1.10) & (fdf['pct_chg'] > HIGH_PCT_THRESHOLD))][span_39](end_span)
    if all(c in fdf.columns for c in ['prev3_sum','pct_chg']):
        fdf = fdf[~((fdf['prev3_sum'] < 0) & (fdf['pct_chg'] > HIGH_PCT_THRESHOLD))]
    if all(c in fdf.columns for c in ['vol_last','vol_ma5']):
        [span_40](start_span)fdf = fdf[~((fdf['vol_last'] > (fdf['vol_ma5'] * VOL_SPIKE_MULT)))][span_40](end_span)
    if 'volatility_10' in fdf.columns:
        fdf = fdf[~(fdf['volatility_10'] > VOLATILITY_MAX)]

    if fdf.empty: return pd.DataFrame()

    # 6. RSL & å½’ä¸€åŒ–
    if '10d_return' in fdf.columns:
        try:
            market_mean_10d = fdf['10d_return'].replace([np.inf,-np.inf], np.nan).dropna().mean()
            [span_41](start_span)fdf['rsl'] = fdf['10d_return'] / (market_mean_10d if abs(market_mean_10d) >= 1e-9 else 1e-9)[span_41](end_span)
        except: fdf['rsl'] = 1.0
    else: fdf['rsl'] = 1.0

    fdf['s_pct'] = norm_col(fdf.get('pct_chg', pd.Series([0]*len(fdf))))
    fdf['s_volratio'] = norm_col(fdf.get('vol_ratio', pd.Series([0]*len(fdf))))
    fdf['s_turn'] = norm_col(fdf.get('turnover_rate', pd.Series([0]*len(fdf))))
    fdf['s_money'] = norm_col(fdf.get('net_mf', pd.Series([0]*len(fdf)))) if fdf['net_mf'].abs().sum() > 0 else norm_col(fdf.get('proxy_money', pd.Series([0]*len(fdf))))
    fdf['s_amount'] = norm_col(fdf.get('amount', pd.Series([0]*len(fdf))))
    fdf['s_10d'] = norm_col(fdf.get('10d_return', pd.Series([0]*len(fdf))))
    fdf['s_macd'] = norm_col(fdf.get('macd', pd.Series([0]*len(fdf))))
    fdf['s_rsl'] = norm_col(fdf.get('rsl', pd.Series([0]*len(fdf))))
    fdf['s_volatility'] = 1 - norm_col(fdf.get('volatility_10', pd.Series([0]*len(fdf))))

    # 7. [span_42](start_span)ç»¼åˆè¯„åˆ† (ä½¿ç”¨ crjsb.py.txt ä¸­çš„æƒé‡)[span_42](end_span)
    w_pct, w_volratio, w_turn, w_money, w_10d, w_macd, w_rsl, w_volatility = \
        0.18, 0.18, 0.12, 0.14, 0.12, 0.06, 0.12, 0.08

    fdf['ç»¼åˆè¯„åˆ†'] = (fdf['s_pct'] * w_pct + fdf['s_volratio'] * w_volratio + fdf['s_turn'] * w_turn +
                   fdf['s_money'] * w_money + fdf['s_10d'] * w_10d + fdf['s_macd'] * w_macd +
                   fdf['s_rsl'] * w_rsl + fdf['s_volatility'] * w_volatility)
    
    fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
    return fdf.head(params['TOP_DISPLAY'])


# ----------------------------------------------------
# ç®€æ˜“å›æµ‹æ¨¡å—
# å‚æ•° BACKTEST_DAYS å¿…é¡»ç›´æ¥æ¥è‡ª Streamlit æ§ä»¶çš„åŸå§‹å€¼ï¼Œä»¥é¿å… UnhashableParamError
# ----------------------------------------------------
def run_simple_backtest(days, params_tuple):
    st.subheader("ğŸ“ˆ ç®€æ˜“å†å²å›æµ‹ç»“æœ")
    
    # è·å–äº¤æ˜“æ—¥å†
    trade_dates_df = safe_get(pro.trade_cal, exchange='SSE', is_open='1', end_date=find_last_trade_day(), fields='cal_date')
    if trade_dates_df.empty:
        st.error("æ— æ³•è·å–å†å²äº¤æ˜“æ—¥å†ã€‚")
        return

    trade_dates = trade_dates_df['cal_date'].sort_values(ascending=False).head(days + 1).tolist()
    trade_dates.reverse() # ä»è€åˆ°æ–°

    if len(trade_dates) < 2:
        st.warning("äº¤æ˜“æ—¥ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå›æµ‹ã€‚")
        return

    backtest_results = []
    
    # å°† params_tuple ä¸­çš„ TOP_DISPLAY è®¾ä¸º 1 ç”¨äºå›æµ‹ï¼ˆåªå–ç¬¬ä¸€åï¼‰
    temp_list = list(params_tuple)
    temp_list[2] = 1 # TOP_DISPLAY ç´¢å¼•ä¸º 2
    backtest_params_tuple = tuple(temp_list)

    # ç¡®ä¿è¿›åº¦æ¡åœ¨ç»“æœä¹‹å‰ï¼Œä¸”åœ¨åŒä¸€å®¹å™¨ä¸­
    pbar_container = st.container()
    pbar = pbar_container.progress(0, text="å›æµ‹å¼€å§‹...")
    
    st.markdown(f"**å›æµ‹å‘¨æœŸï¼š** æœ€è¿‘ **{days}** ä¸ªäº¤æ˜“æ—¥ï¼ˆ**{trade_dates[0]}** è‡³ **{trade_dates[-2]}**ï¼‰")
    
    try:
        for i in range(len(trade_dates) - 1):
            select_date = trade_dates[i]
            next_trade_date = trade_dates[i+1]
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.progress((i+1) / (len(trade_dates) - 1), text=f"æ­£åœ¨å›æµ‹ {select_date}...")

            # è°ƒç”¨ç¼“å­˜å‡½æ•°ï¼Œåªä¼ é€’å¯å“ˆå¸Œå‚æ•°
            select_df = run_scoring_for_date(select_date, backtest_params_tuple)
            
            if select_df.empty:
                backtest_results.append({'é€‰è‚¡æ—¥': select_date, 'è‚¡ç¥¨': 'æ— ç¬¦åˆæ¡ä»¶', 'T+1 æ”¶ç›Šç‡': 0.0, 'ä¹°å…¥ä»·': np.nan, 'å–å‡ºä»·': np.nan, 'è¯„åˆ†': np.nan})
                continue

            top_pick = select_df.iloc[0]
            ts_code = top_pick['ts_code']
            
            # è·å– T+1 äº¤æ˜“æ—¥æ•°æ®
            next_day_data = safe_get(pro.daily, ts_code=ts_code, trade_date=next_trade_date)
            
            return_pct = 0.0
            buy_price, sell_price = np.nan, np.nan

            if not next_day_data.empty:
                buy_price = next_day_data.iloc[0]['open']
                sell_price = next_day_data.iloc[0]['close']
                
                if buy_price > 0:
                    return_pct = (sell_price / buy_price) - 1.0

            backtest_results.append({
                'é€‰è‚¡æ—¥': select_date,
                'è‚¡ç¥¨': f"{top_pick.get('name', 'N/A')}({ts_code})",
                'T+1 æ”¶ç›Šç‡': return_pct * 100,
                'ä¹°å…¥ä»· (T+1 å¼€ç›˜)': buy_price,
                'å–å‡ºä»· (T+1 æ”¶ç›˜)': sell_price,
                'è¯„åˆ†': top_pick['ç»¼åˆè¯„åˆ†']
            })
    except Exception as e:
        # æ•è·å›æµ‹è¿‡ç¨‹ä¸­çš„é”™è¯¯ï¼Œå¹¶æ˜¾ç¤º
        st.error(f"å›æµ‹è¿‡ç¨‹ä¸­æ–­ï¼Œå¯èƒ½å‡ºç°ç½‘ç»œæˆ–æ•°æ®æƒé™é—®é¢˜ã€‚é”™è¯¯ä¿¡æ¯ï¼š{e}")
        pbar.empty() # æ¸…é™¤è¿›åº¦æ¡
        return

    # è¿›åº¦æ¡è·‘å®Œ
    pbar.progress(1.0, text="å›æµ‹å®Œæˆã€‚")
    
    results_df = pd.DataFrame(backtest_results)
    results_df['T+1 æ”¶ç›Šç‡'] = results_df['T+1 æ”¶ç›Šç‡'].replace([np.inf, -np.inf], 0.0).fillna(0.0)
    cumulative_return = (results_df['T+1 æ”¶ç›Šç‡'] / 100 + 1).product() - 1
    wins = (results_df['T+1 æ”¶ç›Šç‡'] > 0).sum()
    total_trades = len(results_df)
    win_rate = wins / total_trades if total_trades > 0 else 0

    st.markdown("---")
    st.subheader("ğŸ’¡ æœ€ç»ˆå›æµ‹æŒ‡æ ‡")
    colA, colB, colC = st.columns(3)
    colA.metric("ç´¯è®¡æ”¶ç›Šç‡ (T+1)", f"{cumulative_return*100:.2f}%")
    colB.metric("èƒœç‡", f"{win_rate*100:.2f}%")
    colC.metric("äº¤æ˜“æ¬¡æ•°", f"{total_trades}")
    
    st.subheader("ğŸ“‹ æ¯æ—¥äº¤æ˜“è®°å½•")
    st.dataframe(results_df, use_container_width=True)


# ----------------------------------------------------
# ä¸»ç¨‹åºå…¥å£
# ----------------------------------------------------
last_trade = find_last_trade_day()
if not last_trade:
    st.error("æ— æ³•æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥ï¼Œæ£€æŸ¥ç½‘ç»œæˆ– Token æƒé™ã€‚")
    st.stop()
st.info(f"å‚è€ƒæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}")


# å°†æ‰€æœ‰å‚æ•°æ‰“åŒ…æˆä¸€ä¸ªå¯å“ˆå¸Œçš„å…ƒç»„ï¼Œç”¨äºä¼ é€’ç»™æ ¸å¿ƒå‡½æ•°
params_tuple = (
    INITIAL_TOP_N, FINAL_POOL, TOP_DISPLAY,
    MIN_PRICE, MAX_PRICE, MIN_TURNOVER,
    MIN_AMOUNT, VOL_SPIKE_MULT, VOLATILITY_MAX,
    HIGH_PCT_THRESHOLD
)

# >>>>> æ§åˆ¶é€»è¾‘ <<<<<
if not st.session_state.get('run_selection') and not st.session_state.get('run_backtest'):
    st.info("è¯·ç‚¹å‡»ä¸Šæ–¹çš„ 'è¿è¡Œå½“æ—¥é€‰è‚¡' æˆ– 'è¿è¡Œå›æµ‹' å¼€å§‹ã€‚")
    st.stop()


# æ£€æŸ¥æ˜¯å¦éœ€è¦è¿è¡Œå›æµ‹
if st.session_state.get('run_backtest', False):
    # è°ƒç”¨å›æµ‹å‡½æ•°ï¼Œä¼ é€’å¤©æ•°å’Œå‚æ•°å…ƒç»„
    run_simple_backtest(BACKTEST_DAYS, params_tuple)
    st.stop()


# å®æ—¶é€‰è‚¡ï¼ˆåªæœ‰å½“ run_selection ä¸º True æ—¶è¿è¡Œï¼‰
if st.session_state.get('run_selection', False):
    st.write(f"æ­£åœ¨è¿è¡Œå®æ—¶é€‰è‚¡ï¼ˆæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}ï¼‰...")

    # è°ƒç”¨è¯„åˆ†å‡½æ•°ï¼Œä¼ é€’å½“å‰äº¤æ˜“æ—¥å’Œå‚æ•°å…ƒç»„
    fdf = run_scoring_for_date(last_trade, params_tuple)

    if fdf.empty:
        st.error("æ¸…æ´—å’Œè¯„åˆ†åæ²¡æœ‰å€™é€‰ï¼Œå»ºè®®æ”¾å®½æ¡ä»¶æˆ–æ£€æŸ¥æ¥å£æƒé™ã€‚")
        st.stop()

    # æœ€ç»ˆæ’åºä¸å±•ç¤º
    fdf.index = fdf.index + 1

    st.success(f"è¯„åˆ†å®Œæˆï¼šæ€»å€™é€‰ {len(fdf)} æ”¯ï¼Œæ˜¾ç¤º Top {min(TOP_DISPLAY, len(fdf))}ã€‚")
    display_cols = ['name','ts_code','ç»¼åˆè¯„åˆ†','pct_chg','vol_ratio','turnover_rate','net_mf','proxy_money','amount','10d_return','macd','k','d','j','rsl','volatility_10']
    for c in display_cols:
        [span_43](start_span)if c not in fdf.columns: fdf[c] = np.nan[span_43](end_span)

    st.dataframe(fdf[display_cols].head(TOP_DISPLAY), use_container_width=True)

    # ä¸‹è½½
    out_csv = fdf[display_cols].head(200).to_csv(index=True, encoding='utf-8-sig')
    st.download_button("ä¸‹è½½è¯„åˆ†ç»“æœï¼ˆå‰200ï¼‰CSV", data=out_csv, file_name=f"score_result_{last_trade}.csv", mime="text/csv")

    # å°ç»“ä¸å»ºè®®ï¼ˆç®€æ´ï¼‰
    st.markdown("### å°ç»“ä¸æ“ä½œæç¤ºï¼ˆç®€æ´ï¼‰")
    st.markdown("""
- **ã€ç­–ç•¥é£æ ¼ã€‘** æœ¬ç‰ˆæœ¬ä¸º BC æ··åˆå¢å¼ºç‰ˆï¼ˆçŸ­çº¿çˆ†å‘ + å¦–è‚¡æ•æ‰ï¼‰ã€‚  
- **ã€é£é™©æ§åˆ¶ã€‘** å·²å¯ç”¨ MACDã€RSLã€ä¸‹è·Œé€”ä¸­å¤§é˜³çº¿è¿‡æ»¤ã€å·¨é‡å†²é«˜è¿‡æ»¤ã€æç«¯æ³¢åŠ¨è¿‡æ»¤ã€‚
- **ã€æ•°æ®æç¤ºã€‘** è‹¥ moneyflow / chip / ths_member èƒ½æˆåŠŸæ‹‰å–ï¼Œå°†ä½œä¸ºé¢å¤–åŠ åˆ†å› å­ï¼›è‹¥æ— æƒé™è„šæœ¬ä¼šè‡ªåŠ¨ç”¨ proxy_money ä»£æ›¿ã€‚  
- **ã€é‡è¦çºªå¾‹ã€‘** å®æˆ˜çºªå¾‹ï¼š**9:40 å‰ä¸ä¹° â†’ è§‚å¯Ÿ 9:40-10:05 çš„é‡ä»·èŠ‚å¥ â†’ 10:05 åæ‹©ä¼˜ä»‹å…¥**ã€‚  
- **ã€é£æ§æç¤ºã€‘** è‹¥ä»Šæ—¥å€™é€‰æ™®éç¿»ç»¿ï¼Œè¯·ä¿æŒç©ºä»“ã€‚  
""")
    st.info("è¿è¡Œå‡ºç°é—®é¢˜è¯·æŠŠ Streamlit çš„é”™è¯¯æ—¥å¿—å‘ç»™æˆ‘ï¼Œæˆ‘ä¼šåœ¨ä¸¤æ¬¡ä¿®æ”¹å†…ç»§ç»­å¸®ä½ è°ƒä¼˜ã€‚")
