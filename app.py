# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V15.2 é«˜æ•ˆæ•°æ®ç‰ˆï¼šä¿®å¤æ•°æ®è·å–é—®é¢˜ + ä¼˜åŒ–è®¡ç®—é€»è¾‘
æ ¸å¿ƒä¿®å¤ï¼š
1. ã€**æ•°æ®è·å–ä¿®å¤**ã€‘ï¼šä¿®æ­£æ‰¹é‡æ•°æ®è·å–é€»è¾‘ï¼Œç¡®ä¿è·å–å®Œæ•´æ•°æ®
   - ä¿®å¤æ—¥çº¿æ•°æ®è·å–ï¼šä½¿ç”¨æ­£ç¡®çš„å‚æ•°æ ¼å¼
   - ä¿®å¤å¤æƒå› å­è·å–ï¼šç¡®ä¿è¦†ç›–æ‰€æœ‰æ—¥æœŸ
   
2. ã€**æ€§èƒ½ä¼˜åŒ–**ã€‘ï¼šå‡å°‘ä¸å¿…è¦çš„è®¡ç®—å’ŒAPIè°ƒç”¨
   - ä¼˜åŒ–æŒ‡æ ‡è®¡ç®—é€»è¾‘
   - å‡å°‘é‡å¤æ•°æ®è·å–
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€å˜é‡åˆå§‹åŒ–
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {}
GLOBAL_STOCK_BASIC = pd.DataFrame()

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V15.2 é«˜æ•ˆæ•°æ®ç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V15.2 é«˜æ•ˆæ•°æ®ç‰ˆï¼ˆğŸš€ æ•°æ®ä¿®å¤ / æ€§èƒ½ä¼˜åŒ–ï¼‰")

# ---------------------------
# è¾…åŠ©å‡½æ•°
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    """å®‰å…¨è°ƒç”¨ Tushare API"""
    global pro
    if pro is None:
        return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception as e:
        return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    """è·å– num_days ä¸ªäº¤æ˜“æ—¥ä½œä¸ºé€‰è‚¡æ—¥"""
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 3)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    
    if cal.empty or 'is_open' not in cal.columns:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œè¯·æ£€æŸ¥ Token æˆ– Tushare æƒé™ã€‚")
        return []
    
    trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)
    trade_days_df = trade_days_df[trade_days_df['cal_date'] <= end_date_str]
    return trade_days_df['cal_date'].head(num_days).tolist()

# ----------------------------------------------------------------------
# â­ï¸ V15.2 ä¿®å¤ï¼šé«˜æ•ˆæ•°æ®è·å–
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24, show_spinner=False)
def get_all_historical_data_fixed(trade_days_list):
    """
    ä¿®å¤ç‰ˆæ•°æ®è·å–ï¼šç¡®ä¿è·å–å®Œæ•´æ•°æ®
    """
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS, GLOBAL_STOCK_BASIC
    
    if not trade_days_list: 
        return False
    
    latest_trade_date = max(trade_days_list) 
    earliest_trade_date = min(trade_days_list)
    
    # è®¡ç®—éœ€è¦çš„æ—¥æœŸèŒƒå›´ï¼ˆå›æµ‹æ—¥æœŸå‰120å¤©åˆ°å20å¤©ï¼‰
    start_date_dt = datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=120)
    end_date_dt = datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=20)
    
    start_date = start_date_dt.strftime("%Y%m%d")
    end_date = end_date_dt.strftime("%Y%m%d")
    
    st.info(f"â³ æ­£åœ¨ä¸‹è½½ {start_date} åˆ° {end_date} çš„å†å²æ•°æ®...")
    
    # 1. è·å–è‚¡ç¥¨åˆ—è¡¨
    if GLOBAL_STOCK_BASIC.empty:
        progress_bar = st.progress(0, text="è·å–è‚¡ç¥¨åˆ—è¡¨...")
        stock_basic = safe_get('stock_basic', exchange='', list_status='L', 
                              fields='ts_code,name,list_date,market')
        if stock_basic.empty:
            st.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return False
        
        # è¿‡æ»¤æ‰åŒ—äº¤æ‰€
        stock_basic = stock_basic[~stock_basic['ts_code'].str.startswith('92')]
        GLOBAL_STOCK_BASIC = stock_basic
        progress_bar.progress(0.2, text=f"è·å–åˆ° {len(stock_basic)} åªè‚¡ç¥¨")
    
    all_stocks = GLOBAL_STOCK_BASIC['ts_code'].tolist()
    
    # 2. è·å–äº¤æ˜“æ—¥å†
    progress_bar.progress(0.3, text="è·å–äº¤æ˜“æ—¥å†...")
    trade_cal = safe_get('trade_cal', start_date=start_date, end_date=end_date, is_open='1')
    if trade_cal.empty:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†")
        return False
    
    all_trade_dates = trade_cal['cal_date'].tolist()
    
    # 3. æ‰¹é‡è·å–å¤æƒå› å­ï¼ˆä½¿ç”¨æ—¥æœŸèŒƒå›´ï¼Œè¿™æ˜¯æœ€é«˜æ•ˆçš„æ–¹å¼ï¼‰
    progress_bar.progress(0.4, text="ä¸‹è½½å¤æƒå› å­...")
    adj_factor_data = safe_get('adj_factor', start_date=start_date, end_date=end_date)
    
    if adj_factor_data.empty:
        st.warning("å¤æƒå› å­æ•°æ®ä¸ºç©ºï¼Œå°è¯•æŒ‰è‚¡ç¥¨è·å–...")
        # å¦‚æœæ‰¹é‡è·å–å¤±è´¥ï¼Œå°è¯•æŒ‰è‚¡ç¥¨è·å–
        adj_factor_list = []
        batch_size = 100
        num_batches = (len(all_stocks) + batch_size - 1) // batch_size
        
        for i in range(num_batches):
            start_idx = i * batch_size
            end_idx = min((i + 1) * batch_size, len(all_stocks))
            batch_stocks = all_stocks[start_idx:end_idx]
            
            for stock in batch_stocks:
                adj_df = safe_get('adj_factor', ts_code=stock, start_date=start_date, end_date=end_date)
                if not adj_df.empty:
                    adj_factor_list.append(adj_df)
            
            progress_bar.progress(0.4 + (i / num_batches) * 0.2, 
                                 text=f"è·å–å¤æƒå› å­: æ‰¹æ¬¡ {i+1}/{num_batches}")
        
        if adj_factor_list:
            adj_factor_data = pd.concat(adj_factor_list, ignore_index=True)
        else:
            st.error("æ— æ³•è·å–å¤æƒå› å­æ•°æ®")
            return False
    
    # å¤„ç†å¤æƒå› å­æ•°æ®
    adj_factor_data['adj_factor'] = pd.to_numeric(adj_factor_data['adj_factor'], errors='coerce').fillna(1.0)
    GLOBAL_ADJ_FACTOR = adj_factor_data.set_index(['ts_code', 'trade_date']).sort_index()
    
    # 4. è·å–æ—¥çº¿æ•°æ®ï¼ˆåˆ†æ‰¹è·å–ï¼Œé¿å…è¶…æ—¶ï¼‰
    progress_bar.progress(0.7, text="ä¸‹è½½æ—¥çº¿æ•°æ®...")
    
    # æ–¹æ³•1ï¼šæŒ‰æ—¥æœŸæ‰¹é‡è·å–ï¼ˆæ›´é«˜æ•ˆï¼‰
    daily_data_list = []
    
    # åˆ†æ‰¹å¤„ç†æ—¥æœŸï¼Œé¿å…å•æ¬¡è¯·æ±‚å¤ªå¤§
    date_batch_size = 20
    num_date_batches = (len(all_trade_dates) + date_batch_size - 1) // date_batch_size
    
    for i in range(num_date_batches):
        start_idx = i * date_batch_size
        end_idx = min((i + 1) * date_batch_size, len(all_trade_dates))
        date_batch = all_trade_dates[start_idx:end_idx]
        
        for date in date_batch:
            daily_df = safe_get('daily', trade_date=date)
            if not daily_df.empty:
                daily_data_list.append(daily_df)
        
        progress_bar.progress(0.7 + (i / num_date_batches) * 0.25, 
                             text=f"ä¸‹è½½æ—¥çº¿æ•°æ®: {i+1}/{num_date_batches}")
    
    if not daily_data_list:
        st.error("æ— æ³•è·å–æ—¥çº¿æ•°æ®")
        return False
    
    daily_raw_data = pd.concat(daily_data_list, ignore_index=True)
    
    # 5. å¤„ç†æ—¥çº¿æ•°æ®
    progress_bar.progress(0.95, text="å¤„ç†æ•°æ®...")
    daily_raw_data['trade_date'] = pd.to_datetime(daily_raw_data['trade_date'], format='%Y%m%d')
    GLOBAL_DAILY_RAW = daily_raw_data.set_index(['ts_code', 'trade_date']).sort_index()
    
    # 6. è®¾ç½®QFQåŸºå‡†å› å­
    try:
        latest_date = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
        if pd.notna(latest_date):
            latest_adj = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_date), 'adj_factor']
            GLOBAL_QFQ_BASE_FACTORS = latest_adj.droplevel(1).to_dict()
            st.success(f"âœ… è®¾ç½®åŸºå‡†å› å­ï¼Œè‚¡ç¥¨æ•°: {len(GLOBAL_QFQ_BASE_FACTORS)}")
    except Exception as e:
        st.warning(f"è®¾ç½®åŸºå‡†å› å­å¤±è´¥: {e}")
        GLOBAL_QFQ_BASE_FACTORS = {}
    
    progress_bar.progress(1.0, text="æ•°æ®åŠ è½½å®Œæˆï¼")
    time.sleep(0.5)
    progress_bar.empty()
    
    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
    st.success(f"""
    âœ… æ•°æ®åŠ è½½å®Œæˆï¼
    - æ—¥çº¿æ•°æ®: {len(GLOBAL_DAILY_RAW):,} æ¡è®°å½•
    - å¤æƒå› å­: {len(GLOBAL_ADJ_FACTOR):,} æ¡è®°å½•
    - åŸºå‡†å› å­: {len(GLOBAL_QFQ_BASE_FACTORS)} åªè‚¡ç¥¨
    - æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}
    """)
    
    return True

# ----------------------------------------------------------------------
# æ•°æ®è·å–å‡½æ•°
# ----------------------------------------------------------------------
def get_qfq_data(ts_code, start_date, end_date):
    """è·å–å‰å¤æƒæ•°æ®"""
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
    
    if GLOBAL_DAILY_RAW.empty or GLOBAL_ADJ_FACTOR.empty:
        return pd.DataFrame()
    
    # è·å–åŸºå‡†å¤æƒå› å­
    base_factor = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, 1.0)
    if base_factor <= 0:
        return pd.DataFrame()
    
    try:
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        start_dt = datetime.strptime(start_date, "%Y%m%d")
        end_dt = datetime.strptime(end_date, "%Y%m%d")
        
        # è·å–æ—¥çº¿æ•°æ®
        if ts_code not in GLOBAL_DAILY_RAW.index.get_level_values('ts_code'):
            return pd.DataFrame()
        
        daily_data = GLOBAL_DAILY_RAW.loc[ts_code].copy()
        daily_data = daily_data[(daily_data.index >= start_dt) & (daily_data.index <= end_dt)]
        
        if daily_data.empty:
            return pd.DataFrame()
        
        # è·å–å¤æƒå› å­
        if ts_code not in GLOBAL_ADJ_FACTOR.index.get_level_values('ts_code'):
            return pd.DataFrame()
        
        adj_data = GLOBAL_ADJ_FACTOR.loc[ts_code].copy()
        adj_data = adj_data[(adj_data.index >= start_dt) & (adj_data.index <= end_dt)]
        
        if adj_data.empty:
            return pd.DataFrame()
        
        # åˆå¹¶æ•°æ®
        df = daily_data.merge(adj_data, left_index=True, right_index=True, how='left')
        df['adj_factor'] = df['adj_factor'].fillna(base_factor)
        
        # è®¡ç®—å‰å¤æƒä»·æ ¼
        for col in ['open', 'high', 'low', 'close', 'pre_close']:
            if col in df.columns:
                df[f'{col}_qfq'] = df[col] * df['adj_factor'] / base_factor
        
        # ä½¿ç”¨å¤æƒä»·æ ¼
        for col in ['open', 'high', 'low', 'close']:
            if f'{col}_qfq' in df.columns:
                df[col] = df[f'{col}_qfq']
        
        return df[['open', 'high', 'low', 'close', 'vol']].reset_index()
        
    except Exception as e:
        return pd.DataFrame()

# ----------------------------------------------------------------------
# æ ¸å¿ƒè®¡ç®—å‡½æ•°
# ----------------------------------------------------------------------
def compute_indicators_simple(ts_code, end_date):
    """ç®€åŒ–çš„æŒ‡æ ‡è®¡ç®—"""
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=60)).strftime("%Y%m%d")
    
    df = get_qfq_data(ts_code, start_date, end_date)
    if df.empty or 'close' not in df.columns:
        return {}
    
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    df['high'] = pd.to_numeric(df['high'], errors='coerce')
    df['low'] = pd.to_numeric(df['low'], errors='coerce')
    
    close = df['close'].dropna()
    if len(close) < 20:
        return {}
    
    res = {'last_close': close.iloc[-1]}
    
    # 1. åŠ¨é‡å› å­
    if len(close) >= 20:
        res['momentum_20d'] = (close.iloc[-1] / close.iloc[-20] - 1) * 100
    
    # 2. è¶‹åŠ¿å› å­
    if len(close) >= 20:
        ma5 = close.rolling(5).mean()
        ma10 = close.rolling(10).mean()
        ma20 = close.rolling(20).mean()
        
        trend_score = 0
        if len(ma5) > 0 and len(ma10) > 0 and ma5.iloc[-1] > ma10.iloc[-1]:
            trend_score += 1
        if len(ma10) > 0 and len(ma20) > 0 and ma10.iloc[-1] > ma20.iloc[-1]:
            trend_score += 1
        if len(close) > 0 and len(ma5) > 0 and close.iloc[-1] > ma5.iloc[-1]:
            trend_score += 1
        
        res['trend_score'] = (trend_score / 3) * 100
    
    # 3. ä½ç½®å› å­
    if len(df) >= 60:
        hist_60 = df.tail(60)
        min_low = hist_60['low'].min()
        max_high = hist_60['high'].max()
        current_close = hist_60['close'].iloc[-1]
        
        if max_high > min_low:
            res['position_60d'] = (current_close - min_low) / (max_high - min_low) * 100
        else:
            res['position_60d'] = 50
    
    # è®¾ç½®é»˜è®¤å€¼
    res.setdefault('momentum_20d', 0)
    res.setdefault('trend_score', 0)
    res.setdefault('position_60d', 50)
    
    return res

def get_future_returns(ts_code, selection_date, selection_price):
    """è·å–æœªæ¥æ”¶ç›Š"""
    if pd.isna(selection_price) or selection_price <= 0:
        return {f'Return_D{n} (%)': np.nan for n in [1, 3, 5]}
    
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    start_date = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_date = (d0 + timedelta(days=15)).strftime("%Y%m%d")
    
    df = get_qfq_data(ts_code, start_date, end_date)
    if df.empty or 'close' not in df.columns:
        return {f'Return_D{n} (%)': np.nan for n in [1, 3, 5]}
    
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    df = df.dropna(subset=['close'])
    
    results = {}
    for n in [1, 3, 5]:
        if len(df) >= n:
            future_price = df.iloc[n-1]['close']
            results[f'Return_D{n} (%)'] = (future_price / selection_price - 1) * 100
        else:
            results[f'Return_D{n} (%)'] = np.nan
    
    return results

# ----------------------------------------------------
# ä¾§è¾¹æ å‚æ•°
# ----------------------------------------------------
with st.sidebar:
    st.header("æ¨¡å¼ä¸æ—¥æœŸé€‰æ‹©")
    backtest_date_end = st.date_input("é€‰æ‹©**å›æµ‹ç»“æŸæ—¥æœŸ**", value=datetime.now().date(), max_value=datetime.now().date())
    BACKTEST_DAYS = st.number_input("**è‡ªåŠ¨å›æµ‹å¤©æ•° (N)**", value=10, step=1, min_value=1, max_value=30)
    
    st.markdown("---")
    st.header("æ ¸å¿ƒå‚æ•°")
    FINAL_POOL = st.number_input("æœ€ç»ˆå…¥å›´è¯„åˆ†æ•°é‡ (M)", value=50, step=10, min_value=10)
    TOP_BACKTEST = st.number_input("å›æµ‹åˆ†æ Top K", value=3, step=1, min_value=1)
    
    st.markdown("---")
    st.header("ğŸ›’ è¿‡æ»¤æ¡ä»¶")
    MIN_PRICE = st.number_input("æœ€ä½è‚¡ä»· (å…ƒ)", value=5.0, step=1.0, min_value=1.0)
    MAX_PRICE = st.number_input("æœ€é«˜è‚¡ä»· (å…ƒ)", value=200.0, step=10.0, min_value=10.0)
    MIN_TURNOVER = st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=1.0, step=0.5, min_value=0.1)
    MIN_CIRC_MV = st.number_input("æœ€ä½æµé€šå¸‚å€¼ (äº¿å…ƒ)", value=20.0, step=5.0, min_value=5.0)

# ---------------------------
# Token è¾“å…¥
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token")
    st.stop()

ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# éªŒè¯Token
try:
    test = pro.trade_cal(exchange='', start_date='20240101', end_date='20240105')
    if test.empty:
        st.error("Tokenæ— æ•ˆ")
        st.stop()
except Exception as e:
    st.error(f"TokenéªŒè¯å¤±è´¥: {e}")
    st.stop()

# ---------------------------
# å›æµ‹å‡½æ•°
# ---------------------------
def run_backtest_single_day(trade_date):
    """å•ä¸ªäº¤æ˜“æ—¥çš„å›æµ‹"""
    # è·å–å½“æ—¥æ•°æ®
    daily_data = safe_get('daily', trade_date=trade_date)
    if daily_data.empty:
        return pd.DataFrame(), f"æ— æ—¥çº¿æ•°æ®: {trade_date}"
    
    daily_basic = safe_get('daily_basic', trade_date=trade_date, 
                          fields='ts_code,turnover_rate,circ_mv')
    
    # åˆå¹¶æ•°æ®
    df = daily_data.copy()
    if not daily_basic.empty:
        df = df.merge(daily_basic, on='ts_code', how='left')
    
    # è¿‡æ»¤STè‚¡å’ŒåŒ—äº¤æ‰€
    df = df[~df['ts_code'].str.startswith(('68', '200', '300', '400', '900', '92'))]
    
    # è½¬æ¢ä¸ºæ•°å€¼
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    df['turnover_rate'] = pd.to_numeric(df['turnover_rate'], errors='coerce').fillna(0)
    df['circ_mv'] = pd.to_numeric(df['circ_mv'], errors='coerce').fillna(0) / 10000  # è½¬ä¸ºäº¿å…ƒ
    
    # ç¡¬æ€§è¿‡æ»¤
    df = df[
        (df['close'] >= MIN_PRICE) & 
        (df['close'] <= MAX_PRICE) &
        (df['turnover_rate'] >= MIN_TURNOVER) &
        (df['circ_mv'] >= MIN_CIRC_MV)
    ].copy()
    
    if df.empty:
        return pd.DataFrame(), f"è¿‡æ»¤åæ— è‚¡ç¥¨: {trade_date}"
    
    # è®¡ç®—æŒ‡æ ‡
    records = []
    for _, row in df.iterrows():
        ts_code = row['ts_code']
        
        # è·å–æŒ‡æ ‡
        indicators = compute_indicators_simple(ts_code, trade_date)
        if not indicators or 'last_close' not in indicators:
            continue
        
        d0_price = indicators['last_close']
        
        # è·å–æœªæ¥æ”¶ç›Š
        future_returns = get_future_returns(ts_code, trade_date, d0_price)
        
        record = {
            'ts_code': ts_code,
            'name': row.get('name', ts_code),
            'Close': row['close'],
            'Circ_MV (äº¿)': row['circ_mv'],
            'Pct_Chg (%)': row.get('pct_chg', 0),
            'turnover': row['turnover_rate'],
            'momentum_20d': indicators.get('momentum_20d', 0),
            'trend_score': indicators.get('trend_score', 0),
            'position_60d': indicators.get('position_60d', 50),
            **future_returns
        }
        
        records.append(record)
    
    if not records:
        return pd.DataFrame(), f"æ— æœ‰æ•ˆæŒ‡æ ‡: {trade_date}"
    
    result_df = pd.DataFrame(records)
    
    # è¯„åˆ†
    def normalize(series):
        if series.empty or series.max() == series.min():
            return pd.Series([0.5] * len(series), index=series.index)
        return (series - series.min()) / (series.max() - series.min() + 1e-9)
    
    # åŠ¨é‡å¾—åˆ†
    result_df['s_momentum'] = normalize(result_df['momentum_20d'])
    
    # è¶‹åŠ¿å¾—åˆ†
    result_df['s_trend'] = normalize(result_df['trend_score'])
    
    # ä½ç½®å¾—åˆ†ï¼ˆ40-70ä¸ºä½³ï¼‰
    position_score = np.where(
        (result_df['position_60d'] >= 40) & (result_df['position_60d'] <= 70),
        1.0,
        np.where(
            result_df['position_60d'] < 40,
            result_df['position_60d'] / 40,
            (100 - result_df['position_60d']) / 30
        )
    )
    result_df['s_position'] = position_score
    
    # ç»¼åˆè¯„åˆ†
    result_df['ç»¼åˆè¯„åˆ†'] = (
        result_df['s_momentum'] * 0.4 +
        result_df['s_trend'] * 0.3 +
        result_df['s_position'] * 0.3
    ) * 100
    
    result_df = result_df.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).head(TOP_BACKTEST)
    return result_df, None

# ---------------------------
# ä¸»è¿è¡Œå—
# ---------------------------
if st.button(f"ğŸš€ å¼€å§‹ {BACKTEST_DAYS} æ—¥å›æµ‹"):
    
    # è·å–äº¤æ˜“æ—¥
    trade_days = get_trade_days(backtest_date_end.strftime("%Y%m%d"), int(BACKTEST_DAYS))
    if not trade_days:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥")
        st.stop()
    
    # åŠ è½½å†å²æ•°æ®
    st.info("æ­£åœ¨åŠ è½½å†å²æ•°æ®...")
    start_time = time.time()
    
    success = get_all_historical_data_fixed(trade_days)
    if not success:
        st.error("æ•°æ®åŠ è½½å¤±è´¥")
        st.stop()
    
    load_time = time.time() - start_time
    st.success(f"æ•°æ®åŠ è½½å®Œæˆï¼è€—æ—¶: {load_time:.1f}ç§’")
    
    # å¼€å§‹å›æµ‹
    st.header(f"ğŸ“ˆ å›æµ‹ {len(trade_days)} ä¸ªäº¤æ˜“æ—¥")
    
    all_results = []
    valid_days = 0
    
    progress_bar = st.progress(0, text="å›æµ‹è¿›åº¦")
    status_text = st.empty()
    
    for i, trade_date in enumerate(trade_days):
        status_text.text(f"å¤„ç†: {trade_date} ({i+1}/{len(trade_days)})")
        
        result, error = run_backtest_single_day(trade_date)
        
        if error:
            st.warning(error)
        elif not result.empty:
            result['Trade_Date'] = trade_date
            all_results.append(result)
            valid_days += 1
        
        progress_bar.progress((i + 1) / len(trade_days))
    
    progress_bar.empty()
    status_text.text(f"å›æµ‹å®Œæˆï¼æœ‰æ•ˆäº¤æ˜“æ—¥: {valid_days}/{len(trade_days)}")
    
    if not all_results:
        st.error("æ‰€æœ‰äº¤æ˜“æ—¥å›æµ‹å‡å¤±è´¥")
        st.stop()
    
    # åˆå¹¶ç»“æœ
    final_results = pd.concat(all_results, ignore_index=True)
    
    # æ˜¾ç¤ºç»Ÿè®¡
    st.header("ğŸ“Š å›æµ‹ç»Ÿè®¡")
    
    # æ”¶ç›Šç»Ÿè®¡
    for n in [1, 3, 5]:
        col = f'Return_D{n} (%)'
        if col in final_results.columns:
            valid = final_results.dropna(subset=[col])
            if not valid.empty:
                avg_return = valid[col].mean()
                hit_rate = (valid[col] > 0).mean() * 100
                count = len(valid)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric(f"D+{n} å¹³å‡æ”¶ç›Š", f"{avg_return:.2f}%")
                with col2:
                    st.metric(f"D+{n} èƒœç‡", f"{hit_rate:.1f}%")
                with col3:
                    st.metric(f"D+{n} æ ·æœ¬æ•°", count)
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    st.header("ğŸ“‹ è¯¦ç»†ç»“æœ")
    
    display_cols = ['Trade_Date', 'ts_code', 'name', 'ç»¼åˆè¯„åˆ†', 'Close', 
                   'Pct_Chg (%)', 'Circ_MV (äº¿)', 'momentum_20d', 'trend_score']
    
    # æ·»åŠ æ”¶ç›Šåˆ—
    for n in [1, 3, 5]:
        col = f'Return_D{n} (%)'
        if col in final_results.columns:
            display_cols.append(col)
    
    available_cols = [col for col in display_cols if col in final_results.columns]
    
    st.dataframe(
        final_results[available_cols].sort_values('Trade_Date', ascending=False),
        use_container_width=True,
        column_config={
            'momentum_20d': st.column_config.NumberColumn(format="%.1f"),
            'trend_score': st.column_config.NumberColumn(format="%.1f"),
        }
    )
