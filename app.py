# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V15.0 åŠ¨é‡è¶‹åŠ¿å¢å¼ºç‰ˆï¼šä¸­æœŸåŠ¨é‡ + è¶‹åŠ¿çªç ´ (é²æ£’æ€§ä¿®å¤+ç­–ç•¥ä¼˜åŒ–)
æ ¸å¿ƒä¼˜åŒ–ï¼š
1. ã€**ç­–ç•¥ä¼˜åŒ– V15.0**ã€‘ï¼šä»èµ„é‡‘æµä¸»å¯¼è½¬å‘åŠ¨é‡è¶‹åŠ¿ä¸»å¯¼ï¼Œé‡‡ç”¨20æ—¥åŠ¨é‡+å‡çº¿è¶‹åŠ¿+çªç ´ä¿¡å·ç»„åˆ
   - æ–°æƒé‡ï¼šåŠ¨é‡(0.40) + è¶‹åŠ¿(0.25) + é‡ä»·(0.15) + çªç ´(0.10) + é˜²å¾¡(0.10) = 1.00
   - æ–°å¢20æ—¥åŠ¨é‡ã€å‡çº¿æ’åˆ—ã€é‡æ¯”ã€çªç ´æ–°é«˜ç­‰å¤šä¸ªæœ‰æ•ˆå› å­
   
2. ã€**è¿‡æ»¤æ¡ä»¶ä¼˜åŒ–**ã€‘ï¼šæ”¾å®½é€‰è‚¡èŒƒå›´ï¼Œæé«˜ç­–ç•¥çµæ´»æ€§
   - æœ€ä½è‚¡ä»·ä»10å…ƒé™è‡³5å…ƒ
   - æœ€ä½æµé€šå¸‚å€¼ä»20äº¿é™è‡³10äº¿
   - æœ€ä½æ¢æ‰‹ç‡ä»2%é™è‡³1%
   - æœ€ä½æˆäº¤é¢ä»0.6äº¿é™è‡³0.3äº¿
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import time  
warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€å˜é‡åˆå§‹åŒ–
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} # {ts_code: latest_adj_factor}


# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V15.0 åŠ¨é‡è¶‹åŠ¿å¢å¼ºç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V15.0 åŠ¨é‡è¶‹åŠ¿å¢å¼ºç‰ˆï¼ˆğŸš€ ä¸­æœŸåŠ¨é‡ / è¶‹åŠ¿çªç ´ - ç­–ç•¥ä¼˜åŒ–ï¼‰")
st.markdown("ğŸ¯ **V15.0 ç­–ç•¥è¯´æ˜ï¼š** **åŠ¨é‡è¶‹åŠ¿ä¸»å¯¼ï¼Œæ³¨é‡ä¸­æœŸåŠ¨èƒ½ã€‚** æ ¸å¿ƒæƒé‡ï¼š**20æ—¥åŠ¨é‡ 0.40** + **è¶‹åŠ¿æ’åˆ— 0.25** + **é‡ä»·é…åˆ 0.15** + **çªç ´æ–°é«˜ 0.10** + **é˜²å¾¡å› å­ 0.10**ã€‚")
st.markdown("âœ… **æŠ€æœ¯è¯´æ˜ï¼š** å¯åŠ¨åŠ è½½æ—¶é—´è¾ƒé•¿ (5-8 åˆ†é’Ÿ)ï¼Œä½†æ•°æ®å¯é ï¼Œå›æµ‹è®¡ç®—é€Ÿåº¦æå¿«ã€‚")


# ---------------------------
# è¾…åŠ©å‡½æ•° (APIè°ƒç”¨å’Œæ•°æ®è·å–)
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    """å®‰å…¨è°ƒç”¨ Tushare API"""
    global pro
    if pro is None:
        return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception as e:
        return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    """è·å– num_days ä¸ªäº¤æ˜“æ—¥ä½œä¸ºé€‰è‚¡æ—¥"""
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 2)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    
    if cal.empty or 'is_open' not in cal.columns:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œè¯·æ£€æŸ¥ Token æˆ– Tushare æƒé™ã€‚")
        return []
    
    trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)
    trade_days_df = trade_days_df[trade_days_df['cal_date'] <= end_date_str]
    return trade_days_df['cal_date'].head(num_days).tolist()


# ----------------------------------------------------------------------
# â­ï¸ V15.0 æ ¸å¿ƒï¼šæŒ‰æ—¥æœŸå¾ªç¯æ‹‰å–å†å²æ•°æ® (é²æ£’æ€§ä¿è¯)
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24)
def get_all_historical_data(trade_days_list):
    """
    V15.0 é²æ£’ä¿®å¤ï¼šæ”¹ç”¨æŒ‰æ—¥æœŸå¾ªç¯æ‹‰å–æ—¥çº¿å’Œå¤æƒå› å­ï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§ã€‚
    """
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS
    
    if not trade_days_list: return False
    
    latest_trade_date = max(trade_days_list) 
    earliest_trade_date = min(trade_days_list)
    
    # æ‰©å¤§æ•°æ®è·å–èŒƒå›´
    start_date_dt = datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=150)
    end_date_dt = datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=20)
    
    start_date = start_date_dt.strftime("%Y%m%d")
    end_date = end_date_dt.strftime("%Y%m%d")
    
    st.info(f"â³ æ­£åœ¨æŒ‰æ—¥æœŸå¾ªç¯ä¸‹è½½ {start_date} åˆ° {end_date} é—´çš„**å…¨å¸‚åœºå†å²æ•°æ®**...")
    
    # 1. è·å–æ‰€æœ‰äº¤æ˜“æ—¥åˆ—è¡¨
    all_trade_dates_df = safe_get('trade_cal', start_date=start_date, end_date=end_date, is_open='1')
    if all_trade_dates_df.empty:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ã€‚")
        return False
    
    all_dates = all_trade_dates_df['cal_date'].tolist()
    
    # 2. å¾ªç¯è·å–å¤æƒå› å­ (adj_factor) å’Œæ—¥çº¿è¡Œæƒ… (daily)
    adj_factor_data_list = []
    daily_data_list = []
    
    download_progress = st.progress(0, text="ä¸‹è½½è¿›åº¦ (æŒ‰æ—¥æœŸå¾ªç¯)...")
    
    for i, date in enumerate(all_dates):
        download_progress.progress((i + 1) / len(all_dates), text=f"ä¸‹è½½è¿›åº¦ï¼šå¤„ç†æ—¥æœŸ {date}")
        
        # è·å–å¤æƒå› å­
        adj_df = safe_get('adj_factor', trade_date=date)
        if not adj_df.empty:
            adj_factor_data_list.append(adj_df)
            
        # è·å–æ—¥çº¿è¡Œæƒ…
        daily_df = safe_get('daily', trade_date=date)
        if not daily_df.empty:
            daily_data_list.append(daily_df)
            
        # é¿å…è¿‡äºé¢‘ç¹çš„ API è°ƒç”¨ï¼ŒTushare æœ‰ QPS é™åˆ¶
    
    download_progress.progress(1.0, text="ä¸‹è½½è¿›åº¦ï¼šåˆå¹¶æ•°æ®...")
    download_progress.empty()

    
    # 3. åˆå¹¶å’Œå¤„ç†æ•°æ®
    if not adj_factor_data_list:
        st.error("âŒ ä¸¥é‡é”™è¯¯ï¼šæ— æ³•è·å–ä»»ä½•å¤æƒå› å­æ•°æ®ã€‚")
        return False
        
    adj_factor_data = pd.concat(adj_factor_data_list)
    adj_factor_data['adj_factor'] = pd.to_numeric(adj_factor_data['adj_factor'], errors='coerce').fillna(0)
    GLOBAL_ADJ_FACTOR = adj_factor_data.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1]) 
    
    if not daily_data_list:
        st.error("âŒ ä¸¥é‡é”™è¯¯ï¼šæ— æ³•è·å–ä»»ä½•å†å²æ—¥çº¿æ•°æ®ã€‚")
        return False

    daily_raw_data = pd.concat(daily_data_list)
    GLOBAL_DAILY_RAW = daily_raw_data.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1])


    # 4. è®¡ç®—å¹¶å­˜å‚¨å…¨å±€å›ºå®š QFQ åŸºå‡†å› å­
    latest_global_date = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
    
    if latest_global_date:
        try:
            latest_adj_df = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_global_date), 'adj_factor']
            GLOBAL_QFQ_BASE_FACTORS = latest_adj_df.droplevel(1).to_dict()
            st.info(f"âœ… å…¨å±€ QFQ åŸºå‡†å› å­å·²è®¾ç½®ã€‚åŸºå‡†æ—¥æœŸ: {latest_global_date}ï¼Œè‚¡ç¥¨æ•°é‡: {len(GLOBAL_QFQ_BASE_FACTORS)}")
        except Exception as e:
            st.error(f"æ— æ³•è®¾ç½®å…¨å±€ QFQ åŸºå‡†å› å­: {e}")
            GLOBAL_QFQ_BASE_FACTORS = {}
    
    
    # 5. è¯Šæ–­ä¿¡æ¯
    st.info(f"âœ… æ•°æ®é¢„åŠ è½½å®Œæˆã€‚æ—¥çº¿æ•°æ®æ€»æ¡ç›®ï¼š{len(GLOBAL_DAILY_RAW)}ï¼Œå¤æƒå› å­æ€»æ¡ç›®ï¼š{len(GLOBAL_ADJ_FACTOR)}")

    # æ£€æŸ¥æ•°æ®æ¡ç›®æ˜¯å¦è¶³å¤Ÿ 
    if len(GLOBAL_DAILY_RAW) < 100000:
         st.warning("âš ï¸ è­¦å‘Šï¼šæ€»æ¡ç›®æ•°åä½ã€‚è¯·å†æ¬¡ç¡®è®¤ Tushare ç§¯åˆ†å’Œ API è®¿é—®æƒé™ã€‚")
         
    return True


# ----------------------------------------------------------------------
# ä¼˜åŒ–çš„æ•°æ®è·å–å‡½æ•°ï¼šåªä»å†…å­˜ä¸­åˆ‡ç‰‡ (å‰å¤æƒè®¡ç®—æ ¸å¿ƒ)
# ----------------------------------------------------------------------
def get_qfq_data_v4_optimized_final(ts_code, start_date, end_date):
    """ 
    æ—¥çº¿æ•°æ®å’Œå¤æƒå› å­å‡ä»é¢„åŠ è½½çš„å…¨å±€å˜é‡ä¸­åˆ‡ç‰‡è·å–ï¼Œ
    å¤æƒåŸºå‡†ä½¿ç”¨ GLOBAL_QFQ_BASE_FACTORS ä¸­å­˜å‚¨çš„ç»Ÿä¸€å› å­ã€‚
    """
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
    
    if GLOBAL_DAILY_RAW.empty or GLOBAL_ADJ_FACTOR.empty or not GLOBAL_QFQ_BASE_FACTORS:
        return pd.DataFrame()
        
    latest_adj_factor = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, np.nan)
    if pd.isna(latest_adj_factor) or latest_adj_factor < 1e-9:
        return pd.DataFrame() 

    try:
        # åˆ‡ç‰‡æ•°æ®
        daily_df_full = GLOBAL_DAILY_RAW.loc[ts_code]
        daily_df = daily_df_full.loc[(daily_df_full.index >= start_date) & (daily_df_full.index <= end_date)]
        
        adj_factor_series_full = GLOBAL_ADJ_FACTOR.loc[ts_code]['adj_factor']
        adj_factor_series = adj_factor_series_full.loc[(adj_factor_series_full.index >= start_date) & (adj_factor_series_full.index <= end_date)]
        
    except KeyError:
        return pd.DataFrame()
    except Exception:
        return pd.DataFrame()
    
    if daily_df.empty or adj_factor_series.empty: return pd.DataFrame()
            
    # åˆå¹¶åŸå§‹ä»·æ ¼å’Œå¤æƒå› å­
    df = daily_df.merge(adj_factor_series.rename('adj_factor'), left_index=True, right_index=True, how='left')
    df = df.dropna(subset=['adj_factor'])
    if df.empty: return pd.DataFrame()
    
    # å¤æƒè®¡ç®—é€»è¾‘
    df = df.sort_index()
    
    # ä½¿ç”¨å…¨å±€å›ºå®šåŸºå‡†è¿›è¡Œå‘é‡åŒ–å¤æƒè®¡ç®—
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns:
            # QFQ Price = Raw Price * (Adj Factor / Global Base Factor)
            df[col + '_qfq'] = df[col] * df['adj_factor'] / latest_adj_factor
    
    df = df.reset_index().rename(columns={'trade_date': 'trade_date_str'})
    df['trade_date'] = pd.to_datetime(df['trade_date_str'], format='%Y%m%d')
    df = df.sort_values('trade_date').set_index('trade_date_str')
    for col in ['open', 'high', 'low', 'close']:
        df[col] = df[col + '_qfq']
    return df[['open', 'high', 'low', 'close', 'vol']].copy() 

# ----------------------------------------------------------------------
# æ ¸å¿ƒå‡½æ•°ï¼šget_future_prices (æ¥å— D0 QFQ ä»·æ ¼)
# ----------------------------------------------------------------------

def get_future_prices(ts_code, selection_date, d0_qfq_close, days_ahead=[1, 3, 5]):
    
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    start_date_future = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_date_future = (d0 + timedelta(days=15)).strftime("%Y%m%d")
    
    selection_price_adj = d0_qfq_close 
    
    # 1. è·å–æœªæ¥ N æ—¥æ•°æ® (ç”¨äºè®¡ç®— D+N çš„åˆ†å­)
    hist = get_qfq_data_v4_optimized_final(ts_code, start_date=start_date_future, end_date=end_date_future)
    if hist.empty or 'close' not in hist.columns:
        results = {}
        for n in days_ahead: results[f'Return_D{n}'] = np.nan
        return results
        
    hist['close'] = pd.to_numeric(hist['close'], errors='coerce')
    hist = hist.dropna(subset=['close'])
    hist = hist.reset_index(drop=True) 
    results = {}
    
    # 2. è®¡ç®—æ”¶ç›Š
    for n in days_ahead:
        col_name = f'Return_D{n}'
        
        if pd.notna(selection_price_adj) and selection_price_adj > 1e-9:
            if len(hist) >= n:
                future_price = hist.iloc[n-1]['close']
                results[col_name] = (future_price / selection_price_adj - 1) * 100
            else:
                results[col_name] = np.nan
        else:
            results[col_name] = np.nan 
            
    return results


# ----------------------------------------------------------------------
# â­ï¸ V15.0 æ–°å¢ï¼šå¢å¼ºç‰ˆæŒ‡æ ‡è®¡ç®—å‡½æ•°
# ----------------------------------------------------------------------
def compute_indicators_v2(ts_code, end_date):
    """å¢å¼ºç‰ˆæŒ‡æ ‡è®¡ç®— - æ–°å¢åŠ¨é‡ã€è¶‹åŠ¿ã€é‡ä»·ã€çªç ´ç­‰å› å­"""
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=120)).strftime("%Y%m%d")
    
    # è·å– QFQ æ•°æ®ï¼Œç”¨äºè®¡ç®—æ‰€æœ‰æŒ‡æ ‡
    df = get_qfq_data_v4_optimized_final(ts_code, start_date=start_date, end_date=end_date)
    
    res = {}
    if df.empty or 'close' not in df.columns: 
        return res
        
    df['close'] = pd.to_numeric(df['close'], errors='coerce').astype(float)
    df['high'] = pd.to_numeric(df['high'], errors='coerce').astype(float)
    df['low'] = pd.to_numeric(df['low'], errors='coerce').astype(float)
    df['vol'] = pd.to_numeric(df['vol'], errors='coerce').fillna(0)
    
    if len(df) >= 2:
         df['pct_chg'] = df['close'].pct_change().fillna(0) * 100 
    else:
         df['pct_chg'] = 0.0
         
    close = df['close']
    high = df['high']
    low = df['low']
    vol = df['vol']
    
    res['last_close'] = close.iloc[-1] if len(close) > 0 else np.nan
    
    # 1. åŠ¨é‡å› å­ (20æ—¥æ¶¨å¹…)
    if len(close) >= 20:
        res['momentum_20d'] = (close.iloc[-1] / close.iloc[-20] - 1) * 100
    else:
        res['momentum_20d'] = 0
    
    # 2. è¶‹åŠ¿å› å­ (å‡çº¿æ’åˆ—)
    if len(close) >= 20:
        ma5 = close.rolling(5).mean()
        ma10 = close.rolling(10).mean()
        ma20 = close.rolling(20).mean()
        
        # å‡çº¿å¤šå¤´æ’åˆ—å¾—åˆ†
        trend_score = 0
        if ma5.iloc[-1] > ma10.iloc[-1]: trend_score += 1
        if ma10.iloc[-1] > ma20.iloc[-1]: trend_score += 1
        if close.iloc[-1] > ma5.iloc[-1]: trend_score += 1
        res['trend_score'] = trend_score / 3 * 100  # å½’ä¸€åŒ–åˆ°0-100
    else:
        res['trend_score'] = 0
    
    # 3. é‡ä»·å…³ç³»
    if len(vol) >= 10:
        # é‡æ¯”ï¼šå½“æ—¥æˆäº¤é‡/5æ—¥å‡é‡
        avg_vol_5d = vol.rolling(5).mean().iloc[-1]
        if avg_vol_5d > 0:
            res['volume_ratio'] = vol.iloc[-1] / avg_vol_5d
        else:
            res['volume_ratio'] = 1
        
        # æ¢æ‰‹ç‡ç¨³å®šæ€§
        vol_std = vol.tail(10).std()
        vol_mean = vol.tail(10).mean()
        if vol_mean > 0:
            res['volume_stability'] = (1 - vol_std / vol_mean) * 100
    else:
        res['volume_ratio'] = 1
        res['volume_stability'] = 50
    
    # 4. çªç ´å› å­ (åˆ›20æ—¥æ–°é«˜)
    if len(high) >= 20:
        highest_20d = high.tail(20).max()
        current_high = high.iloc[-1]
        res['breakout_score'] = 100 if current_high >= highest_20d else 0
    else:
        res['breakout_score'] = 0
    
    # 5. é˜²å¾¡å› å­ (60æ—¥ä½ç½® + æ³¢åŠ¨ç‡)
    if len(df) >= 60:
        hist_60 = df.tail(60)
        min_low = hist_60['low'].min()
        max_high = hist_60['high'].max()
        current_close = hist_60['close'].iloc[-1]
        
        if max_high > min_low:
            res['position_60d'] = (current_close - min_low) / (max_high - min_low) * 100
        else:
            res['position_60d'] = 50
    
    # è®¡ç®—æ³¢åŠ¨ç‡ (20æ—¥)
    if len(df) >= 20:
        returns = close.pct_change().dropna()
        res['volatility_20d'] = returns.tail(20).std() * np.sqrt(252) * 100  # å¹´åŒ–æ³¢åŠ¨ç‡
    
    # ä¿ç•™åŸæœ‰æŒ‡æ ‡ç”¨äºå…¼å®¹
    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        res['macd_val'] = ((diff - dea) * 2).iloc[-1]
    else: 
        res['macd_val'] = np.nan
        
    vols = df['vol'].tolist()
    if len(vols) >= 6 and vols[-6:-1] and np.mean(vols[-6:-1]) > 1e-9:
        res['vol_ratio'] = vols[-1] / np.mean(vols[-6:-1])
    else: 
        res['vol_ratio'] = np.nan
        
    res['10d_return'] = (close.iloc[-1]/close.iloc[-10] - 1) * 100 if len(close)>=10 and close.iloc[-10]!=0 else 0
    res['volatility'] = df['pct_chg'].tail(10).std() if len(df)>=10 else 0
    
    return res


# ----------------------------------------------------
# ä¾§è¾¹æ å‚æ•° (V15.0 ä¼˜åŒ–ï¼šæ›´å®½æ¾çš„è¿‡æ»¤æ¡ä»¶)
# ----------------------------------------------------
with st.sidebar:
    st.header("æ¨¡å¼ä¸æ—¥æœŸé€‰æ‹©")
    backtest_date_end = st.date_input("é€‰æ‹©**å›æµ‹ç»“æŸæ—¥æœŸ**", value=datetime.now().date(), max_value=datetime.now().date())
    BACKTEST_DAYS = int(st.number_input("**è‡ªåŠ¨å›æµ‹å¤©æ•° (N)**", value=20, step=1, min_value=1, max_value=50, help="ç¨‹åºå°†è‡ªåŠ¨å›æµ‹æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥ã€‚å»ºè®®è®¾ç½®ä¸º 20 å¤©ä»¥è·å¾—æ›´å¯é çš„ç»Ÿè®¡æ•°æ®ã€‚"))
    
    st.markdown("---")
    st.header("æ ¸å¿ƒå‚æ•°")
    FINAL_POOL = int(st.number_input("æœ€ç»ˆå…¥å›´è¯„åˆ†æ•°é‡ (M)", value=100, step=1, min_value=1)) 
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=10, step=1))
    TOP_BACKTEST = int(st.number_input("å›æµ‹åˆ†æ Top K", value=3, step=1, min_value=1)) 
    
    st.markdown("---")
    st.header("ğŸ›’ V15.0 çµæ´»è¿‡æ»¤æ¡ä»¶ (æ›´å®½æ¾)")
    MIN_PRICE = st.number_input("æœ€ä½è‚¡ä»· (å…ƒ)", value=5.0, step=0.5, min_value=0.1, help="ä»10å…ƒé™è‡³5å…ƒï¼Œæ‰©å¤§é€‰è‚¡èŒƒå›´")
    MAX_PRICE = st.number_input("æœ€é«˜è‚¡ä»· (å…ƒ)", value=500.0, step=5.0, min_value=1.0, help="ä»300å…ƒå‡è‡³500å…ƒï¼ŒåŒ…å«æ›´å¤šé«˜ä»·ä¼˜è´¨è‚¡")
    MIN_TURNOVER = st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=1.0, step=0.5, min_value=0.1, help="ä»2%é™è‡³1%ï¼Œå‡å°‘è¿‡æ»¤æ‰ä½æ¢æ‰‹æ½œåŠ›è‚¡")
    MIN_CIRC_MV_BILLIONS = st.number_input("æœ€ä½æµé€šå¸‚å€¼ (äº¿å…ƒ)", value=10.0, step=1.0, min_value=1.0, help="ä»20äº¿é™è‡³10äº¿ï¼Œæ‰©å¤§ä¸­å°ç›˜è‚¡é€‰æ‹©")
    MIN_AMOUNT_MILLIONS = st.number_input("æœ€ä½æˆäº¤é¢ (äº¿å…ƒ)", value=0.3, step=0.1, min_value=0.1, help="ä»0.6äº¿é™è‡³0.3äº¿ï¼Œæé«˜ç­–ç•¥çµæ´»æ€§")
    MIN_AMOUNT = MIN_AMOUNT_MILLIONS * 100000000 

# ---------------------------
# Token è¾“å…¥ä¸åˆå§‹åŒ– (ä¿æŒä¸å˜)
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()
ts.set_token(TS_TOKEN)
pro = ts.pro_api() 

# ---------------------------
# â­ï¸ V15.0 æ ¸å¿ƒå›æµ‹é€»è¾‘å‡½æ•° (å¢å¼ºç‰ˆ)
# ---------------------------
def run_backtest_for_a_day(last_trade, TOP_BACKTEST, FINAL_POOL, MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, MIN_CIRC_MV_BILLIONS):
    """ä¸ºå•ä¸ªäº¤æ˜“æ—¥è¿è¡Œé€‰è‚¡å’Œå›æµ‹é€»è¾‘ - V15.0 å¢å¼ºç‰ˆ"""
    global GLOBAL_DAILY_RAW
    
    # 1. æ‹‰å–å…¨å¸‚åœº Daily æ•°æ® (ä»Šæ—¥å¿«ç…§)
    daily_all = safe_get('daily', trade_date=last_trade) 
    if daily_all.empty or 'ts_code' not in daily_all.columns: 
        return pd.DataFrame(), f"æ•°æ®ç¼ºå¤±æˆ–æ‹‰å–å¤±è´¥ï¼š{last_trade}"

    pool_raw = daily_all.reset_index(drop=True) 
    stock_basic = safe_get('stock_basic', list_status='L', fields='ts_code,name,list_date') 
    REQUIRED_BASIC_COLS = ['ts_code','turnover_rate','amount','total_mv','circ_mv'] 
    daily_basic = safe_get('daily_basic', trade_date=last_trade, fields=','.join(REQUIRED_BASIC_COLS))
    mf_raw = safe_get('moneyflow', trade_date=last_trade)
    pool_merged = pool_raw.copy()

    # æ•°æ®åˆå¹¶
    if not stock_basic.empty and 'name' in stock_basic.columns:
        pool_merged = pool_merged.merge(stock_basic[['ts_code','name','list_date']], on='ts_code', how='left')
    else:
        pool_merged['name'] = pool_merged['ts_code']
        pool_merged['list_date'] = '20000101'
        
    if not daily_basic.empty:
        cols_to_merge = [c for c in REQUIRED_BASIC_COLS if c in daily_basic.columns]
        if 'amount' in pool_merged.columns and 'amount' in cols_to_merge: 
            pool_merged = pool_merged.drop(columns=['amount'])
        pool_merged = pool_merged.merge(daily_basic[cols_to_merge], on='ts_code', how='left')
    
    moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])
    if not mf_raw.empty:
        possible = ['net_mf','net_mf_amount','net_mf_in']
        for c in possible:
            if c in mf_raw.columns:
                moneyflow = mf_raw[['ts_code', c]].rename(columns={c:'net_mf'}).fillna(0)
                break            
    if not moneyflow.empty:
        pool_merged = pool_merged.merge(moneyflow, on='ts_code', how='left')
        
    pool_merged['net_mf'] = pool_merged['net_mf'].fillna(0) 
    
    # æ£€æŸ¥ 'turnover_rate' å­—æ®µ
    if 'turnover_rate' not in pool_merged.columns:
        pool_merged['turnover_rate'] = 0.0 
    
    pool_merged['turnover_rate'] = pool_merged['turnover_rate'].fillna(0) 
    
   
    # 3. æ‰§è¡Œç¡¬æ€§æ¡ä»¶è¿‡æ»¤
    df = pool_merged.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce') 
    df['turnover_rate'] = pd.to_numeric(df['turnover_rate'], errors='coerce').fillna(0)
    df['amount'] = pd.to_numeric(df['amount'], errors='coerce').fillna(0) * 1000 # è½¬æ¢ä¸ºä¸‡å…ƒ
    df['circ_mv_billion'] = pd.to_numeric(df['circ_mv'], errors='coerce').fillna(0) / 10000 
    df['name'] = df['name'].astype(str)
    
    # è¿‡æ»¤ ST è‚¡/é€€å¸‚è‚¡/åŒ—äº¤æ‰€
    mask_st = df['name'].str.contains('ST|é€€', case=False, na=False)
    df = df[~mask_st]
    mask_bj = df['ts_code'].str.startswith('92') 
    df = df[~mask_bj]
    
    # æ–°è‚¡è¿‡æ»¤
    TODAY = datetime.strptime(last_trade, "%Y%m%d")
    MIN_LIST_DAYS = 120
    df['list_date_dt'] = pd.to_datetime(df['list_date'], format='%Y%m%d', errors='coerce')
    df['days_listed'] = (TODAY - df['list_date_dt']).dt.days
    
    mask_new_all = df['days_listed'] < MIN_LIST_DAYS
    df = df[~mask_new_all] 
    
    # è¿‡æ»¤ä»·æ ¼
    mask_price = (df['close'] >= MIN_PRICE) & (df['close'] <= MAX_PRICE)
    df = df[mask_price]
    
    # è¿‡æ»¤æµé€šå¸‚å€¼
    mask_circ_mv = df['circ_mv_billion'] >= MIN_CIRC_MV_BILLIONS
    df = df[mask_circ_mv] 
    
    # è¿‡æ»¤æ¢æ‰‹ç‡
    mask_turn = df['turnover_rate'] >= MIN_TURNOVER 
    df = df[mask_turn]
    
    # è¿‡æ»¤æˆäº¤é¢
    mask_amt = df['amount'] * 1000 >= MIN_AMOUNT
    df = df[mask_amt]
    
    df = df.reset_index(drop=True)
    initial_candidate_count = len(df)

    if initial_candidate_count == 0: 
        return pd.DataFrame(), f"ç¡¬æ€§è¿‡æ»¤åæ— è‚¡ç¥¨ï¼š{last_trade}"

    # 4. V15.0 æ–°å¢ï¼šè®¡ç®—åŠ¨é‡è¶‹åŠ¿æŒ‡æ ‡è¿›è¡Œé¢„ç­›é€‰
    momentum_scores = []
    trend_scores = []
    
    for row in df.itertuples():
        ts_code = row.ts_code
        ind = compute_indicators_v2(ts_code, last_trade)
        momentum_scores.append(ind.get('momentum_20d', 0))
        trend_scores.append(ind.get('trend_score', 0))
    
    df['momentum_20d'] = momentum_scores
    df['trend_score'] = trend_scores
    
    # V15.0 åŠ¨é‡è¶‹åŠ¿é¢„ç­›é€‰ï¼šè¦æ±‚20æ—¥åŠ¨é‡>0ä¸”è¶‹åŠ¿å¾—åˆ†>33
    if len(df) > 0:
        momentum_mask = df['momentum_20d'] > 0
        trend_mask = df['trend_score'] > 33  # è‡³å°‘æ»¡è¶³ä¸€ä¸ªè¶‹åŠ¿æ¡ä»¶
        df = df[momentum_mask & trend_mask].copy()
    
    if len(df) == 0:
        return pd.DataFrame(), f"åŠ¨é‡è¶‹åŠ¿ç­›é€‰åæ— è‚¡ç¥¨ï¼š{last_trade}"

    # 5. é´é€‰å†³èµ›åå•
    # V15.0 ç­›é€‰ï¼šä½¿ç”¨20æ—¥åŠ¨é‡å’Œè¶‹åŠ¿å¾—åˆ†ä½œä¸ºå…¥å›´æ ‡å‡†
    limit_momentum = int(FINAL_POOL * 0.6)  # 60% æŒ‰åŠ¨é‡é€‰
    limit_trend = FINAL_POOL - limit_momentum  # 40% æŒ‰è¶‹åŠ¿é€‰
    
    df_momentum = df.sort_values('momentum_20d', ascending=False).head(limit_momentum).copy()
    
    existing_codes = set(df_momentum['ts_code'])
    df_trend = df[~df['ts_code'].isin(existing_codes)].sort_values('trend_score', ascending=False).head(limit_trend).copy()
    
    final_candidates = pd.concat([df_momentum, df_trend]).reset_index(drop=True)
    
    # é²æ£’æ€§å¼ºåŒ–ï¼šæ£€æŸ¥å€™é€‰è‚¡åœ¨å†…å­˜ä¸­çš„ D0 QFQ æ•°æ®æ˜¯å¦å®Œæ•´
    if not GLOBAL_DAILY_RAW.empty:
        try:
            codes_with_d0_data = GLOBAL_DAILY_RAW.loc[(slice(None), last_trade), :].index.get_level_values('ts_code').unique()
            final_candidates = final_candidates[final_candidates['ts_code'].isin(codes_with_d0_data)].copy()
        except KeyError:
            return pd.DataFrame(), f"è·³è¿‡ {last_trade}ï¼šæ ¸å¿ƒå†å²æ•°æ®ç¼“å­˜ä¸­ç¼ºå¤±å›æµ‹æ—¥ {last_trade} çš„å…¨éƒ¨æ•°æ® (å·²é€šè¿‡é²æ£’æ€§æ£€æŸ¥è¿‡æ»¤)"
            
    if final_candidates.empty:
        return pd.DataFrame(), f"è·³è¿‡ {last_trade}ï¼šè¯„åˆ†åˆ—è¡¨ä¸ºç©º. åŸå› ï¼šåœ¨ {len(final_candidates)} ä¸ªå·²æ£€æŸ¥çš„å€™é€‰è‚¡ä¸­ï¼Œæ‰€æœ‰è‚¡ç¥¨çš„ D0 QFQ ä»·æ ¼å‡æ— æ•ˆã€‚"

    # 6. V15.0 æ·±åº¦è¯„åˆ† (ä½¿ç”¨æ–°å› å­å’Œæ–°æƒé‡)
    records = []
    
    for row in final_candidates.itertuples():
        ts_code = row.ts_code
        
        raw_close = getattr(row, 'close', np.nan)
        
        # è®¡ç®—å¢å¼ºç‰ˆæŒ‡æ ‡
        ind = compute_indicators_v2(ts_code, last_trade) 
        d0_qfq_close = ind.get('last_close', np.nan) # æå– D0 QFQ Close Price

        # ä»…å½“ D0 QFQ Close Price æœ‰æ•ˆä¸”éé›¶æ—¶ï¼Œæ‰è¿›è¡Œæ”¶ç›Šç‡è®¡ç®—å’Œè®°å½•
        if pd.notna(d0_qfq_close) and d0_qfq_close > 1e-9:
            
            future_returns = get_future_prices(ts_code, last_trade, d0_qfq_close) 
            
            rec = {
                'ts_code': ts_code, 
                'name': getattr(row, 'name', ts_code),
                'Close': raw_close, 
                'Circ_MV (äº¿)': getattr(row, 'circ_mv_billion', np.nan),
                'Pct_Chg (%)': getattr(row, 'pct_chg', 0), 
                'turnover': getattr(row, 'turnover_rate', 0),
                'net_mf': getattr(row, 'net_mf', 0),
                # V15.0 æ–°å¢å› å­
                'momentum_20d': ind.get('momentum_20d', 0),
                'trend_score': ind.get('trend_score', 0),
                'volume_ratio': ind.get('volume_ratio', 1),
                'volume_stability': ind.get('volume_stability', 50),
                'breakout_score': ind.get('breakout_score', 0),
                'position_60d': ind.get('position_60d', 50),
                'volatility_20d': ind.get('volatility_20d', 30),
                # ä¿ç•™åŸæœ‰å› å­
                'vol_ratio': ind.get('vol_ratio', np.nan), 
                'macd': ind.get('macd_val', np.nan),
                '10d_return': ind.get('10d_return', np.nan), 
                'volatility': ind.get('volatility', np.nan), 
            }
            
            rec.update({
                'Return_D1 (%)': future_returns.get('Return_D1', np.nan),
                'Return_D3 (%)': future_returns.get('Return_D3', np.nan),
                'Return_D5 (%)': future_returns.get('Return_D5', np.nan),
            })
            
            records.append(rec)
    
    fdf = pd.DataFrame(records)
    
    if fdf.empty: 
        return pd.DataFrame(), f"è·³è¿‡ {last_trade}ï¼šè¯„åˆ†åˆ—è¡¨ä¸ºç©º. åŸå› ï¼šåœ¨ {len(final_candidates)} ä¸ªå·²æ£€æŸ¥çš„å€™é€‰è‚¡ä¸­ï¼Œæ‰€æœ‰è‚¡ç¥¨çš„ D0 QFQ ä»·æ ¼å‡æ— æ•ˆã€‚"

    # 7. V15.0 å½’ä¸€åŒ–ä¸ç­–ç•¥ç²¾è°ƒè¯„åˆ† 
    def normalize(series):
        series_nn = series.dropna() 
        if series_nn.empty or series_nn.max() == series_nn.min(): 
            return pd.Series([0.5] * len(series), index=series.index)
        return (series - series_nn.min()) / (series_nn.max() - series_nn.min() + 1e-9)

    # å½’ä¸€åŒ–æ‰€æœ‰ä½¿ç”¨çš„å› å­
    fdf['s_momentum'] = normalize(fdf['momentum_20d'])          # åŠ¨é‡è¶Šå¤§è¶Šå¥½
    fdf['s_trend'] = normalize(fdf['trend_score'])              # è¶‹åŠ¿è¶Šå¼ºè¶Šå¥½
    
    # é‡æ¯”å¾—åˆ†ï¼š1.5-3.0ä¸ºæœ€ä½³åŒºé—´
    fdf['s_volume'] = np.where(
        (fdf['volume_ratio'] >= 1.5) & (fdf['volume_ratio'] <= 3.0),
        1.0,
        np.where(
            fdf['volume_ratio'] < 1.5, 
            fdf['volume_ratio'] / 1.5, 
            3.0 / fdf['volume_ratio']
        )
    )
    
    fdf['s_breakout'] = fdf['breakout_score'] / 100           # çªç ´å¾—åˆ† (0æˆ–1)
    
    # ä½ç½®å¾—åˆ†ï¼š40-70åˆ†æœ€å¥½ï¼Œè¿‡é«˜æˆ–è¿‡ä½éƒ½å‡åˆ†
    position_score = np.where(
        (fdf['position_60d'] >= 40) & (fdf['position_60d'] <= 70),
        1.0,
        np.where(
            fdf['position_60d'] < 40, 
            fdf['position_60d'] / 40, 
            (100 - fdf['position_60d']) / 30
        )
    )
    fdf['s_position'] = position_score
    
    # æ³¢åŠ¨ç‡å¾—åˆ†ï¼šè¶Šä½è¶Šå¥½
    fdf['s_volatility'] = 1 - normalize(fdf['volatility_20d'])
    
    # ğŸš¨ V15.0 ç­–ç•¥æƒé‡ (åŠ¨é‡è¶‹åŠ¿å¢å¼º)
    w_momentum = 0.40      # åŠ¨é‡å› å­ (æ­£å‘)
    w_trend = 0.25         # è¶‹åŠ¿å› å­ (æ­£å‘)
    w_volume = 0.15        # é‡ä»·å…³ç³» (æ­£å‘)
    w_breakout = 0.10      # çªç ´å› å­ (æ­£å‘)
    w_defensive = 0.10     # é˜²å¾¡å› å­ (ä½ç½®+æ³¢åŠ¨ç‡)
    
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    score = (
        fdf['s_momentum'].fillna(0.5) * w_momentum +
        fdf['s_trend'].fillna(0.5) * w_trend +
        fdf['s_volume'].fillna(0.5) * w_volume +
        fdf['s_breakout'].fillna(0) * w_breakout +
        fdf['s_position'].fillna(0.5) * 0.05 +  # ä½ç½®å› å­å é˜²å¾¡æƒé‡çš„ä¸€åŠ
        fdf['s_volatility'].fillna(0.5) * 0.05   # æ³¢åŠ¨ç‡å› å­å é˜²å¾¡æƒé‡çš„ä¸€åŠ
    )
    
    fdf['ç»¼åˆè¯„åˆ†'] = score * 100
    fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
    fdf.index += 1

    return fdf.head(TOP_BACKTEST).copy(), None

# ---------------------------
# ä¸»è¿è¡Œå— 
# ---------------------------
if st.button(f"ğŸš€ å¼€å§‹ {BACKTEST_DAYS} æ—¥è‡ªåŠ¨å›æµ‹ (V15.0 åŠ¨é‡è¶‹åŠ¿å¢å¼ºç‰ˆ)"):
    
    st.warning("âš ï¸ **è¯·åŠ¡å¿…å…ˆæ¸…é™¤ Streamlit ç¼“å­˜ï¼**ï¼ˆå³ä¸Šè§’ä¸‰ç‚¹èœå• -> Settings -> Clear Cacheï¼‰è¿™æ˜¯è®©ç¨‹åºå¼ºåˆ¶é‡æ–°ä¸‹è½½æ•°æ®çš„å…³é”®ä¸€æ­¥ã€‚")
   
    trade_days_str = get_trade_days(backtest_date_end.strftime("%Y%m%d"), BACKTEST_DAYS)
    if not trade_days_str:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥æ—¥æœŸæˆ– Tokenã€‚")
        st.stop()
    
    # ----------------------------------------------------------------------
    # æ ¸å¿ƒä¼˜åŒ–æ­¥éª¤ï¼šé¢„åŠ è½½æ‰€æœ‰å†å²æ•°æ®
    # ----------------------------------------------------------------------
    preload_success = get_all_historical_data(trade_days_str)
    if not preload_success:
        st.error("âŒ å†å²æ•°æ®é¢„åŠ è½½å¤±è´¥ï¼Œå›æµ‹æ— æ³•è¿›è¡Œã€‚è¯·æ£€æŸ¥ Tushare Token å’Œæƒé™ã€‚")
        st.stop()
    st.success("âœ… å†å²æ•°æ®é¢„åŠ è½½å®Œæˆï¼QFQ åŸºå‡†å·²å›ºå®šã€‚ç°åœ¨å¼€å§‹æé€Ÿå›æµ‹...")
    # ----------------------------------------------------------------------
    
    st.header(f"ğŸ“ˆ æ­£åœ¨è¿›è¡Œ {BACKTEST_DAYS} ä¸ªäº¤æ˜“æ—¥çš„å›æµ‹ (V15.0 åŠ¨é‡è¶‹åŠ¿å¢å¼ºç‰ˆ)...")
    
    results_list = []
    total_days = len(trade_days_str)
    
    progress_text = st.empty()
    my_bar = st.progress(0)
    
    for i, trade_date in enumerate(trade_days_str):
        progress_text.text(f"ğŸš€ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{total_days} ä¸ªäº¤æ˜“æ—¥ï¼š{trade_date} (çº¯å†…å­˜è®¡ç®—)")
        
        daily_result_df, error = run_backtest_for_a_day(
            trade_date, TOP_BACKTEST, FINAL_POOL, MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, MIN_CIRC_MV_BILLIONS
        )
        
        if error:
            st.warning(f"{error}")
        elif not daily_result_df.empty:
            daily_result_df['Trade_Date'] = trade_date
            results_list.append(daily_result_df)
            
        my_bar.progress((i + 1) / total_days)

    progress_text.text("âœ… å›æµ‹å®Œæˆï¼Œæ­£åœ¨æ±‡æ€»ç»“æœ...")
    my_bar.empty()
    
    if not results_list:
        st.error("æ‰€æœ‰äº¤æ˜“æ—¥çš„å›æµ‹å‡å¤±è´¥æˆ–æ— ç»“æœã€‚")
        st.stop()
        
    all_results = pd.concat(results_list)
    
    st.header(f"ğŸ“Š æœ€ç»ˆå¹³å‡å›æµ‹ç»“æœ (Top {TOP_BACKTEST}ï¼Œå…± {len(all_results['Trade_Date'].unique())} ä¸ªæœ‰æ•ˆäº¤æ˜“æ—¥)")
    
    # æ˜¾ç¤ºæ‰€æœ‰è¿”å›å› å­çš„ç»Ÿè®¡ä¿¡æ¯
    st.subheader("ğŸ“ˆ é€‰è‚¡å› å­ç»Ÿè®¡")
    factor_cols = ['momentum_20d', 'trend_score', 'volume_ratio', 'breakout_score', 'position_60d', 'volatility_20d']
    factor_stats = {}
    
    for col in factor_cols:
        if col in all_results.columns:
            factor_stats[col] = {
                'å‡å€¼': all_results[col].mean(),
                'ä¸­ä½æ•°': all_results[col].median(),
                'æ ‡å‡†å·®': all_results[col].std()
            }
    
    if factor_stats:
        factor_df = pd.DataFrame(factor_stats).T
        st.dataframe(factor_df.round(2), use_container_width=True)
    
    # æ˜¾ç¤ºæ”¶ç›Šç»Ÿè®¡
    for n in [1, 3, 5]:
        col = f'Return_D{n} (%)' 
        
        filtered_returns = all_results.copy()
        valid_returns = filtered_returns.dropna(subset=[col])

        if not valid_returns.empty:
            avg_return = valid_returns[col].mean()
            hit_rate = (valid_returns[col] > 0).sum() / len(valid_returns) * 100 if len(valid_returns) > 0 else 0.0
            total_count = len(valid_returns)
            median_return = valid_returns[col].median()
            std_return = valid_returns[col].std()
        else:
            avg_return = np.nan
            hit_rate = 0.0
            total_count = 0
            median_return = np.nan
            std_return = np.nan
            
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric(f"D+{n} å¹³å‡æ”¶ç›Š", f"{avg_return:.2f}%")
        with col2:
            st.metric(f"D+{n} èƒœç‡", f"{hit_rate:.1f}%")
        with col3:
            st.metric(f"D+{n} ä¸­ä½æ•°æ”¶ç›Š", f"{median_return:.2f}%")
        with col4:
            st.metric(f"D+{n} æ ·æœ¬æ•°", f"{total_count}")
        
        # æ˜¾ç¤ºæ”¶ç›Šåˆ†å¸ƒ
        if not valid_returns.empty and len(valid_returns) > 5:
            st.caption(f"D+{n} æ”¶ç›Šåˆ†å¸ƒï¼šæœ€ä½ {valid_returns[col].min():.2f}%ï¼Œæœ€é«˜ {valid_returns[col].max():.2f}%ï¼Œæ ‡å‡†å·® {std_return:.2f}%")

    st.header("ğŸ“‹ æ¯æ—¥å›æµ‹è¯¦æƒ… (Top K æ˜ç»†)")
    
    # æ˜¾ç¤ºè¯¦ç»†çš„å›æµ‹ç»“æœ
    display_cols = ['Trade_Date', 'name', 'ts_code', 'ç»¼åˆè¯„åˆ†', 
                    'Close', 'Pct_Chg (%)', 'Circ_MV (äº¿)',
                    'momentum_20d', 'trend_score', 'volume_ratio',
                    'Return_D1 (%)', 'Return_D3 (%)', 'Return_D5 (%)']
    
    # åªæ˜¾ç¤ºå­˜åœ¨çš„åˆ—
    available_cols = [col for col in display_cols if col in all_results.columns]
    
    st.dataframe(all_results[available_cols].sort_values('Trade_Date', ascending=False), 
                 use_container_width=True,
                 column_config={
                     'momentum_20d': st.column_config.NumberColumn(format="%.1f"),
                     'trend_score': st.column_config.NumberColumn(format="%.1f"),
                     'volume_ratio': st.column_config.NumberColumn(format="%.2f"),
                     'Return_D1 (%)': st.column_config.NumberColumn(format="%.2f"),
                     'Return_D3 (%)': st.column_config.NumberColumn(format="%.2f"),
                     'Return_D5 (%)': st.column_config.NumberColumn(format="%.2f"),
                 })
