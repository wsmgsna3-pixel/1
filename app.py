# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V30.12.3 æ•æ·æ”¹è¿›ç‰ˆ (MACD 8-17-5)
------------------------------------------------
ç‰ˆæœ¬ç‰¹æ€§ (Agile Edition):
1. **ç­–ç•¥å‡çº§**ï¼šMACD å‚æ•°è°ƒæ•´ä¸º (8, 17, 5)ï¼Œæ›´çµæ•æ•æ‰èµ·æ¶¨ç‚¹ã€‚
2. **ç¨³å®šå¹¶å‘**ï¼š2 çº¿ç¨‹ä¸‹è½½ï¼Œæœç» Tushare é™æµæŠ¥é”™ã€‚
3. **å‘é‡åŒ–è®¡ç®—**ï¼šå…¨å¸‚åœºçŸ©é˜µè®¡ç®—ï¼Œè®¡ç®—é€Ÿåº¦æå¿«ã€‚
4. **ç‰¹è‰²æ•°æ®**ï¼šåˆ©ç”¨ cyq_perf (ç­¹ç è·åˆ©ç›˜) æ•æ‰ä¸»å‡æµªã€‚
------------------------------------------------
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import time
import concurrent.futures

warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€å˜é‡åˆå§‹åŒ–
# ---------------------------
pro = None
# ç¼“å­˜å…¨å¸‚åœºè®¡ç®—å¥½çš„æŒ‡æ ‡ï¼Œé¿å…é‡å¤è®¡ç®—
GLOBAL_INDICATORS = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame()
GLOBAL_STOCK_INDUSTRY = {}
GLOBAL_CHIP_DATA = {} # ç­¹ç æ•°æ®ç¼“å­˜

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ V30.12.3 æ•æ·ç‰ˆ", layout="wide")
st.title("âš¡ é€‰è‚¡ç‹ V30.12.3ï¼šMACD(8,17,5) æ•æ·ç‰ˆ")
st.markdown("""
**âš™ï¸ ç­–ç•¥å˜æ›´ï¼š**
* **MACD å‚æ•°**ï¼šç”± (12,26,9) è°ƒæ•´ä¸º **(8, 17, 5)**
* **é€»è¾‘**ï¼šæ›´æ•æ„Ÿçš„å‡çº¿ç³»ç»Ÿï¼Œæ—¨åœ¨æå‰å‘ç°è¶…çŸ­çº¿çˆ†å‘ä¿¡å·ã€‚
""")

# ---------------------------
# åŸºç¡€ API å‡½æ•°
# ---------------------------
@st.cache_data(ttl=3600*12)
def safe_get(func_name, **kwargs):
    global pro
    if pro is None:
        return pd.DataFrame()
   
    func = getattr(pro, func_name)
    try:
        return func(**kwargs)
    except Exception as e:
        time.sleep(0.5) # ç¨å¾®ç­‰å¾…
        try:
            return func(**kwargs)
        except:
            return pd.DataFrame()

def get_trade_days(end_date_str, num_days):
    # è·å–è¶³å¤Ÿé•¿çš„äº¤æ˜“æ—¥å†ä»¥ç¡®ä¿æŒ‡æ ‡è®¡ç®—ï¼ˆå‘å‰æ¨ 250 å¤©ï¼‰
    lookback_days = max(num_days + 250, 365)
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=lookback_days)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    
    if cal.empty or 'cal_date' not in cal.columns:
        return []
        
    trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)
    # è¿”å›æ‰€æœ‰éœ€è¦çš„æ—¥æœŸï¼ˆåŒ…æ‹¬å›æµ‹æœŸå’Œè®¡ç®—æŒ‡æ ‡çš„ç¼“å†²æœŸï¼‰
    return trade_days_df['cal_date'].tolist()

# --- è¡Œä¸šåŠ è½½ ---
@st.cache_data(ttl=3600*24*7)
def load_industry_mapping():
    global pro
    if pro is None: return {}
    try:
        sw_indices = pro.index_classify(level='L1', src='SW2021')
        if sw_indices.empty: return {}
        index_codes = sw_indices['index_code'].tolist()
        all_members = []
        
        # å³ä½¿æ˜¯è¡Œä¸šè·å–ï¼Œä¹Ÿé™åˆ¶ä¸€ä¸‹å¹¶å‘ï¼Œé˜²æ­¢åˆå§‹åŒ–å°±å´©
        def fetch_member(idx_code):
            return safe_get('index_member', index_code=idx_code, is_new='Y')

        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            results = executor.map(fetch_member, index_codes)
            for res in results:
                if not res.empty: all_members.append(res)
                
        if not all_members: return {}
        full_df = pd.concat(all_members)
        full_df = full_df.drop_duplicates(subset=['con_code'])
        return dict(zip(full_df['con_code'], full_df['index_code']))
    except Exception:
        return {}

# ---------------------------
# æ ¸å¿ƒï¼šæ‰¹é‡æŒ‡æ ‡è®¡ç®— (å‘é‡åŒ–) - å·²ä¿®æ”¹ MACD
# ---------------------------
def calculate_all_indicators_vectorized(daily_df, adj_df):
    """
    ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„ RSI, MACD, MA
    """
    st.info("âš¡ æ­£åœ¨è¿›è¡Œå…¨å¸‚åœºå‘é‡åŒ–æŒ‡æ ‡è®¡ç®— (MACD 8-17-5)...")
    
    # 1. å‡†å¤‡æ•°æ®ï¼šåˆå¹¶å¤æƒå› å­
    df = daily_df.copy()
    if not adj_df.empty:
        df = df.join(adj_df['adj_factor'])

    # ç®€å•å‰å¤æƒå¤„ç†è®¡ç®—ç”¨äºæŒ‡æ ‡çš„ä»·æ ¼
    df['adj_factor'] = df['adj_factor'].fillna(1.0)
    df['close_calc'] = df['close'] * df['adj_factor']
    
    # 2. æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„è®¡ç®—
    grouped = df.groupby(level='ts_code')
    
    # === [ä¿®æ”¹ç‚¹] MACD (8, 17, 5) ===
    # å¿«çº¿ 8
    ema_fast = grouped['close_calc'].transform(lambda x: x.ewm(span=8, adjust=False).mean())
    # æ…¢çº¿ 17
    ema_slow = grouped['close_calc'].transform(lambda x: x.ewm(span=17, adjust=False).mean())
    
    df['diff'] = ema_fast - ema_slow
    # ä¿¡å·çº¿ 5
    df['dea'] = df.groupby(level='ts_code')['diff'].transform(lambda x: x.ewm(span=5, adjust=False).mean())
    df['macd'] = (df['diff'] - df['dea']) * 2
    
    # --- RSI (12) ---
    def calc_rsi_series(series, period=12):
        delta = series.diff()
        gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
        loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
        rs = gain / (loss + 1e-9)
        return 100 - (100 / (1 + rs))
    
    df['rsi'] = grouped['close_calc'].transform(lambda x: calc_rsi_series(x, 12))
    
    # --- MA20, MA60 ---
    df['ma20'] = grouped['close_calc'].transform(lambda x: x.rolling(window=20).mean())
    df['ma60'] = grouped['close_calc'].transform(lambda x: x.rolling(window=60).mean())
    
    # --- å®ä½“ä½ç½® & ä¸Šå½±çº¿ (åŸºäºåŸå§‹ High/Low/Close è®¡ç®—å³å¯ï¼Œæ¯”ä¾‹ä¸å˜) ---
    df['real_body_top'] = df[['open', 'close']].max(axis=1)
    df['upper_shadow_pct'] = (df['high'] - df['real_body_top']) / (df['real_body_top'] + 1e-9) * 100
    
    range_len = df['high'] - df['low']
    df['body_pos'] = (df['close'] - df['low']) / (range_len + 1e-9)
    
    return df[['close', 'pct_chg', 'rsi', 'macd', 'ma20', 'ma60', 'upper_shadow_pct', 'body_pos']]


# ---------------------------
# æ•°æ®è·å–æ ¸å¿ƒ (åŒçº¿ç¨‹ç¨³å®šç‰ˆ)
# ---------------------------
def get_all_data_and_calc(trade_days_full_list):
    global GLOBAL_DAILY_RAW, GLOBAL_INDICATORS, GLOBAL_CHIP_DATA, GLOBAL_STOCK_INDUSTRY
    
    if not trade_days_full_list: return False
    
    with st.spinner("ğŸš€ [é˜²é™æµæ¨¡å¼] æ­£åœ¨æ‹‰å–å¸‚åœºæ•°æ® (2çº¿ç¨‹)..."):
        GLOBAL_STOCK_INDUSTRY.update(load_industry_mapping())
        
        daily_list = []
        adj_list = []
        
        # å®šä¹‰ä»»åŠ¡
        def fetch_daily(date):
            d = safe_get('daily', trade_date=date)
            a = safe_get('adj_factor', trade_date=date)
            return d, a

        # æ”¹ä¸º 2 çº¿ç¨‹ï¼Œæå…¶å®‰å…¨
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            future_to_date = {executor.submit(fetch_daily, date): date for date in trade_days_full_list}
            
            bar = st.progress(0, text="æ•°æ®åŒæ­¥ä¸­...")
            for i, future in enumerate(concurrent.futures.as_completed(future_to_date)):
                d, a = future.result()
                if not d.empty: daily_list.append(d)
                if not a.empty: adj_list.append(a)
                bar.progress((i+1)/len(trade_days_full_list))
            bar.empty()
            
    if not daily_list:
        st.error("æ•°æ®è·å–å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–æ¥å£è¿”å›ç©º")
        return False

    with st.spinner("æ­£åœ¨æ„å»ºå…¨å¸‚åœºå› å­çŸ©é˜µ..."):
        # åˆå¹¶æ•°æ®
        daily_df = pd.concat(daily_list).drop_duplicates(subset=['ts_code', 'trade_date'])
        adj_df = pd.concat(adj_list).drop_duplicates(subset=['ts_code', 'trade_date'])
        
        # è®¾ç½®ç´¢å¼•
        daily_df = daily_df.set_index(['ts_code', 'trade_date']).sort_index()
        adj_df = adj_df.set_index(['ts_code', 'trade_date']).sort_index()
        
        GLOBAL_DAILY_RAW = daily_df # ä¿å­˜åŸå§‹æ•°æ®ç”¨äºåç»­æŸ¥ä»·æ ¼
        
        # è®¡ç®—æŒ‡æ ‡
        GLOBAL_INDICATORS = calculate_all_indicators_vectorized(daily_df, adj_df)
        
    return True

# ---------------------------
# å›æµ‹é€»è¾‘
# ---------------------------
def run_backtest_optimized(target_date, TOP_K, PARAMS):
    """
    é’ˆå¯¹å•æ—¥è¿›è¡Œç­›é€‰
    """
    global GLOBAL_INDICATORS, GLOBAL_DAILY_RAW, GLOBAL_STOCK_INDUSTRY
    
    # 1. è·å–å½“å¤©çš„æˆªé¢æ•°æ®
    try:
        idx = pd.IndexSlice
        today_data = GLOBAL_INDICATORS.loc[idx[:, target_date], :].reset_index(level='trade_date', drop=True)
    except KeyError:
        return pd.DataFrame(), "æ— å½“æ—¥æ•°æ®"
        
    # 2. åŸºç¡€è¿‡æ»¤
    df = today_data[today_data['pct_chg'] <= PARAMS['max_prev_pct']]
    
    # è·å– daily_basic
    daily_basic = safe_get('daily_basic', trade_date=target_date, fields='ts_code,turnover_rate,circ_mv,name')
    if daily_basic.empty: return pd.DataFrame(), "æ— åŸºç¡€æ•°æ®"
    
    df = df.join(daily_basic.set_index('ts_code'))
    df = df.dropna(subset=['close']) 
    
    # å¸‚å€¼ä¸ä»·æ ¼è¿‡æ»¤
    df['circ_mv_billion'] = df['circ_mv'] / 10000
    df = df[(df['circ_mv_billion'] >= PARAMS['min_mv']) & (df['circ_mv_billion'] <= PARAMS['max_mv'])]
    df = df[df['turnover_rate'] <= PARAMS['max_turnover']]
    df = df[df['close'] >= PARAMS['min_price']]
    
    # 3. å½¢æ€é£æ§
    df = df[df['upper_shadow_pct'] <= PARAMS['max_upper_shadow']]
    df = df[df['body_pos'] >= PARAMS['min_body_pos']]
    
    # 4. ç­¹ç æ•°æ®
    chip_df = safe_get('cyq_perf', trade_date=target_date)
    chip_map = {}
    if not chip_df.empty:
        chip_map = dict(zip(chip_df['ts_code'], chip_df['winner_rate']))
    
    candidates = []
    
    # è·å–æ¿å—æ•°æ®
    strong_industry_codes = set()
    try:
        sw_df = safe_get('sw_daily', trade_date=target_date)
        if not sw_df.empty:
            strong_sw = sw_df[sw_df['pct_chg'] >= PARAMS['sector_threshold']]
            strong_industry_codes = set(strong_sw['index_code'].tolist())
    except: pass
    
    # 5. å¾ªç¯ç­›é€‰
    for ts_code, row in df.iterrows():
        # åˆå§‹åŒ–å˜é‡
        ind_code = None
        
        # æ¿å—è¿‡æ»¤
        if GLOBAL_STOCK_INDUSTRY and strong_industry_codes:
            ind_code = GLOBAL_STOCK_INDUSTRY.get(ts_code)
            if ind_code and (ind_code not in strong_industry_codes): continue
            
        # ç­¹ç è¿‡æ»¤
        win_rate = chip_map.get(ts_code, 50)
        if win_rate < PARAMS['chip_min_win_rate']: continue
        
        # RSI æ‹¦æˆª
        if row['rsi'] > PARAMS['rsi_limit']: continue 
        
        # å‡çº¿å¤šå¤´
        if row['close'] < row['ma60']: continue
        
        # è®¡ç®—å¾—åˆ† (æ³¨æ„ï¼šè¿™é‡Œçš„ macd å·²ç»æ˜¯ 8-17-5 çš„å€¼äº†)
        score = row['macd'] * 1000
        if win_rate > 90: score += 1000
        if row['rsi'] > 90: score += 3000 
        
        candidates.append({
            'ts_code': ts_code,
            'name': row.get('name', ts_code),
            'Close': row['close'],
            'Pct_Chg': row['pct_chg'],
            'rsi': row['rsi'],
            'winner_rate': win_rate,
            'Score': score,
            'Sector_Boost': 'Yes' if (ind_code and ind_code in strong_industry_codes) else 'No'
        })
        
    if not candidates: return pd.DataFrame(), "æ— æ ‡çš„"
    
    final_df = pd.DataFrame(candidates).sort_values('Score', ascending=False).head(TOP_K)
    
    # 6. è®¡ç®—æœªæ¥æ”¶ç›Š (é€šè¿‡é—­åŒ…ä¼ é€’å½“å‰Close)
    def get_returns_safe(code, current_close):
        try:
            idx = pd.IndexSlice
            # æ‰¾åˆ°è¯¥è‚¡ç¥¨åœ¨ target_date ä¹‹åçš„æ•°æ®
            future_data = GLOBAL_DAILY_RAW.loc[idx[code, :]]
            future_data = future_data[future_data.index > target_date].head(6)
            
            if future_data.empty: return np.nan, np.nan, np.nan
            
            d1_data = future_data.iloc[0]
            
            # ä¸€å­—æ¶¨åœæ— æ³•ä¹°å…¥åˆ¤æ–­
            limit_ratio = 1.195 if code.startswith('688') or code.startswith('300') else 1.095
            
            # ä½¿ç”¨ D1 çš„ pre_closeï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”¨ Tæ—¥çš„ close
            ref_close = d1_data.get('pre_close', current_close)
            if pd.isna(ref_close): ref_close = current_close
            
            if d1_data['open'] >= ref_close * limit_ratio:
                return np.nan, np.nan, np.nan # ä¸€å­—æ¿ä¹°ä¸è¿›
            
            # ä¹°å…¥ä»·ï¼šå¼€ç›˜ä»· + 1.5% æ»‘ç‚¹
            buy_price = d1_data['open'] * 1.015 
            
            # ç¡®ä¿ä¹°å…¥ä»·ä¸è¶…è¿‡æ¶¨åœä»·
            limit_up_price = ref_close * (1.20 if limit_ratio > 1.1 else 1.10)
            if buy_price > limit_up_price:
                buy_price = limit_up_price 
                
            rets = []
            for d in [1, 3, 5]:
                if len(future_data) >= d:
                    sell_price = future_data.iloc[d-1]['close']
                    ret = (sell_price - buy_price) / buy_price * 100
                    rets.append(ret)
                else:
                    rets.append(np.nan)
            return rets
        except Exception as e:
            return np.nan, np.nan, np.nan

    # æ‰¹é‡è®¡ç®—æ”¶ç›Š
    returns = final_df.apply(lambda row: get_returns_safe(row['ts_code'], row['Close']), axis=1)
    
    if not returns.empty:
        # returns æ˜¯ä¸€ä¸ªåŒ…å« list çš„ Seriesï¼Œéœ€è¦æ‹†åˆ†
        final_df['Return_D1 (%)'] = returns.apply(lambda x: x[0])
        final_df['Return_D3 (%)'] = returns.apply(lambda x: x[1])
        final_df['Return_D5 (%)'] = returns.apply(lambda x: x[2])
    
    return final_df, None

# ---------------------------
# UI ä¸»ç¨‹åº
# ---------------------------
with st.sidebar:
    st.header("âš™ï¸ æ•æ·ç‰ˆå‚æ•°é…ç½®")
    backtest_date_end = st.date_input("åˆ†ææˆªæ­¢æ—¥æœŸ", value=datetime.now().date())
    BACKTEST_DAYS = st.number_input("åˆ†æå¤©æ•°", value=30, step=1)
    TOP_BACKTEST = st.number_input("æ¯æ—¥ä¼˜é€‰ TopK", value=5)
    
    st.markdown("---")
    col1, col2 = st.columns(2)
    MIN_PRICE = col1.number_input("æœ€ä½è‚¡ä»·", value=10.0)
    MIN_MV = col2.number_input("æœ€å°å¸‚å€¼(äº¿)", value=50.0)
    MAX_MV = st.number_input("æœ€å¤§å¸‚å€¼(äº¿)", value=1000.0)
    
    CHIP_MIN_WIN_RATE = st.number_input("æœ€ä½è·åˆ©ç›˜ (%)", value=70.0)
    MAX_PREV_PCT = st.number_input("æ˜¨æ—¥æ¶¨å¹…é™åˆ¶ (%)", value=19.0)
    RSI_LIMIT = st.number_input("RSI æ‹¦æˆªçº¿", value=100.0)
    
    SECTOR_THRESHOLD = st.number_input("æ¿å—æ¶¨å¹… (%)", value=1.5)
    MAX_UPPER_SHADOW = st.number_input("ä¸Šå½±çº¿ (%)", value=5.0)
    MIN_BODY_POS = st.number_input("å®ä½“ä½ç½®", value=0.6)
    MAX_TURNOVER_RATE = st.number_input("æ¢æ‰‹ç‡ (%)", value=20.0)

TS_TOKEN = st.text_input("Tushare Token", type="password")

if TS_TOKEN:
    ts.set_token(TS_TOKEN)
    pro = ts.pro_api()

if st.button("ğŸš€ å¯åŠ¨æ•æ·å›æµ‹"):
    if not TS_TOKEN: st.error("è¯·è¾“å…¥ Token"); st.stop()
    
    full_dates = get_trade_days(backtest_date_end.strftime("%Y%m%d"), int(BACKTEST_DAYS))
    if not full_dates: st.error("æ—¥æœŸè·å–å¤±è´¥"); st.stop()
    
    trade_dates = full_dates[:int(BACKTEST_DAYS)]
    
    # 1. è·å–å…¨é‡æ•°æ® (2çº¿ç¨‹)
    if not get_all_data_and_calc(full_dates): st.stop()
    
    # 2. å¾ªç¯å›æµ‹
    results = []
    params = {
        'min_price': MIN_PRICE, 'min_mv': MIN_MV, 'max_mv': MAX_MV,
        'chip_min_win_rate': CHIP_MIN_WIN_RATE, 'max_prev_pct': MAX_PREV_PCT,
        'rsi_limit': RSI_LIMIT, 'sector_threshold': SECTOR_THRESHOLD,
        'max_upper_shadow': MAX_UPPER_SHADOW, 'min_body_pos': MIN_BODY_POS,
        'max_turnover': MAX_TURNOVER_RATE
    }
    
    bar = st.progress(0, text="ç­–ç•¥ç­›é€‰ä¸­...")
    for i, date in enumerate(trade_dates):
        res, err = run_backtest_optimized(date, int(TOP_BACKTEST), params)
        if not res.empty:
            res['Trade_Date'] = date
            results.append(res)
        bar.progress((i+1)/len(trade_dates))
    bar.empty()
    
    if results:
        all_res = pd.concat(results)
        
        st.header("ğŸ“Š V30.12.3 æ•æ·ç‰ˆä»ªè¡¨ç›˜ (MACD 8-17-5)")
        
        cols = st.columns(3)
        for idx, n in enumerate([1, 3, 5]):
            col_name = f'Return_D{n} (%)'
            valid = all_res.dropna(subset=[col_name])
            if not valid.empty:
                avg = valid[col_name].mean()
                win = (valid[col_name] > 0).mean() * 100
                max_dd = valid[col_name].min()
                cols[idx].metric(f"D+{n} å‡ç›Š/èƒœç‡", f"{avg:.2f}% / {win:.1f}%", f"æœ€å¤§å›æ’¤: {max_dd:.2f}%")

        st.dataframe(all_res, use_container_width=True)
        
        csv = all_res.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å›æµ‹ç»“æœ (CSV)",
            data=csv,
            file_name=f"{datetime.now().strftime('%Y-%m-%d_%H-%M')}_agile_export.csv",
            mime="text/csv",
        )
            
    else:
        st.warning("âš ï¸ æ²¡æœ‰é€‰å‡ºè‚¡ç¥¨ã€‚")
