# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V30.6 å¼ºå¼±å¸‚è‡ªé€‚åº”ç­–ç•¥ (å³ä¾§å®æˆ˜æ¨¡æ‹Ÿç‰ˆ)
V30.6 æ›´æ–°å†…å®¹ï¼š
1. [å®æˆ˜æ¨¡æ‹Ÿ] å¼•å…¥â€œå³ä¾§ä¹°å…¥é˜ˆå€¼â€æœºåˆ¶ï¼Œæ¨¡æ‹Ÿ 9:40 ç¡®è®¤ä¸Šæ¶¨åä¹°å…¥ã€‚
   - åªæœ‰ D1 æœ€é«˜ä»· > å¼€ç›˜ä»· * (1 + é˜ˆå€¼) æ‰æˆäº¤ï¼Œå¦åˆ™è®°ä¸ºç©ºä»“ã€‚
2. [æ•°æ®ä¼˜åŒ–] ä¿æŒ V30.5 çš„å†…å­˜ä¼˜åŒ–æ–¹æ¡ˆï¼Œæ”¯æŒé•¿å‘¨æœŸå›æµ‹ã€‚
3. [å‚æ•°å¢å¼º] ä¾§è¾¹æ å¯è°ƒæ•´ä¹°å…¥é˜ˆå€¼ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import time  
warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€å˜é‡åˆå§‹åŒ–
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} 


# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V30.6 å³ä¾§å®æˆ˜ç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V30.6 å¼ºå¼±å¸‚è‡ªé€‚åº”ç­–ç•¥ï¼ˆğŸ¹ å³ä¾§ç¡®è®¤ä¹°å…¥ / âš¡ å†…å­˜ä¼˜åŒ–ï¼‰")
st.markdown("ğŸ¯ **V30.6 æ ¸å¿ƒé€»è¾‘ï¼š** æ¨¡æ‹Ÿå®æˆ˜æ“ä½œï¼Œåªæœ‰åœ¨æ¬¡æ—¥ç›˜ä¸­æ¶¨å¹…è¾¾åˆ°è®¾å®šé˜ˆå€¼ï¼ˆå¦‚ +1.5%ï¼‰æ—¶æ‰ä¹°å…¥ï¼Œè¿‡æ»¤æ‰å¼€ç›˜å³ä¸‹è·Œçš„æ— æ•ˆäº¤æ˜“ã€‚")


# ---------------------------
# è¾…åŠ©å‡½æ•° 
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    """å®‰å…¨è°ƒç”¨ Tushare API"""
    global pro
    if pro is None:
        return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        if kwargs.get('is_index'):
             df = pro.index_daily(**kwargs)
        else:
            df = func(**kwargs)

        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception as e:
        return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    """è·å– num_days ä¸ªäº¤æ˜“æ—¥ä½œä¸ºé€‰è‚¡æ—¥"""
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 3)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    
    if cal.empty or 'is_open' not in cal.columns:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œè¯·æ£€æŸ¥ Token æˆ– Tushare æƒé™ã€‚")
        return []
    
    trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)
    trade_days_df = trade_days_df[trade_days_df['cal_date'] <= end_date_str]
    return trade_days_df['cal_date'].head(num_days).tolist()


# ----------------------------------------------------------------------
# ç¼“å­˜ä¸æ•°æ®æ‹‰å–
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24)
def fetch_and_cache_daily_data(date):
    """å®‰å…¨æ‹‰å–å¹¶ç¼“å­˜å•ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®"""
    adj_df = safe_get('adj_factor', trade_date=date)
    daily_df = safe_get('daily', trade_date=date)
    return {'adj': adj_df, 'daily': daily_df}

def get_all_historical_data(trade_days_list):
    """
    é¢„åŠ è½½æ•°æ®ï¼šä¿ç•™æ ¸å¿ƒåˆ—å¹¶å‹ç¼©ç±»å‹ (float32) ä»¥èŠ‚çœå†…å­˜
    """
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS
    
    if not trade_days_list: return False
    
    latest_trade_date = max(trade_days_list) 
    earliest_trade_date = min(trade_days_list)
    
    # æ‰©å¤§æ•°æ®è·å–èŒƒå›´ (150å¤©å†å² + 20å¤©æœªæ¥)
    start_date_dt = datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=150)
    end_date_dt = datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=20)
    
    start_date = start_date_dt.strftime("%Y%m%d")
    end_date = end_date_dt.strftime("%Y%m%d")
    
    all_trade_dates_df = safe_get('trade_cal', start_date=start_date, end_date=end_date, is_open='1')
    if all_trade_dates_df.empty:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ã€‚")
        return False
    
    all_dates = all_trade_dates_df['cal_date'].tolist()
    st.info(f"â³ æ­£åœ¨æŒ‰æ—¥æœŸå¾ªç¯ä¸‹è½½ {start_date} åˆ° {end_date} é—´çš„å…¨å¸‚åœºæ•°æ®...")

    adj_factor_data_list = []
    daily_data_list = []
    
    download_progress = st.progress(0, text="ä¸‹è½½è¿›åº¦ (æŒ‰æ—¥æœŸå¾ªç¯)...")
    
    for i, date in enumerate(all_dates):
        try:
            cached_data = fetch_and_cache_daily_data(date)
            if not cached_data['adj'].empty:
                adj_factor_data_list.append(cached_data['adj'])
            if not cached_data['daily'].empty:
                daily_data_list.append(cached_data['daily'])
            download_progress.progress((i + 1) / len(all_dates), text=f"ä¸‹è½½è¿›åº¦ï¼šå¤„ç†æ—¥æœŸ {date}")
        except Exception:
            continue 
            
    download_progress.progress(1.0, text="ä¸‹è½½è¿›åº¦ï¼šåˆå¹¶æ•°æ®...")
    download_progress.empty()

    if not adj_factor_data_list or not daily_data_list:
        st.error("âŒ ä¸¥é‡é”™è¯¯ï¼šæ— æ³•è·å–å†å²æ•°æ®ã€‚")
        return False
        
    adj_factor_data = pd.concat(adj_factor_data_list)
    adj_factor_data['adj_factor'] = pd.to_numeric(adj_factor_data['adj_factor'], errors='coerce').fillna(0)
    GLOBAL_ADJ_FACTOR = adj_factor_data.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1]) 
    
    # [V30.5/6] å†…å­˜ä¼˜åŒ–ï¼šåªä¿ç•™æ ¸å¿ƒåˆ—
    cols_to_keep = ['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'vol']
    valid_cols = [c for c in cols_to_keep if c in daily_data_list[0].columns]
    daily_raw_data = pd.concat(daily_data_list)[valid_cols]
    
    # [V30.5/6] å†…å­˜ä¼˜åŒ–ï¼šå¼ºåˆ¶è½¬æ¢ç±»å‹ä¸º float32
    float_cols = ['open', 'high', 'low', 'close', 'vol']
    for col in float_cols:
        if col in daily_raw_data.columns:
            daily_raw_data[col] = pd.to_numeric(daily_raw_data[col], errors='coerce').astype('float32')

    GLOBAL_DAILY_RAW = daily_raw_data.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1])

    latest_global_date = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
    if latest_global_date:
        try:
            latest_adj_df = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_global_date), 'adj_factor']
            GLOBAL_QFQ_BASE_FACTORS = latest_adj_df.droplevel(1).to_dict()
        except Exception:
            GLOBAL_QFQ_BASE_FACTORS = {}
    
    return True


# ----------------------------------------------------------------------
# æ•°æ®åˆ‡ç‰‡å‡½æ•°
# ----------------------------------------------------------------------
def get_qfq_data_v4_optimized_final(ts_code, start_date, end_date):
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
  
    if GLOBAL_DAILY_RAW.empty or GLOBAL_ADJ_FACTOR.empty: return pd.DataFrame()
        
    latest_adj_factor = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, np.nan)
    if pd.isna(latest_adj_factor) or latest_adj_factor < 1e-9: return pd.DataFrame() 

    try:
        daily_df_full = GLOBAL_DAILY_RAW.loc[ts_code]
        daily_df = daily_df_full.loc[(daily_df_full.index >= start_date) & (daily_df_full.index <= end_date)]
        adj_factor_series_full = GLOBAL_ADJ_FACTOR.loc[ts_code]['adj_factor']
        adj_factor_series = adj_factor_series_full.loc[(adj_factor_series_full.index >= start_date) & (adj_factor_series_full.index <= end_date)]
    except KeyError:
        return pd.DataFrame()
    
    if daily_df.empty or adj_factor_series.empty: return pd.DataFrame()
            
    df = daily_df.merge(adj_factor_series.rename('adj_factor'), left_index=True, right_index=True, how='left')
    df = df.dropna(subset=['adj_factor'])
    
    # å¤æƒè®¡ç®—
    df = df.sort_index()
    for col in ['open', 'high', 'low', 'close']:
        if col in df.columns:
            df[col + '_qfq'] = df[col] * df['adj_factor'] / latest_adj_factor
    
    df = df.reset_index().rename(columns={'trade_date': 'trade_date_str'})
    df['trade_date'] = pd.to_datetime(df['trade_date_str'], format='%Y%m%d')
    df = df.sort_values('trade_date').set_index('trade_date_str')
    
    for col in ['open', 'high', 'low', 'close']:
        if col + '_qfq' in df.columns: df[col] = df[col + '_qfq']
            
    return df[['open', 'high', 'low', 'close', 'vol']].copy() 

# ----------------------------------------------------------------------
# [V30.6 æ ¸å¿ƒ] è®¡ç®—æœªæ¥æ”¶ç›Š (å³ä¾§äº¤æ˜“æ¨¡æ‹Ÿ)
# ----------------------------------------------------------------------
def get_future_prices_right_side(ts_code, selection_date, days_ahead=[1, 3, 5], buy_threshold_pct=1.5):
    """
    æ¨¡æ‹Ÿå®æˆ˜ï¼šåªæœ‰å½“ D1 æ—¥å†…æ¶¨å¹…è¶…è¿‡é˜ˆå€¼ (buy_threshold_pct) æ—¶æ‰ä¹°å…¥ã€‚
    """
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    start_date_future = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_date_future = (d0 + timedelta(days=20)).strftime("%Y%m%d")
    
    # è·å–æœªæ¥æ•°æ®
    hist = get_qfq_data_v4_optimized_final(ts_code, start_date=start_date_future, end_date=end_date_future)
    
    results = {}
    for n in days_ahead: results[f'Return_D{n}'] = np.nan

    if hist.empty or len(hist) < 1:
        return results
        
    # --- å³ä¾§ç¡®è®¤é€»è¾‘ ---
    d1_data = hist.iloc[0]
    d1_open = d1_data['open']
    d1_high = d1_data['high']
    
    # è®¾å®šä¹°å…¥ä»·æ ¼ï¼šå¼€ç›˜ä»· * (1 + é˜ˆå€¼%)
    # ä¾‹å¦‚ï¼šå¼€ç›˜ 10.0ï¼Œé˜ˆå€¼ 1.5%ï¼Œåˆ™å¿…é¡»æ¶¨åˆ° 10.15 æ‰ä¹°å…¥ï¼Œä¹°å…¥ä»·å³ä¸º 10.15
    buy_price_threshold = d1_open * (1 + buy_threshold_pct / 100.0)
    
    if buy_price_threshold <= 1e-9: return results

    # [è¿‡æ»¤]ï¼šå¦‚æœå½“å¤©æœ€é«˜ä»·éƒ½æ²¡æ‘¸åˆ°ä¹°å…¥ä»·ï¼Œè¯´æ˜å…¨å¤©å¼±åŠ¿ï¼Œæœªæˆäº¤
    if d1_high < buy_price_threshold:
        return results # è¿”å› NaNï¼Œä»£è¡¨ç©ºä»“/è·³è¿‡

    # --- æˆäº¤ï¼Œè®¡ç®—æ”¶ç›Š ---
    for n in days_ahead:
        col_name = f'Return_D{n}'
        idx = n - 1
        if len(hist) > idx:
            sell_price = hist.iloc[idx]['close'] # å‡è®¾ N å¤©åæ”¶ç›˜å–å‡º
            # æ”¶ç›Šç‡ = (å–å‡ºä»· - å³ä¾§ç¡®è®¤ä¹°å…¥ä»·) / å³ä¾§ç¡®è®¤ä¹°å…¥ä»·
            results[col_name] = (sell_price / buy_price_threshold - 1) * 100
            
    return results

# ----------------------------------------------------------------------
# æŒ‡æ ‡è®¡ç®—
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*12) 
def compute_indicators(ts_code, end_date):
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=120)).strftime("%Y%m%d")
    df = get_qfq_data_v4_optimized_final(ts_code, start_date=start_date, end_date=end_date)
    
    res = {}
    if df.empty or len(df) < 3 or 'close' not in df.columns: return res
        
    if len(df) >= 2:
       df['pct_chg'] = df['close'].pct_change().fillna(0) * 100 
    else:
         df['pct_chg'] = 0.0
         
    close = df['close']
    res['last_close'] = close.iloc[-1] 
    
    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        res['macd_val'] = ((diff - dea) * 2).iloc[-1]
    else: res['macd_val'] = np.nan
        
    if len(close) >= 20: res['ma20'] = close.tail(20).mean()
    else: res['ma20'] = np.nan
        
    res['volatility'] = df['pct_chg'].tail(10).std() if len(df)>=10 else 0
    
    if len(df) >= 60:
        hist_60 = df.tail(60)
        min_low = hist_60['low'].min()
        max_high = hist_60['high'].max()
        current_close = hist_60['close'].iloc[-1]
        if max_high == min_low: res['position_60d'] = 50.0 
        else: res['position_60d'] = (current_close - min_low) / (max_high - min_low) * 100
    else: res['position_60d'] = np.nan 
    
    return res

@st.cache_data(ttl=3600*12)
def get_market_state(trade_date):
    """åˆ¤æ–­å¸‚åœºçŠ¶æ€"""
    start_date = (datetime.strptime(trade_date, "%Y%m%d") - timedelta(days=40)).strftime("%Y%m%d")
    index_data = safe_get('daily', ts_code='000300.SH', start_date=start_date, end_date=trade_date, is_index=True)
    
    if index_data.empty or len(index_data) < 20: return 'Weak'

    index_data['close'] = pd.to_numeric(index_data['close'], errors='coerce').astype(float)
    index_data = index_data.sort_values('trade_date', ascending=True)

    latest_close = index_data.iloc[-1]['close']
    ma20 = index_data['close'].tail(20).mean()

    return 'Strong' if latest_close > ma20 else 'Weak'
      
        
# ----------------------------------------------------
# ä¾§è¾¹æ å‚æ•° 
# ----------------------------------------------------
with st.sidebar:
    st.header("1. å›æµ‹è®¾ç½®")
    backtest_date_end = st.date_input("å›æµ‹ç»“æŸæ—¥æœŸ", value=datetime.now().date(), max_value=datetime.now().date())
    
    BACKTEST_DAYS = int(st.number_input("**å›æµ‹å¤©æ•° (N)**", value=30, step=1, help="é«˜ç§¯åˆ†ç”¨æˆ·å»ºè®®è®¾ç½® 100-200 å¤©"))
    
    st.markdown("---")
    st.header("2. å®æˆ˜æ¨¡æ‹Ÿè®¾ç½® (V30.6)")
    st.info("ğŸ’¡ **å³ä¾§ä¹°å…¥é€»è¾‘**ï¼šD1 å¼€ç›˜åï¼Œå¿…é¡»æ¶¨å¹…è¶…è¿‡ä¸‹æ–¹é˜ˆå€¼æ‰ä¹°å…¥ï¼Œå¦åˆ™ç©ºä»“ã€‚")
    BUY_THRESHOLD_PCT = st.number_input(
        "**ä¹°å…¥ç¡®è®¤é˜ˆå€¼ (%)**", 
        value=1.5, 
        step=0.1, 
        help="æ¨¡æ‹Ÿ 9:40 ä¸Šæ¶¨ç¡®è®¤ã€‚å»ºè®® 1.0% - 2.0%ã€‚å¦‚æœè®¾ç½®ä¸º 0 åˆ™ä»£è¡¨å¼€ç›˜ç›´æ¥ä¹°ã€‚"
    )
    
    st.markdown("---")
    st.header("3. ç­–ç•¥æƒé‡ (å¼±å¸‚)")
    WEIGHT_MACD = st.slider("MACD æƒé‡", 0.0, 1.0, 0.45)
    WEIGHT_VOL = st.slider("ä½æ³¢åŠ¨æƒé‡", 0.0, 1.0, 0.45)
    
    st.markdown("---")
    st.header("4. è¿‡æ»¤æ¡ä»¶")
    FINAL_POOL = int(st.number_input("å…¥å›´æ•°é‡", value=100)) 
    TOP_BACKTEST = int(st.number_input("æ¯æ—¥æŒä»“ Top K", value=5))
    MIN_PRICE = st.number_input("æœ€ä½ä»·", value=5.0) 
    MAX_PRICE = st.number_input("æœ€é«˜ä»·", value=300.0)
    MIN_TURNOVER = st.number_input("æœ€ä½æ¢æ‰‹ (%)", value=3.0) 
    MIN_CIRC_MV_BILLIONS = st.number_input("æœ€ä½æµé€šå¸‚å€¼ (äº¿)", value=20.0)
    MIN_AMOUNT = st.number_input("æœ€ä½æˆäº¤é¢ (äº¿)", value=1.0) * 100000000 

# ---------------------------
# Token è¾“å…¥
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tokenã€‚")
    st.stop()
ts.set_token(TS_TOKEN)
pro = ts.pro_api() 

# ----------------------------------------------------------------------
# æ ¸å¿ƒå›æµ‹é€»è¾‘å‡½æ•° 
# ----------------------------------------------------------------------
def run_backtest_for_a_day(last_trade, TOP_BACKTEST, FINAL_POOL, buy_threshold):
    """ä¸ºå•ä¸ªäº¤æ˜“æ—¥è¿è¡Œé€‰è‚¡å’Œå›æµ‹é€»è¾‘"""
    global GLOBAL_DAILY_RAW
    
    market_state = get_market_state(last_trade)
 
    daily_all = safe_get('daily', trade_date=last_trade) 
    if daily_all.empty: return pd.DataFrame(), f"æ•°æ®ç¼ºå¤±"

    pool_raw = daily_all.reset_index(drop=True) 
    stock_basic = safe_get('stock_basic', list_status='L', fields='ts_code,name,list_date') 
    REQUIRED_BASIC_COLS = ['ts_code','turnover_rate','amount','total_mv','circ_mv'] 
    daily_basic = safe_get('daily_basic', trade_date=last_trade, fields=','.join(REQUIRED_BASIC_COLS))
    mf_raw = safe_get('moneyflow', trade_date=last_trade)
    
    pool_merged = pool_raw.copy()
    if not stock_basic.empty:
        pool_merged = pool_merged.merge(stock_basic[['ts_code','name','list_date']], on='ts_code', how='left')
    else:
        pool_merged['name'], pool_merged['list_date'] = pool_merged['ts_code'], '20000101'
        
    if not daily_basic.empty:
        cols = [c for c in REQUIRED_BASIC_COLS if c in daily_basic.columns]
        if 'amount' in pool_merged.columns and 'amount' in cols: pool_merged = pool_merged.drop(columns=['amount'])
        pool_merged = pool_merged.merge(daily_basic[cols], on='ts_code', how='left')
    
    for c in ['turnover_rate','amount','circ_mv','net_mf']: 
        if c not in pool_merged.columns: pool_merged[c] = 0.0
            
    if not mf_raw.empty:
        mf = mf_raw[['ts_code', 'net_mf']].fillna(0) if 'net_mf' in mf_raw.columns else pd.DataFrame()
        if not mf.empty: 
            pool_merged = pool_merged.drop(columns=['net_mf'], errors='ignore')
            pool_merged = pool_merged.merge(mf, on='ts_code', how='left')

    df = pool_merged.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce') 
    df['amount'] = pd.to_numeric(df['amount'], errors='coerce').fillna(0) * 1000 
    df['circ_mv_billion'] = pd.to_numeric(df['circ_mv'], errors='coerce').fillna(0) / 10000 
    
    # ç¡¬æ€§è¿‡æ»¤
    df = df[~df['name'].str.contains('ST|é€€', case=False, na=False)]
    df = df[~df['ts_code'].str.startswith('92')]
    df['days_listed'] = (datetime.strptime(last_trade, "%Y%m%d") - pd.to_datetime(df['list_date'], format='%Y%m%d', errors='coerce')).dt.days
    df = df[df['days_listed'] >= 120]
    
    df = df[(df['close'] >= MIN_PRICE) & (df['close'] <= MAX_PRICE)]
    df = df[df['circ_mv_billion'] >= MIN_CIRC_MV_BILLIONS]
    df = df[df['turnover_rate'] >= MIN_TURNOVER]
    df = df[df['amount'] >= MIN_AMOUNT]
    
    if len(df) == 0: return pd.DataFrame(), f"è¿‡æ»¤åæ— è‚¡ç¥¨"

    # åˆé€‰
    limit_mf = int(FINAL_POOL * 0.5)
    df_mf = df.sort_values('net_mf', ascending=False).head(limit_mf)
    df_pct = df[~df['ts_code'].isin(df_mf['ts_code'])].sort_values('pct_chg', ascending=False).head(FINAL_POOL - len(df_mf))
    final_candidates = pd.concat([df_mf, df_pct]).reset_index(drop=True)
    
    # ç¼“å­˜æ•°æ®æ£€æŸ¥
    if not GLOBAL_DAILY_RAW.empty:
        try:
            available = GLOBAL_DAILY_RAW.loc[(slice(None), last_trade), :].index.get_level_values('ts_code').unique()
            final_candidates = final_candidates[final_candidates['ts_code'].isin(available)]
        except: return pd.DataFrame(), f"ç¼“å­˜ç¼ºå¤±"

    if final_candidates.empty: return pd.DataFrame(), f"ç­›é€‰ä¸ºç©º"

    # æ·±åº¦è¯„åˆ†
    records = []
    for row in final_candidates.itertuples():
        ts_code = row.ts_code
        ind = compute_indicators(ts_code, last_trade) 
        d0_close, d0_ma20, d0_pos = ind.get('last_close'), ind.get('ma20'), ind.get('position_60d')

        if market_state == 'Weak':
            if pd.isna(d0_ma20) or d0_close < d0_ma20 or d0_pos > 20.0: continue 

        if pd.notna(d0_close):
            # æ ¸å¿ƒï¼šä½¿ç”¨å¸¦é˜ˆå€¼çš„å³ä¾§æ”¶ç›Šè®¡ç®—
            future_returns = get_future_prices_right_side(ts_code, last_trade, buy_threshold_pct=buy_threshold)
            
            rec = {
                'ts_code': ts_code, 'name': getattr(row, 'name', ts_code),
                'Close': row.close, 
                'Pct_Chg (%)': getattr(row, 'pct_chg', 0),
                'macd': ind.get('macd_val', np.nan), 
                'volatility': ind.get('volatility', np.nan),
                'Return_D1 (%)': future_returns.get('Return_D1', np.nan),
                'Return_D3 (%)': future_returns.get('Return_D3', np.nan),
            }
            records.append(rec)
    
    fdf = pd.DataFrame(records)
    if fdf.empty: return pd.DataFrame(), f"è¯„åˆ†åæ— è‚¡ç¥¨"

    # è¯„åˆ†é€»è¾‘
    def normalize(s): 
        s = s.dropna()
        if s.empty or s.max() == s.min(): return pd.Series([0.5]*len(s), index=s.index)
        return (s - s.min()) / (s.max() - s.min() + 1e-9)

    fdf['s_vol'] = normalize(fdf['volatility'])
    
    if market_state == 'Strong':
        fdf['ç­–ç•¥'] = 'ç»å¯¹MACDä¼˜åŠ¿'
        fdf = fdf[fdf['macd'] > 0].copy()
        if not fdf.empty:
            fdf['ç»¼åˆè¯„åˆ†'] = fdf['macd'] * 10000 + fdf['s_vol'].rsub(1) * 0.3
            fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False)
    else: 
        fdf['ç­–ç•¥'] = 'æè‡´åå¼¹é˜²å¾¡'
        fdf['s_macd'] = normalize(fdf['macd'])
        score = fdf['s_vol'].rsub(1).fillna(0.5) * WEIGHT_VOL + fdf['s_macd'].fillna(0.5) * WEIGHT_MACD
        fdf['ç»¼åˆè¯„åˆ†'] = score * 100
        fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False)
        
    return fdf.head(TOP_BACKTEST).copy(), None

# ---------------------------
# ä¸»è¿è¡Œå— 
# ---------------------------
if st.button(f"ğŸš€ å¼€å§‹ {BACKTEST_DAYS} æ—¥è‡ªåŠ¨å›æµ‹"):
    
    trade_days_str = get_trade_days(backtest_date_end.strftime("%Y%m%d"), BACKTEST_DAYS)
    if not trade_days_str: st.stop()
    
    if not get_all_historical_data(trade_days_str): st.stop()
    st.success("âœ… æ•°æ®å°±ç»ªï¼å¼€å§‹å³ä¾§äº¤æ˜“å›æµ‹...")
    
    results_list = []
    my_bar = st.progress(0)
    
    for i, trade_date in enumerate(trade_days_str):
        daily_result_df, error = run_backtest_for_a_day(
            trade_date, TOP_BACKTEST, FINAL_POOL, BUY_THRESHOLD_PCT
        )
        if not daily_result_df.empty:
            daily_result_df['Trade_Date'] = trade_date
            results_list.append(daily_result_df)
        my_bar.progress((i + 1) / len(trade_days_str))
    my_bar.empty()
    
    if not results_list:
        st.error("æ— å›æµ‹ç»“æœï¼ˆå¯èƒ½å…¨éƒ¨æœªè¾¾åˆ°ä¹°å…¥é˜ˆå€¼ï¼‰ã€‚")
        st.stop()
        
    all_results = pd.concat(results_list)
    if all_results['Trade_Date'].dtype != 'object': all_results['Trade_Date'] = all_results['Trade_Date'].astype(str)
        
    st.header(f"ğŸ“Š å³ä¾§äº¤æ˜“å›æµ‹æŠ¥å‘Š (ä¹°å…¥é˜ˆå€¼: +{BUY_THRESHOLD_PCT}%)")
    
    cols = st.columns(2)
    for idx, n in enumerate([1, 3]):
        col_name = f'Return_D{n} (%)' 
        valid = all_results.dropna(subset=[col_name])
        
        # è®¡ç®—é€»è¾‘ï¼šåˆ†æ¯æ˜¯â€œå®é™…æˆäº¤çš„äº¤æ˜“æ¬¡æ•°â€ï¼Œè€Œä¸æ˜¯â€œæ‰€æœ‰æ¨èæ¬¡æ•°â€
        if not valid.empty:
            avg_ret = valid[col_name].mean()
            hit_rate = (valid[col_name] > 0).sum() / len(valid) * 100
            count = len(valid)
        else:
            avg_ret, hit_rate, count = 0, 0, 0
            
        with cols[idx]:
            st.metric(
                f"D+{n} æ”¶ç›Š / èƒœç‡", 
                f"{avg_ret:.2f}% / {hit_rate:.1f}%",
                help=f"å®é™…æˆäº¤ç¬”æ•°ï¼š{count}ã€‚æœªæˆäº¤çš„äº¤æ˜“å·²è‡ªåŠ¨å‰”é™¤ã€‚"
            )

    st.markdown(f"**æ³¨ï¼š** äº¤æ˜“ç¬”æ•°è¾ƒå°‘æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºä»£ç è¿‡æ»¤æ‰äº† D1 æœ€é«˜ä»·æœªè§¦åŠ `å¼€ç›˜ä»· * {1+BUY_THRESHOLD_PCT/100}` çš„æ‰€æœ‰è‚¡ç¥¨ã€‚")
    
    st.header("ğŸ“‹ æ¯æ—¥æˆäº¤æ˜ç»†")
    # åªæ˜¾ç¤ºæœ‰å®é™…å›æŠ¥ç‡çš„è®°å½•ï¼ˆå³å®é™…æˆäº¤çš„ï¼‰
    mask_traded = all_results['Return_D1 (%)'].notna()
    st.dataframe(all_results[mask_traded].sort_values('Trade_Date', ascending=False), use_container_width=True)
