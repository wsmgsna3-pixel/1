# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V13.8ï¼ˆæ•°æ®æ ¡éªŒç¨³å®šç‰ˆï¼‰
æ ¸å¿ƒï¼šä¿®å¤æ—¥æœŸè·å–é€»è¾‘ã€‚é‡‡ç”¨ 'æ•°æ®æ ¡éªŒå›æº¯æ³•'ï¼Œç¡®ä¿é€‰è‚¡æ—¥æ˜¯ Tushare æ¥å£å®é™…æœ‰æ•°æ®çš„æœ€è¿‘æ—¥æœŸã€‚
"""
import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import joblib 
import os
import math
import time 

warnings.filterwarnings("ignore")

# ---------------------------
# å¤–éƒ¨ç¼“å­˜é…ç½® (joblib ä»…ç”¨äºå†å²æ•°æ®)
# ---------------------------
CACHE_DIR = "data_cache"
os.makedirs(CACHE_DIR, exist_ok=True)
memory = joblib.Memory(CACHE_DIR, verbose=0) 

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ï¼ˆV13.8 æ•°æ®æ ¡éªŒç¨³å®šç‰ˆï¼‰", layout="wide")
st.markdown("### é€‰è‚¡ç‹ï¼ˆV13.8 æ•°æ®æ ¡éªŒç¨³å®šç‰ˆï¼‰- ä¿®å¤æœªæ¥æ—¥æœŸé—®é¢˜") 

# ---------------------------
# é»˜è®¤å‚æ•°å®šä¹‰ (ä¿æŒ V13.6/V13.7)
# ---------------------------
DEFAULT_FINAL_POOL = 500
DEFAULT_TOP_DISPLAY = 30
DEFAULT_MIN_PRICE = 10.0
DEFAULT_MAX_PRICE = 200.0
DEFAULT_MIN_CIRC_MV_B = 40.0 
DEFAULT_MAX_CIRC_MV_B = 500.0 
DEFAULT_MIN_TURNOVER = 3.0 
DEFAULT_MIN_AMOUNT = 200_000_000.0 
DEFAULT_MA_PERIOD = 20
DEFAULT_MIN_LIST_DAYS = 180
DEFAULT_BACKTEST_DAYS = 10

DEFAULT_VOL_SPIKE_MULT = 1.7
DEFAULT_HIGH_PCT_THRESHOLD = 6.0
DEFAULT_MAX_VOLATILITY_10D = 8.0 

# ---------------------------
# ä¾§è¾¹æ å‚æ•° 
# ---------------------------
with st.sidebar:
    st.header("å¯è°ƒå‚æ•°ï¼ˆV13.8 é»˜è®¤å€¼ï¼‰")
    INITIAL_TOP_N = 99999 
    
    FINAL_POOL = int(st.number_input("æ¸…æ´—åå–å‰ M è¿›å…¥è¯„åˆ†", value=DEFAULT_FINAL_POOL, step=50))
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=DEFAULT_TOP_DISPLAY, step=5))
    
    st.markdown("---")
    st.subheader("åŸºç¡€è¿‡æ»¤ (ç¡¬æ€§è¦æ±‚)")
    MIN_PRICE = float(st.number_input("æœ€ä½ä»·æ ¼ (å…ƒ)", value=DEFAULT_MIN_PRICE, step=1.0))
    MAX_PRICE = float(st.number_input("æœ€é«˜ä»·æ ¼ (å…ƒ)", value=DEFAULT_MAX_PRICE, step=10.0))
    
    # è¯·æ ¹æ®éœ€è¦è°ƒæ•´æµé€šå¸‚å€¼èŒƒå›´
    MIN_CIRC_MV_Billion = float(st.number_input("æœ€ä½æµé€šå¸‚å€¼ (äº¿)", value=DEFAULT_MIN_CIRC_MV_B, step=5.0)) 
    MAX_CIRC_MV_Billion = float(st.number_input("æœ€é«˜æµé€šå¸‚å€¼ (äº¿)", value=DEFAULT_MAX_CIRC_MV_B, step=50.0)) 
    
    MIN_TURNOVER = float(st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=DEFAULT_MIN_TURNOVER, step=0.1)) 
    MIN_AMOUNT = float(st.number_input("æœ€ä½æˆäº¤é¢ (å…ƒ)", value=DEFAULT_MIN_AMOUNT, step=50_000_000.0))
    
    MA_TREND_PERIOD = int(st.number_input("è¶‹åŠ¿è¿‡æ»¤ï¼šMA å‘¨æœŸ", value=DEFAULT_MA_PERIOD, step=5))
    MIN_LIST_DAYS = int(st.number_input("æ¬¡æ–°è‚¡æ’é™¤ï¼šæœ€ä½ä¸Šå¸‚å¤©æ•° (å¤©)", value=DEFAULT_MIN_LIST_DAYS, step=30))
    
    st.markdown("---")
    st.subheader("çŸ­çº¿é£æ§å‚æ•° (BC å¢å¼º)")
    
    VOL_SPIKE_MULT = float(st.number_input("å·¨é‡å†²é«˜ï¼šæ”¾é‡å€æ•°é˜ˆå€¼", value=DEFAULT_VOL_SPIKE_MULT, step=0.1))
    HIGH_PCT_THRESHOLD = float(st.number_input("å¤§é˜³çº¿/åå¼¹å®šä¹‰ (%å˜åŒ–)", value=DEFAULT_HIGH_PCT_THRESHOLD, step=0.5))
    MAX_VOLATILITY_10D = float(st.number_input("æç«¯æ³¢åŠ¨ï¼š10æ—¥æ³¢åŠ¨ std é˜ˆå€¼ (%)", value=DEFAULT_MAX_VOLATILITY_10D, step=0.5))
    
    st.markdown("---")
    
    BACKTEST_DAYS = int(st.number_input("å›æµ‹ï¼šæœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥", value=DEFAULT_BACKTEST_DAYS, step=1))
    
    st.markdown("---")
    st.caption("æç¤ºï¼šç­–ç•¥å·²å‡çº§è‡³ 'V13.8 æ•°æ®æ ¡éªŒç¨³å®šç‰ˆ'ã€‚")


# ---------------------------
# Token è¾“å…¥
# ---------------------------
st.markdown("è¯·è¾“å…¥ Tushare Tokenã€‚")
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password", label_visibility="collapsed")

if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

# åˆå§‹åŒ– tushare
ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# ä¾èµ–å‡½æ•°ï¼šæ•°æ®å®‰å…¨è·å–
# ---------------------------
def safe_get(func, **kwargs):
    """å°è¯•è·å–æ•°æ®ï¼Œå¤±è´¥åˆ™è¿”å›ç©º DataFrame"""
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

# ----------------------------------------------------
# äº¤æ˜“æ—¥å†è·å– (V13.8: è·å–æ—¥å†çš„é€»è¾‘ä¸å˜ï¼Œä½†ç”¨äºç¨³å®šæ ¡éªŒ)
# ----------------------------------------------------
@st.cache_data(ttl=600)
def get_trade_cal_dates():
    """å®‰å…¨åœ°ä» Tushare è·å–æ‰€æœ‰å¼€æ”¾äº¤æ˜“æ—¥ï¼Œå¹¶æŒ‰é™åºæ’åˆ—ã€‚"""
    end_date = datetime.now().strftime("%Y%m%d")
    cal_df = safe_get(
        pro.trade_cal, 
        exchange='SSE', 
        is_open='1', 
        end_date=end_date, 
        fields='cal_date'
    )
    if cal_df.empty: return []
    return cal_df['cal_date'].sort_values(ascending=False).tolist()

# ----------------------------------------------------
# æ ¸å¿ƒä¿®æ­£ï¼šæ•°æ®æ ¡éªŒå›æº¯å‡½æ•° (V13.8 æ–°å¢)
# ----------------------------------------------------
@st.cache_data(ttl=3600)
def find_last_trade_day_robust(pro_api):
    """
    V13.8 æ ¸å¿ƒä¿®æ­£ï¼šè¿­ä»£æœ€è¿‘äº¤æ˜“æ—¥ï¼Œç›´åˆ°æ‰¾åˆ° Tushare æ¥å£å®é™…èƒ½æä¾›æ•°æ®çš„æ—¥æœŸã€‚
    """
    trade_dates = get_trade_cal_dates()
    
    if not trade_dates: return None
    
    # å°è¯•æœ€è¿‘çš„ 5 ä¸ªäº¤æ˜“æ—¥
    for date_str in trade_dates[:5]: 
        
        # å°è¯•æ‹‰å–å…¨å¸‚åœºæ—¥çº¿æ•°æ®
        daily_all = safe_get(pro_api.daily, trade_date=date_str)
        
        if not daily_all.empty:
            # æ‰¾åˆ°æœ‰æ•°æ®çš„æ—¥æœŸï¼Œè¿”å›
            return date_str
        
        # å¦åˆ™ï¼Œç»§ç»­å›æº¯åˆ°å‰ä¸€ä¸ªæ—¥æœŸ
            
    return None # 5 å¤©å†…éƒ½æ²¡æœ‰æ•°æ®ï¼Œè¿”å› None

# V13.8 è¿è¡Œç¨³å®šçš„æ—¥æœŸå‡½æ•°
last_trade = find_last_trade_day_robust(pro)

if not last_trade:
    st.error("æ— æ³•è·å–æœ€è¿‘äº¤æ˜“æ—¥ã€‚å·²å°è¯•å›æº¯æœ€è¿‘ 5 ä¸ªäº¤æ˜“æ—¥ï¼Œä½† Tushare æ¥å£å‡æ— æ•°æ®ã€‚è¯·æ£€æŸ¥ Tushare Token æˆ–ç­‰å¾…æ•°æ®æ›´æ–°ã€‚")
    st.stop()
st.info(f"å‚è€ƒæœ€è¿‘äº¤æ˜“æ—¥ï¼ˆç»æ•°æ®æ ¡éªŒï¼‰ï¼š**{last_trade}**")


# ----------------------------------------------------
# æŒ‰é’®æ§åˆ¶æ¨¡å— 
# ----------------------------------------------------
if 'run_selection' not in st.session_state: st.session_state['run_selection'] = False
if 'run_backtest' not in st.session_state: st.session_state['run_backtest'] = False
if 'backtest_status' not in st.session_state: 
    st.session_state['backtest_status'] = {'progress': 0.0, 'results': [], 'current_index': 0, 'total_days': 0}

col1, col2 = st.columns(2)

with col1:
    if st.button("ğŸš€ è¿è¡Œå½“æ—¥é€‰è‚¡", use_container_width=True):
        st.session_state['run_selection'] = True
        st.session_state['run_backtest'] = False
        st.session_state['backtest_status'] = {'progress': 0.0, 'results': [], 'current_index': 0, 'total_days': 0}
        st.rerun()

with col2:
    if st.button(f"âœ… è¿è¡Œå†å²å›æµ‹ ({BACKTEST_DAYS} æ—¥)", use_container_width=True):
        st.session_state['run_backtest'] = True
        st.session_state['run_selection'] = False
        if st.session_state['backtest_status']['progress'] == 1.0 or st.session_state['backtest_status']['total_days'] == 0:
             st.session_state['backtest_status'] = {'progress': 0.0, 'results': [], 'current_index': 0, 'total_days': 0}
        st.rerun()

st.markdown("---")

# ---------------------------
# è¾…åŠ©å‡½æ•° (ä¿æŒ V13.7 é€»è¾‘)
# ---------------------------
def safe_merge_pool(pool_df, other_df, cols):
    pool = pool_df.set_index('ts_code').copy()
    if other_df is None or other_df.empty:
        for c in cols: pool[c] = np.nan
        return pool.reset_index()
    if 'ts_code' not in other_df.columns:
        try: other_df = other_df.reset_index()
        except:
            for c in cols: pool[c] = np.nan
            return pool.reset_index()
    
    for c in cols:
        if c not in other_df.columns: other_df[c] = np.nan
    
    try: 
        joined = pool.join(other_df.set_index('ts_code')[cols], how='left')
    except Exception:
        for c in cols: pool[c] = np.nan
        return pool.reset_index()
    
    for c in cols:
        if c not in joined.columns: joined[c] = np.nan
        
    return joined.reset_index()

def norm_col(s):
    s = s.fillna(0.0).replace([np.inf,-np.inf], np.nan).fillna(0.0)
    mn = s.min(); mx = s.max()
    if mx - mn < 1e-9: return pd.Series([0.5]*len(s), index=s.index)
    return (s - mn) / (mx - mn)


# ---------------------------
# V13.8 å¢å¼ºï¼šæŒ‡æ ‡è®¡ç®—å’Œå½’ä¸€åŒ– (ä¿æŒ V13.7 é€»è¾‘)
# ---------------------------
def compute_indicators(df, ma_period):
    res = {}
    if df.empty or len(df) < 3: return res
    close = df['close'].astype(float)
    high = df['high'].astype(float)
    low = df['low'].astype(float)
    vols = df['vol'].astype(float).tolist()

    res['last_close'] = close.iloc[-1]
    
    if len(close) >= ma_period:
        res[f'ma{ma_period}'] = close.rolling(window=ma_period).mean().iloc[-1]
    else:
        res[f'ma{ma_period}'] = np.nan
        
    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        res['macd'] = (diff - dea).iloc[-1] * 2
    else: res['macd'] = np.nan

    n_kdj = 9
    if len(close) >= n_kdj:
        low_n = low.rolling(window=n_kdj).min()
        high_n = high.rolling(window=n_kdj).max()
        rsv = (close - low_n) / (high_n - low_n + 1e-9) * 100
        rsv = rsv.fillna(50)
        k = rsv.ewm(alpha=1/3, adjust=False).mean()
        d = k.ewm(alpha=1/3, adjust=False).mean()
        j = 3*k - 2*d
        res['k'] = k.iloc[-1]; res['d'] = d.iloc[-1]; res['j'] = j.iloc[-1]
    else:
        res['k'] = res['d'] = res['j'] = np.nan

    if len(vols) >= 6:
        avg_prev5 = np.mean(vols[-6:-1])
        res['vol_ratio'] = vols[-1] / (avg_prev5 + 1e-9)
        res['vol_last'] = vols[-1]
        res['vol_ma5'] = avg_prev5
    else:
        res['vol_ratio'] = res['vol_last'] = res['vol_ma5'] = np.nan

    if len(close) >= 10:
        res['10d_return'] = close.iloc[-1] / close.iloc[-10] - 1
    else:
        res['10d_return'] = np.nan
    
    if 'pct_chg' in df.columns and len(df) >= 4:
        try:
            pct = df['pct_chg'].astype(float)
            res['prev3_sum'] = pct.iloc[-4:-1].sum()
        except:
            res['prev3_sum'] = np.nan
    else:
        res['prev3_sum'] = np.nan

    try:
        if 'pct_chg' in df.columns and len(df) >= 10:
            res['volatility_10'] = df['pct_chg'].astype(float).tail(10).std()
        else:
            res['volatility_10'] = np.nan
    except: res['volatility_10'] = np.nan
    
    return res

# ----------------------------------------------------
# æ ¸å¿ƒè¯„åˆ†å‡½æ•° (V13.8: é€»è¾‘ä¿æŒ V13.7)
# ----------------------------------------------------
@st.cache_data(show_spinner=False, ttl=600)
def run_scoring_for_date(trade_date, params):
    
    # å‚æ•°å®‰å…¨è§£åŒ…
    min_price = params.get('MIN_PRICE', DEFAULT_MIN_PRICE)
    max_price = params.get('MAX_PRICE', DEFAULT_MAX_PRICE)
    min_turnover = params.get('MIN_TURNOVER', DEFAULT_MIN_TURNOVER)
    min_amount = params.get('MIN_AMOUNT', DEFAULT_MIN_AMOUNT)
    min_circ_mv_billion = params.get('MIN_CIRC_MV_Billion', DEFAULT_MIN_CIRC_MV_B)
    max_circ_mv_billion = params.get('MAX_CIRC_MV_Billion', DEFAULT_MAX_CIRC_MV_B)
    ma_trend_period = params.get('MA_TREND_PERIOD', DEFAULT_MA_PERIOD)
    min_list_days = params.get('MIN_LIST_DAYS', DEFAULT_MIN_LIST_DAYS)
    final_pool_size = params.get('FINAL_POOL', DEFAULT_FINAL_POOL) 

    vol_spike_mult = params.get('VOL_SPIKE_MULT', DEFAULT_VOL_SPIKE_MULT)
    high_pct_threshold = params.get('HIGH_PCT_THRESHOLD', DEFAULT_HIGH_PCT_THRESHOLD)
    max_volatility_10d = params.get('MAX_VOLATILITY_10D', DEFAULT_MAX_VOLATILITY_10D)
    
    # 1. æ‹‰å–æ•°æ® (Daily æä¾› open/high/low/pre_close)
    daily_all = safe_get(pro.daily, trade_date=trade_date)
    daily_basic = safe_get(pro.daily_basic, trade_date=trade_date, fields='ts_code,turnover_rate,amount,total_mv,circ_mv')
    moneyflow = safe_get(pro.moneyflow, trade_date=trade_date, fields='ts_code,net_mf_amount') 

    if daily_all.empty: 
        # V13.8: åªæœ‰åœ¨é€‰è‚¡æ—¥ä¸ç­‰äºå…¨å±€ last_trade (å³å›æµ‹ä¸­è°ƒç”¨) æ‰ä¼šè­¦å‘Š
        if trade_date == last_trade: 
             # ç†è®ºä¸Šè¢« find_last_trade_day_robust è¿‡æ»¤äº†ï¼Œæ­¤å¤„ä¸ºåŒé‡ä¿é™©
             st.error(f"è¯Šæ–­ï¼šTushare æ— æ³•è·å– {trade_date} çš„æ—¥çº¿æ•°æ®ã€‚è¯·æ£€æŸ¥ Token æƒé™æˆ–ç­‰å¾…æ•°æ®æ›´æ–°ã€‚")
        return pd.DataFrame()
    
    pool0 = daily_all.copy().reset_index(drop=True)

    # 2. åˆå¹¶åŸºæœ¬ä¿¡æ¯ 
    stock_basic = safe_get(pro.stock_basic, list_status='L', fields='ts_code,name,industry,list_date,total_mv,circ_mv')
    
    if not stock_basic.empty:
        keep = [c for c in ['ts_code','name','industry','total_mv','circ_mv','list_date'] if c in stock_basic.columns]
        try: pool0 = pool0.merge(stock_basic[keep], on='ts_code', how='left')
        except Exception: 
            pool0['name'] = pool0['ts_code']; pool0['industry'] = ''; pool0['list_date'] = '20000101'
    else: 
        pool0['name'] = pool0['ts_code']; pool0['industry'] = ''; pool0['list_date'] = '20000101'
    
    pool_merged = safe_merge_pool(pool0, daily_basic.rename(columns={'amount':'amount_db'}), ['turnover_rate','amount_db','total_mv','circ_mv'])

    if not moneyflow.empty:
        pool_merged = safe_merge_pool(pool_merged, moneyflow, ['net_mf_amount'])
    else:
        pool_merged['net_mf_amount'] = 0.0

    
    if 'amount' in pool_merged.columns:
        pool_merged['amount'] = pool_merged['amount'].apply(lambda amt: amt * 10000.0 if not pd.isna(amt) and amt > 0 and amt < 1e5 else amt)
    else:
        pool_merged['amount'] = pool_merged['amount_db'].apply(lambda amt: amt * 10000.0 if not pd.isna(amt) and amt > 0 and amt < 1e5 else amt)
    
    pool_merged['amount_yuan'] = pool_merged['amount']
    pool_merged['circ_mv_wan'] = pool_merged['circ_mv'].fillna(0)


    # 3. V13.8 ç¡¬æ€§è¿‡æ»¤
    clean_df = pool_merged.copy()
    
    # åŸºç¡€é£é™©è¿‡æ»¤ (ST, ä»·æ ¼, åŒ—äº¤æ‰€)
    clean_df = clean_df[~(
        (clean_df['close'].isna()) | 
        (clean_df['close'] < min_price) | 
        (clean_df['close'] > max_price) | 
        (clean_df['name'].str.contains('ST|é€€', case=False, na=False)) |
        (clean_df['ts_code'].str.endswith('.BJ', na=False)) 
    )]
    
    # ä»Šæ—¥å¿…é¡»ä¸Šæ¶¨ï¼ˆpct_chg > 0ï¼‰
    clean_df = clean_df[~((clean_df['pct_chg'].isna()) | (clean_df['pct_chg'] < 0))]
    
    # æ’é™¤ä¸€å­—æ¿ (open == high == low == pre_close)
    mask_yiziban = (clean_df['open'] == clean_df['high']) & \
                   (clean_df['high'] == clean_df['low']) & \
                   (clean_df['low'] == clean_df['pre_close']) & \
                   (clean_df['high'] > clean_df['pre_close']) 
    clean_df = clean_df[~mask_yiziban.fillna(False)]
    
    # æ¬¡æ–°è‚¡è¿‡æ»¤ 
    current_date = datetime.strptime(trade_date, "%Y%m%d")
    clean_df['list_date'] = pd.to_datetime(clean_df['list_date'], format='%Y%m%d', errors='coerce')
    clean_df['days_since_list'] = (current_date - clean_df['list_date']).dt.days
    clean_df = clean_df[clean_df['days_since_list'].notna() & (clean_df['days_since_list'] >= min_list_days)]
    
    # æµé€šå¸‚å€¼ä¸Šä¸‹é™è¿‡æ»¤ (è¿™æ˜¯æ‚¨è¦å…³æ³¨çš„æ ¸å¿ƒèŒƒå›´)
    min_circ_mv_wan = min_circ_mv_billion * 10000.0 
    max_circ_mv_wan = max_circ_mv_billion * 10000.0 
    clean_df = clean_df[clean_df['circ_mv_wan'].notna() & 
                        (clean_df['circ_mv_wan'] >= min_circ_mv_wan) &
                        (clean_df['circ_mv_wan'] <= max_circ_mv_wan)]

    # æµåŠ¨æ€§è¿‡æ»¤
    clean_df = clean_df[clean_df['amount_yuan'].notna() & (clean_df['amount_yuan'] >= min_amount)]
    clean_df = clean_df[clean_df['turnover_rate'].notna() & (clean_df['turnover_rate'] >= min_turnover)]
    
    
    if clean_df.empty: 
        if trade_date == last_trade: st.error(f"è¯Šæ–­ï¼šæ‰€æœ‰ç¡¬æ€§è¿‡æ»¤åï¼Œå‰©ä½™è‚¡ç¥¨æ•°é‡ä¸º **0** æ”¯ã€‚è¯·æ£€æŸ¥ä¾§è¾¹æ å‚æ•°ã€‚")
        return pd.DataFrame()

    if trade_date == last_trade:
        st.info(f"è¯Šæ–­ï¼šç¡¬æ€§è¿‡æ»¤ (å·²åŒ…å«æ¬¡æ–°è‚¡ã€å¸‚å€¼æ”¶ç´§) åï¼Œå‰©ä½™è‚¡ç¥¨æ•°é‡: **{len(clean_df)}** æ”¯ï¼Œå¼€å§‹è®¡ç®—æŒ‡æ ‡...")
        
    # 4. æŒ‡æ ‡è®¡ç®—ä¸ MA è¶‹åŠ¿ç¡¬æ€§è¿‡æ»¤ 
    score_pool = clean_df.sort_values('pct_chg', ascending=False).head(min(len(clean_df), 300)).copy().reset_index(drop=True)

    records = []
    start_dt = datetime.strptime(trade_date, "%Y%m%d") - timedelta(days=60 * 1.5) 
    start_date_hist = start_dt.strftime("%Y%m%d")
    
    pbar = None
    if trade_date == last_trade:
        pbar = st.progress(0.0, text=f"æ­£åœ¨è®¡ç®— {len(score_pool)} æ”¯è‚¡ç¥¨çš„æŒ‡æ ‡...")

    for i, row in enumerate(score_pool.itertuples()):
        ts_code = getattr(row, 'ts_code');
        close_price = getattr(row, 'close', np.nan)
        
        @memory.cache 
        def get_daily_hist(ts_code, start_date, end_date):
            return safe_get(pro.daily, ts_code=ts_code, start_date=start_date, end_date=end_date)
            
        hist = get_daily_hist(ts_code, start_date_hist, trade_date)
        
        ind = compute_indicators(hist, ma_trend_period)
        ma_trend_val = ind.get(f'ma{ma_trend_period}', np.nan)
        
        # --- MA è¶‹åŠ¿ç¡¬æ€§è¿‡æ»¤ --- 
        if not pd.isna(close_price) and not pd.isna(ma_trend_val) and (close_price < ma_trend_val):
             if pbar: pbar.progress((i + 1) / len(score_pool), text=f"æŒ‡æ ‡è®¡ç®—è¿›åº¦ï¼š[{i+1}/{len(score_pool)}]... (å·²æ’é™¤è¶‹åŠ¿å‘ä¸‹è‚¡)")
             continue 

        rec = {
            'ts_code': ts_code, 
            'pct_chg': getattr(row, 'pct_chg', np.nan),
            'turnover_rate': getattr(row, 'turnover_rate', np.nan),
            'circ_mv_wan': getattr(row, 'circ_mv_wan', np.nan),
            'amount_yuan': getattr(row, 'amount_yuan', np.nan),
            'net_mf_amount': getattr(row, 'net_mf_amount', np.nan),
            'name': getattr(row, 'name', ts_code),
            f'ma{ma_trend_period}': ma_trend_val,
            
            'last_close': ind.get('last_close', np.nan),
            'macd': ind.get('macd', np.nan), 
            'k': ind.get('k', np.nan), 'd': ind.get('d', np.nan), 'j': ind.get('j', np.nan),
            'vol_ratio': ind.get('vol_ratio', np.nan),
            'vol_last': ind.get('vol_last', np.nan),
            'vol_ma5': ind.get('vol_ma5', np.nan),
            '10d_return': ind.get('10d_return', np.nan),
            'prev3_sum': ind.get('prev3_sum', np.nan),
            'volatility_10': ind.get('volatility_10', np.nan),
        }
        records.append(rec)
        
        if pbar: pbar.progress((i + 1) / len(score_pool), text=f"æŒ‡æ ‡è®¡ç®—è¿›åº¦ï¼š[{i+1}/{len(score_pool)}]... (å·²æ’é™¤è¶‹åŠ¿å‘ä¸‹è‚¡)")
        
    fdf = pd.DataFrame(records)
    if fdf.empty: return pd.DataFrame()
    if pbar: pbar.empty()

    if trade_date == last_trade:
        st.info(f"è¯Šæ–­ï¼šé€šè¿‡ {ma_trend_period} æ—¥å‡çº¿è¶‹åŠ¿è¿‡æ»¤åï¼Œå‰©ä½™è‚¡ç¥¨æ•°é‡: **{len(fdf)}** æ”¯ï¼Œå¼€å§‹é«˜çº§é£é™©è¿‡æ»¤...")
        
    
    # 5. V13.8 é«˜çº§é£é™©è¿‡æ»¤
    try:
        before_cnt = len(fdf)
        
        if all(c in fdf.columns for c in [f'ma{ma_trend_period}','last_close','pct_chg']):
            mask_high_big = (fdf['last_close'] > fdf[f'ma{ma_trend_period}'] * 1.10) & (fdf['pct_chg'] > high_pct_threshold)
            fdf = fdf[~mask_high_big.fillna(False)]

        if all(c in fdf.columns for c in ['prev3_sum','pct_chg']):
            mask_down_rebound = (fdf['prev3_sum'] < 0) & (fdf['pct_chg'] > high_pct_threshold)
            fdf = fdf[~mask_down_rebound.fillna(False)]

        if 'vol_ratio' in fdf.columns:
            mask_vol_spike = (fdf['vol_ratio'] > vol_spike_mult)
            fdf = fdf[~mask_vol_spike.fillna(False)]

        if 'volatility_10' in fdf.columns:
            mask_volatility = fdf['volatility_10'] > max_volatility_10d
            fdf = fdf[~mask_volatility.fillna(False)]

        after_cnt = len(fdf)
        if trade_date == last_trade:
            st.info(f"è¯Šæ–­ï¼šé«˜çº§é£é™©è¿‡æ»¤åï¼Œå‰©ä½™è‚¡ç¥¨æ•°é‡: **{after_cnt}** æ”¯ï¼Œå¼€å§‹è¯„åˆ†...")
    except Exception as e:
        if trade_date == last_trade: st.warning(f"é«˜çº§é£é™©è¿‡æ»¤æ¨¡å—å¼‚å¸¸ï¼Œè·³è¿‡è¿‡æ»¤ã€‚é”™è¯¯ï¼š{e}")
    
    if fdf.empty: return pd.DataFrame()


    # 6. RSLï¼ˆç›¸å¯¹å¼ºå¼±ï¼‰è®¡ç®—
    if '10d_return' in fdf.columns:
        try:
            fdf['proxy_money'] = (abs(fdf['pct_chg']) + 1e-9) * fdf['vol_ratio'].fillna(0) * fdf['turnover_rate'].fillna(0)
            
            market_mean_10d = fdf['10d_return'].replace([np.inf,-np.inf], np.nan).dropna().mean()
            if np.isnan(market_mean_10d) or abs(market_mean_10d) < 1e-9:
                market_mean_10d = 1e-9
            fdf['rsl'] = fdf['10d_return'] / market_mean_10d
        except:
            fdf['rsl'] = 1.0
            fdf['proxy_money'] = 0.0
    else:
        fdf['rsl'] = 1.0
        fdf['proxy_money'] = 0.0


    # 7. å½’ä¸€åŒ–
    fdf['s_pct'] = norm_col(fdf.get('pct_chg', pd.Series([0]*len(fdf))))
    fdf['s_volratio'] = norm_col(fdf.get('vol_ratio', pd.Series([0]*len(fdf))))
    fdf['s_turn'] = norm_col(fdf.get('turnover_rate', pd.Series([0]*len(fdf))))
    
    if 'net_mf_amount' in fdf.columns and fdf['net_mf_amount'].abs().sum() > 0:
        fdf['s_money'] = norm_col(fdf.get('net_mf_amount', pd.Series([0]*len(fdf))))
    else:
        fdf['s_money'] = norm_col(fdf.get('proxy_money', pd.Series([0]*len(fdf))))

    fdf['s_amount'] = norm_col(fdf.get('amount_yuan', pd.Series([0]*len(fdf))))
    fdf['s_10d'] = norm_col(fdf.get('10d_return', pd.Series([0]*len(fdf))))
    fdf['s_macd'] = norm_col(fdf.get('macd', pd.Series([0]*len(fdf))))
    fdf['s_rsl'] = norm_col(fdf.get('rsl', pd.Series([0]*len(fdf))))
    fdf['s_volatility'] = 1 - norm_col(fdf.get('volatility_10', pd.Series([0]*len(fdf)))) 
    
    
    # 8. ç»¼åˆè¯„åˆ†
    w_pct = 0.18        
    w_volratio = 0.18   
    w_turn = 0.12       
    w_money = 0.14      
    w_10d = 0.12        
    w_macd = 0.06       
    w_rsl = 0.12        
    w_volatility = 0.08 

    fdf['ç»¼åˆè¯„åˆ†'] = (
        fdf['s_pct'] * w_pct +
        fdf['s_volratio'] * w_volratio +
        fdf['s_turn'] * w_turn +
        fdf['s_money'] * w_money +
        fdf['s_10d'] * w_10d +
        fdf['s_macd'] * w_macd +
        fdf['s_rsl'] * w_rsl +
        fdf['s_volatility'] * w_volatility
    )
    
    return fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).head(final_pool_size).reset_index(drop=True)


# ----------------------------------------------------
# ç®€æ˜“å›æµ‹æ¨¡å— (ä¿æŒ V13.7 é€»è¾‘)
# ----------------------------------------------------
def run_simple_backtest(days, params):
    
    HOLDING_PERIODS = [1, 3, 5]
    status = st.session_state['backtest_status']
    
    container = st.empty()
    with container.container():
        st.subheader(f"ğŸ“ˆ ç®€æ˜“å†å²å›æµ‹ç»“æœ (V13.8 æ•°æ®æ ¡éªŒç¨³å®šç‰ˆ)")
        
        trade_dates_all = get_trade_cal_dates()
        
        if not trade_dates_all:
             st.error("æ— æ³•è·å–å†å²äº¤æ˜“æ—¥å†ã€‚")
             return

        try:
            current_trade_idx = trade_dates_all.index(last_trade)
            # ç¡®ä¿ trade_dates_all çš„ç¬¬ä¸€ä¸ªæ—¥æœŸå°±æ˜¯ last_tradeï¼Œåªä¿ç•™æœ‰æ•°æ®çš„æ—¥æœŸ
            trade_dates_all = trade_dates_all[current_trade_idx:]
        except ValueError:
            st.error(f"å†…éƒ¨é”™è¯¯ï¼šæ— æ³•å®šä½æœ€è¿‘æœ‰æ•ˆäº¤æ˜“æ—¥ {last_trade}ã€‚")
            return


        max_holding = max(HOLDING_PERIODS)
        trade_dates = trade_dates_all[:days + max_holding]
        trade_dates.reverse() 
        total_iterations = len(trade_dates) - max_holding 
        
        if total_iterations < 1:
            st.warning(f"äº¤æ˜“æ—¥ä¸è¶³ {max_holding + 1} å¤©ï¼Œæ— æ³•è¿›è¡Œå›æµ‹ã€‚")
            return
            
        status['total_days'] = total_iterations
        start_index = status['current_index']
        
        if start_index >= total_iterations:
             st.success(f"å›æµ‹å·²å®Œæˆã€‚ç´¯è®¡æ”¶ç›Šç‡è¯·æŸ¥çœ‹ä¸‹æ–¹ã€‚")
        else:
             st.info(f"å›æµ‹å‘¨æœŸï¼š**{trade_dates[0]}** è‡³ **{trade_dates[total_iterations-1]}**ã€‚æ­£åœ¨ä»ç¬¬ {start_index+1} å¤©ç»§ç»­...")

        pbar = st.progress(status['progress'], text=f"å›æµ‹è¿›åº¦ï¼š[{status['current_index']}/{status['total_days']}]...")
        
        score_params = {
            'MIN_PRICE': params.get('MIN_PRICE', DEFAULT_MIN_PRICE), 
            'MAX_PRICE': params.get('MAX_PRICE', DEFAULT_MAX_PRICE), 
            'MIN_TURNOVER': params.get('MIN_TURNOVER', DEFAULT_MIN_TURNOVER), 
            'MIN_AMOUNT': params.get('MIN_AMOUNT', DEFAULT_MIN_AMOUNT), 
            'MIN_CIRC_MV_Billion': params.get('MIN_CIRC_MV_Billion', DEFAULT_MIN_CIRC_MV_B),
            'MAX_CIRC_MV_Billion': params.get('MAX_CIRC_MV_Billion', DEFAULT_MAX_CIRC_MV_B),
            'MA_TREND_PERIOD': params.get('MA_TREND_PERIOD', DEFAULT_MA_PERIOD),
            'MIN_LIST_DAYS': params.get('MIN_LIST_DAYS', DEFAULT_MIN_LIST_DAYS),
            'FINAL_POOL': params.get('FINAL_POOL', DEFAULT_FINAL_POOL),
            'VOL_SPIKE_MULT': params.get('VOL_SPIKE_MULT', DEFAULT_VOL_SPIKE_MULT),
            'HIGH_PCT_THRESHOLD': params.get('HIGH_PCT_THRESHOLD', DEFAULT_HIGH_PCT_THRESHOLD),
            'MAX_VOLATILITY_10D': params.get('MAX_VOLATILITY_10D', DEFAULT_MAX_VOLATILITY_10D)
        }
        
        for i in range(start_index, total_iterations):
            select_date = trade_dates[i]
            next_trade_date = trade_dates[i+1] 
            
            select_df_full = run_scoring_for_date(select_date, score_params) 

            result = {
                'é€‰è‚¡æ—¥': select_date, 
                'è‚¡ç¥¨': 'æ— ç¬¦åˆæ¡ä»¶', 
                'ä¹°å…¥ä»· (T+1 å¼€ç›˜)': np.nan, 
                'è¯„åˆ†': np.nan,
                'å¸‚å€¼ (äº¿)': np.nan
            }
            for N in HOLDING_PERIODS:
                 result[f'T+{N} æ”¶ç›Šç‡ (%)'] = 0.0
                 result[f'T+{N} å–å‡ºä»·'] = np.nan
                 
            
            if not select_df_full.empty:
                top_pick = select_df_full.iloc[0] 
                ts_code = top_pick['ts_code']
                
                max_retries = 3 
                buy_day_data = pd.DataFrame()
                for attempt in range(max_retries):
                    buy_day_data = safe_get(pro.daily, ts_code=ts_code, trade_date=next_trade_date)
                    if not buy_day_data.empty: break
                    time.sleep(1) 
                    
                buy_price = buy_day_data.iloc[0]['open'] if not buy_day_data.empty and 'open' in buy_day_data.columns else np.nan
                
                result['è‚¡ç¥¨'] = f"{top_pick.get('name', 'N/A')}({ts_code})"
                result['ä¹°å…¥ä»· (T+1 å¼€ç›˜)'] = buy_price
                result['è¯„åˆ†'] = top_pick['ç»¼åˆè¯„åˆ†']
                result['å¸‚å€¼ (äº¿)'] = top_pick['circ_mv_wan'] / 10000.0 if not pd.isna(top_pick['circ_mv_wan']) else np.nan
                
                if buy_price > 0 and not pd.isna(buy_price):
                    
                    for N in HOLDING_PERIODS:
                        sell_trade_date = trade_dates[i+N] 
                        
                        sell_day_data = safe_get(pro.daily, ts_code=ts_code, trade_date=sell_trade_date)
                        
                        if not sell_day_data.empty and 'close' in sell_day_data.columns:
                            sell_price = sell_day_data.iloc[0]['close']
                            result[f'T+{N} å–å‡ºä»·'] = sell_price
                            
                            if not pd.isna(sell_price):
                                return_pct = (sell_price / buy_price) - 1.0
                                return_pct = max(-0.10, return_pct) 
                                result[f'T+{N} æ”¶ç›Šç‡ (%)'] = return_pct * 100
                        
            status['results'].append(result)
            status['current_index'] = i + 1
            status['progress'] = (i + 1) / total_iterations
            
            pbar.progress(status['progress'], text=f"æ­£åœ¨å›æµ‹ {select_date}... [{i+1}/{total_iterations}]")
            
            if (i+1) % 2 == 0 or (i + 1) == total_iterations: 
                 st.rerun() 
        
        status['progress'] = 1.0
        status['current_index'] = total_iterations
        pbar.progress(1.0, text="å›æµ‹å®Œæˆã€‚")
        
        results_df = pd.DataFrame(status['results'])
        
        if results_df.empty:
            st.warning("å›æµ‹ç»“æœä¸ºç©ºã€‚")
            return
            
        st.markdown("---")
        st.subheader("ğŸ’¡ æœ€ç»ˆå›æµ‹æŒ‡æ ‡ï¼ˆå¤šå‘¨æœŸå¯¹æ¯”ï¼‰")
        
        cols_metrics = st.columns(len(HOLDING_PERIODS))
        
        for idx, N in enumerate(HOLDING_PERIODS):
            col_name = f'T+{N} æ”¶ç›Šç‡ (%)'
            results_df[col_name] = results_df[col_name].replace([np.inf, -np.inf], 0.0).fillna(0.0)
            cumulative_return = (results_df[col_name] / 100 + 1).product() - 1
            wins = (results_df[col_name] > 0).sum()
            total_trades = len(results_df)
            win_rate = wins / total_trades if total_trades > 0 else 0

            with cols_metrics[idx]:
                st.metric(f"ç´¯è®¡æ”¶ç›Šç‡ (T+{N})", f"{cumulative_return*100:.2f}%")
                st.caption(f"èƒœç‡: {win_rate*100:.2f}% | äº¤æ˜“æ¬¡æ•°: {total_trades}")
        
        st.markdown("---")
        st.subheader("ğŸ“‹ æ¯æ—¥äº¤æ˜“è®°å½•")
        
        display_cols = ['é€‰è‚¡æ—¥', 'è‚¡ç¥¨', 'å¸‚å€¼ (äº¿)', 'è¯„åˆ†', 'ä¹°å…¥ä»· (T+1 å¼€ç›˜)']
        for N in HOLDING_PERIODS:
            display_cols.append(f'T+{N} æ”¶ç›Šç‡ (%)')
            
        st.dataframe(results_df[display_cols], use_container_width=True)


# ----------------------------------------------------
# å®æ—¶é€‰è‚¡æ¨¡å— (V13.8)
# ----------------------------------------------------
def run_live_selection(last_trade, params):
    st.write(f"æ­£åœ¨è¿è¡Œå®æ—¶é€‰è‚¡ï¼ˆæœ€è¿‘æœ‰æ•ˆäº¤æ˜“æ—¥ï¼š{last_trade}ï¼‰...")
    
    params_dict = {
        'MIN_PRICE': params.get('MIN_PRICE', DEFAULT_MIN_PRICE), 
        'MAX_PRICE': params.get('MAX_PRICE', DEFAULT_MAX_PRICE), 
        'MIN_TURNOVER': params.get('MIN_TURNOVER', DEFAULT_MIN_TURNOVER), 
        'MIN_AMOUNT': params.get('MIN_AMOUNT', DEFAULT_MIN_AMOUNT), 
        'MIN_CIRC_MV_Billion': params.get('MIN_CIRC_MV_Billion', DEFAULT_MIN_CIRC_MV_B),
        'MAX_CIRC_MV_Billion': params.get('MAX_CIRC_MV_Billion', DEFAULT_MAX_CIRC_MV_B),
        'MA_TREND_PERIOD': params.get('MA_TREND_PERIOD', DEFAULT_MA_PERIOD),
        'MIN_LIST_DAYS': params.get('MIN_LIST_DAYS', DEFAULT_MIN_LIST_DAYS),
        'FINAL_POOL': params.get('FINAL_POOL', DEFAULT_FINAL_POOL),
        'VOL_SPIKE_MULT': params.get('VOL_SPIKE_MULT', DEFAULT_VOL_SPIKE_MULT),
        'HIGH_PCT_THRESHOLD': params.get('HIGH_PCT_THRESHOLD', DEFAULT_HIGH_PCT_THRESHOLD),
        'MAX_VOLATILITY_10D': params.get('MAX_VOLATILITY_10D', DEFAULT_MAX_VOLATILITY_10D)
    }
    
    fdf_full = run_scoring_for_date(last_trade, params_dict)

    if fdf_full.empty:
        st.error(f"æ¸…æ´—å’Œè¯„åˆ†åæ²¡æœ‰å€™é€‰ã€‚è¯·æ£€æŸ¥ç¡¬æ€§è¿‡æ»¤å‚æ•°æ˜¯å¦è¿‡äºä¸¥æ ¼ã€‚")
        st.stop()

    fdf = fdf_full.head(params.get('TOP_DISPLAY', DEFAULT_TOP_DISPLAY)).copy()
    fdf.index = fdf.index + 1

    st.success(f"è¯„åˆ†å®Œæˆï¼šæ€»å€™é€‰ {len(fdf_full)} æ”¯ï¼Œæ˜¾ç¤º Top {min(params.get('TOP_DISPLAY', DEFAULT_TOP_DISPLAY), len(fdf))}ã€‚")
    
    fdf['æµé€šå¸‚å€¼ (äº¿)'] = fdf['circ_mv_wan'] / 10000.0
    
    final_display_cols = [
        'name','ts_code','ç»¼åˆè¯„åˆ†','pct_chg','æµé€šå¸‚å€¼ (äº¿)','turnover_rate',
        'vol_ratio','10d_return','net_mf_amount','macd','volatility_10'
    ]
    
    for c in final_display_cols:
        if c not in fdf.columns: fdf[c] = np.nan
    
    if 'net_mf_amount' in fdf.columns:
        fdf['å‡€æµå…¥ (äº¿)'] = fdf['net_mf_amount'] / 1e8
        final_display_cols[final_display_cols.index('net_mf_amount')] = 'å‡€æµå…¥ (äº¿)'
        
    
    st.dataframe(fdf[final_display_cols], use_container_width=True, height=500)

    download_cols = [c for c in fdf_full.columns if c not in ['list_date', 'days_since_list', 'circ_mv_wan']]
    out_csv = fdf_full[download_cols].head(200).to_csv(index=True, encoding='utf-8-sig')
    st.download_button("ä¸‹è½½è¯„åˆ†ç»“æœï¼ˆå‰200ï¼‰CSV", data=out_csv, file_name=f"score_result_{last_trade}_V13_8.csv", mime="text/csv")

    st.markdown("### å°ç»“ä¸æ“ä½œæç¤ºï¼ˆV13.8 æ•°æ®æ ¡éªŒç¨³å®šç‰ˆï¼‰")
    st.markdown(f"""
- **ã€æ ¸å¿ƒä¿®æ­£ã€‘** å·²ä¿®å¤â€œæœªæ¥æ—¥æœŸâ€é—®é¢˜ï¼Œç°åœ¨é€‰è‚¡æ—¥ **{last_trade}** æ˜¯ Tushare æ¥å£å®é™…æœ‰æ•°æ®å¯ç”¨çš„æ—¥æœŸã€‚
- **ã€å¸‚å€¼èŒƒå›´ã€‘** å½“å‰æµé€šå¸‚å€¼èŒƒå›´ï¼š**{params_dict['MIN_CIRC_MV_Billion']} äº¿ åˆ° {params_dict['MAX_CIRC_MV_Billion']} äº¿**ã€‚
- **ã€æ“ä½œå»ºè®®ã€‘** **å¦‚æœæ‚¨ä»æœªçœ‹åˆ° 100 äº¿ - 200 äº¿çš„è‚¡ç¥¨**ï¼Œè¯·åœ¨å·¦ä¾§è¾¹æ å°†å‚æ•°è°ƒæ•´ä¸ºï¼š
    - æœ€ä½æµé€šå¸‚å€¼ (äº¿) = **100.0**
    - æœ€é«˜æµé€šå¸‚å€¼ (äº¿) = **200.0**
    - ç„¶åé‡æ–°è¿è¡Œã€‚
""")


# ----------------------------------------------------
# ä¸»ç¨‹åºæ§åˆ¶é€»è¾‘
# ----------------------------------------------------
params = {
    'FINAL_POOL': FINAL_POOL, 'TOP_DISPLAY': TOP_DISPLAY,
    'MIN_PRICE': MIN_PRICE, 'MAX_PRICE': MAX_PRICE, 'MIN_TURNOVER': MIN_TURNOVER,
    'MIN_AMOUNT': MIN_AMOUNT, 
    'MIN_CIRC_MV_Billion': MIN_CIRC_MV_Billion,
    'MAX_CIRC_MV_Billion': MAX_CIRC_MV_Billion,
    'MA_TREND_PERIOD': MA_TREND_PERIOD,
    'MIN_LIST_DAYS': MIN_LIST_DAYS,
    'VOL_SPIKE_MULT': VOL_SPIKE_MULT,
    'HIGH_PCT_THRESHOLD': HIGH_PCT_THRESHOLD,
    'MAX_VOLATILITY_10D': MAX_VOLATILITY_10D
}

if st.session_state.get('run_backtest', False):
    run_simple_backtest(BACKTEST_DAYS, params)
    
elif st.session_state.get('run_selection', False):
    run_live_selection(last_trade, params)
    
else:
    st.info("è¯·ç‚¹å‡»ä¸Šæ–¹çš„æŒ‰é’®å¼€å§‹è¿è¡Œã€‚")
