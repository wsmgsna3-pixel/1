import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
import altair as alt
import time
import gc
from datetime import datetime, timedelta

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="V32.0 å®Œç¾æŒ‡æŒ¥å®˜", layout="wide")

# ==========================================
# 2. å…¨å±€ç¼“å­˜ä¸æ™ºèƒ½å·¥å…·
# ==========================================
@st.cache_resource
def get_pro_api(token):
    if not token: return None
    ts.set_token(token)
    return ts.pro_api()

# --- ä¿®å¤ç‰ˆï¼šæ›´ç¨³å¥çš„æ—¥æœŸå›æº¯ ---
def get_latest_trade_date(_pro, curr_date_str):
    """
    æ™ºèƒ½å¯»æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥ã€‚
    ä¿®å¤é€»è¾‘ï¼šæ‰©å¤§å›æº¯çª—å£è‡³60å¤©ï¼Œç¡®ä¿è¦†ç›–é•¿å‡ã€‚
    """
    try:
        # å¦‚æœå½“å¤©æ˜¯äº¤æ˜“æ—¥ï¼Œç›´æ¥è¿”å›
        df_curr = _pro.trade_cal(exchange='', start_date=curr_date_str, end_date=curr_date_str, is_open='1')
        if not df_curr.empty:
            return curr_date_str
            
        # å¦åˆ™å¾€å‰æ‰¾ 60 å¤©
        end_dt = pd.to_datetime(curr_date_str)
        start_dt = end_dt - timedelta(days=60)
        
        df = _pro.trade_cal(exchange='', start_date=start_dt.strftime('%Y%m%d'), 
                            end_date=curr_date_str, is_open='1')
        
        if not df.empty:
            # å–æœ€åä¸€ä¸ªï¼Œå³æœ€è¿‘çš„ä¸€ä¸ªäº¤æ˜“æ—¥
            return df['cal_date'].iloc[-1]
            
        return curr_date_str # å…œåº•
    except:
        return curr_date_str

@st.cache_data(ttl=86400 * 7)
def fetch_daily_atomic_data(date, _pro):
    if _pro is None: return {}
    try:
        df_daily = _pro.daily(trade_date=date)
        df_basic = _pro.daily_basic(trade_date=date, fields='ts_code,turnover_rate,circ_mv,pe_ttm')
        df_names = _pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,industry')
        
        df_cyq = _pro.cyq_perf(trade_date=date)
        if df_cyq.empty: 
             for i in range(1, 4):
                 prev = (pd.to_datetime(date) - pd.Timedelta(days=i)).strftime('%Y%m%d')
                 df_cyq = _pro.cyq_perf(trade_date=prev)
                 if not df_cyq.empty: break
        
        return {'daily': df_daily, 'basic': df_basic, 'cyq': df_cyq, 'names': df_names}
    except Exception: return {}

@st.cache_data(ttl=86400)
def get_market_sentiment(start, end, _pro):
    if _pro is None: return {}
    try:
        real_start = (pd.to_datetime(start) - pd.Timedelta(days=90)).strftime('%Y%m%d')
        df = _pro.index_daily(ts_code='000001.SH', start_date=real_start, end_date=end)
        df = df.sort_values('trade_date', ascending=True)
        df['ma20'] = df['close'].rolling(20).mean()
        return df.set_index('trade_date')['close'].gt(df.set_index('trade_date')['ma20']).to_dict()
    except: return {}

# ==========================================
# 3. é€»è¾‘å±‚
# ==========================================
def run_strategy_logic(snapshot, p_min, p_max, to_max, top_n=1):
    if not snapshot: return None
    d1, d2, d3, d4 = snapshot.get('daily'), snapshot.get('basic'), snapshot.get('names'), snapshot.get('cyq')
    
    if d1 is None or d1.empty or d2 is None or d2.empty or d4 is None or d4.empty: return None
    if 'cost_50pct' not in d4.columns: return None
    
    m1 = pd.merge(d1, d2, on='ts_code')
    m2 = pd.merge(m1, d3, on='ts_code')
    df = pd.merge(m2, d4[['ts_code', 'cost_50pct', 'winner_rate']], on='ts_code')
    
    df['bias'] = (df['close'] - df['cost_50pct']) / df['cost_50pct']
    
    condition = (
        (df['bias'] > -0.03) & (df['bias'] < 0.15) & 
        (df['winner_rate'] < 70) &
        (df['circ_mv'] > 300000) &  
        (df['close'] >= p_min) &       
        (df['close'] <= p_max) &       
        (df['turnover_rate'] < to_max) 
    )
    
    sorted_df = df[condition].sort_values('bias', ascending=True)
    if sorted_df.empty: return None
    return sorted_df.head(top_n)

# ==========================================
# 4. ä¾§è¾¹æ ï¼šé…ç½®ä¸­å¿ƒ
# ==========================================
st.sidebar.header("ğŸ›ï¸ æŒ‡æŒ¥å®˜æ§åˆ¶å°")
token_input = st.sidebar.text_input("Tushare Token", type="password")
pro = get_pro_api(token_input)

st.sidebar.divider()
st.sidebar.subheader("âš“ ä»“ä½ç®¡ç†")
# è¿™é‡Œçš„æ»‘å—å†³å®šäº†æ˜¾ç¤ºå‡ åªè‚¡ç¥¨ã€‚é»˜è®¤è®¾ä¸º3ï¼Œé¿å…è¯¯è§£ã€‚
cfg_position_count = st.sidebar.slider("æ˜¾ç¤ºè‚¡ç¥¨æ•°é‡ (Top N)", 1, 5, 3, help="æƒ³çœ‹æ›´å¤šå¤‡é€‰ï¼Ÿè¯·æ‹‰å¤§è¿™ä¸ªæ•°å­—ã€‚")

st.sidebar.divider()
st.sidebar.subheader("ğŸ¯ ä¸Šå¸å‚æ•° (é»˜è®¤æœ€ä¼˜)")
cfg_min_price = st.sidebar.number_input("æœ€ä½ä»· (å…ƒ)", value=8.1, step=0.1)
cfg_max_price = st.sidebar.number_input("æœ€é«˜ä»· (å…ƒ)", value=20.0, step=0.5)
cfg_max_turnover = st.sidebar.slider("æœ€å¤§æ¢æ‰‹ç‡ (%)", 0.5, 5.0, 2.1, step=0.1)

st.sidebar.divider()
st.sidebar.subheader("ğŸ›¡ï¸ é£æ§å‚æ•°")
cfg_stop_loss = st.sidebar.slider("æ­¢æŸçº¿ (-%)", 3.0, 15.0, 8.5, step=0.5)
cfg_max_hold = st.sidebar.slider("æœ€é•¿æŒè‚¡ (å¤©)", 5, 30, 15)
cfg_trail_start = st.sidebar.slider("æ­¢ç›ˆå¯åŠ¨ (+%)", 5.0, 15.0, 8.0, step=0.5) / 100.0
cfg_trail_drop = st.sidebar.slider("å›è½å–å‡º (-%)", 1.0, 5.0, 3.0, step=0.5) / 100.0
stop_loss_decimal = cfg_stop_loss / 100.0

# --- åŠ¨æ€æ—¥æœŸ (ä¿®å¤ä¸æ›´æ–°çš„é—®é¢˜) ---
today = datetime.now()
# é»˜è®¤å›æµ‹ç»“æŸæ—¥æœŸä¸ºä»Šå¤©
default_end_date = today.strftime('%Y%m%d')
# é»˜è®¤å›æµ‹å¼€å§‹æ—¥æœŸä¸ºä»Šå¹´å¹´åˆ
default_start_date = f"{today.year}0101"

st.sidebar.divider()
st.sidebar.subheader("â³ æ—¶é—´è®¾ç½®")
start_date = st.sidebar.text_input("å¼€å§‹æ—¥æœŸ", value=default_start_date)
end_date = st.sidebar.text_input("ç»“æŸæ—¥æœŸ", value=default_end_date, help="å·²è‡ªåŠ¨æ›´æ–°ä¸ºä»Šå¤©")

# ==========================================
# 5. ä¸»ç¨‹åº
# ==========================================
st.title("ğŸš€ V32.0 å®Œç¾æŒ‡æŒ¥å®˜ (æ™ºèƒ½ä¿®å¤ç‰ˆ)")

tab1, tab2 = st.tabs(["ğŸ“¡ æ™ºèƒ½å®ç›˜æ‰«æ", "ğŸ§ª å†å²åˆ†ä»“å›æµ‹"])

# --- Tab 1: æ™ºèƒ½å®ç›˜ ---
with tab1:
    col_d, col_b = st.columns([3, 1])
    with col_d:
        # é»˜è®¤é€‰ä¸­ä»Šå¤©
        scan_date_input = st.date_input("é€‰æ‹©æ—¥æœŸ (æ”¯æŒè‡ªåŠ¨å›æº¯)", value=pd.Timestamp.now())
    scan_date_str = scan_date_input.strftime('%Y%m%d')
    
    if col_b.button("å¼€å§‹æ‰«æ", type="primary", use_container_width=True):
        if not pro:
            st.error("è¯·å…ˆè¾“å…¥ Token")
            st.stop()
            
        with st.spinner("æ­£åœ¨æ ¡å¯¹äº¤æ˜“æ—¥å†..."):
            # æ™ºèƒ½ä¿®æ­£æ—¥æœŸ
            real_date_str = get_latest_trade_date(pro, scan_date_str)
            
            if real_date_str != scan_date_str:
                st.info(f"ğŸ“… æ‚¨é€‰æ‹©çš„ **{scan_date_str}** æ˜¯éäº¤æ˜“æ—¥ï¼Œç³»ç»Ÿå·²è‡ªåŠ¨åˆ‡æ¢è‡³æœ€è¿‘çš„äº¤æ˜“æ—¥ï¼š**{real_date_str}**")
            
            # è·å–æ•°æ®
            snap = fetch_daily_atomic_data(real_date_str, pro)
            # è¿è¡Œç­–ç•¥
            fleet = run_strategy_logic(snap, cfg_min_price, cfg_max_price, cfg_max_turnover, cfg_position_count)
            
            if fleet is not None and not fleet.empty:
                st.success(f"âš“ æˆåŠŸé€‰å‡º {len(fleet)} åªæ ‡çš„ (åŸºäº {real_date_str} æ•°æ®)")
                
                # éšè—ç´¢å¼•ï¼Œé˜²æ­¢è¯¯è§£
                st.dataframe(fleet[['ts_code', 'name', 'close', 'bias', 'turnover_rate', 'winner_rate', 'industry']].style.format({
                    'close': '{:.2f}', 'bias': '{:.4f}', 'turnover_rate': '{:.2f}', 'winner_rate': '{:.1f}'
                }), hide_index=True)
                
                st.info(f"""
                **ğŸ“ äº¤æ˜“è®¡åˆ’ï¼š**
                1.  **æ ‡çš„**ï¼š{', '.join(fleet['name'].tolist())}
                2.  **ä¹°å…¥**ï¼šä¸‹ä¸ªäº¤æ˜“æ—¥å¼€ç›˜ä¹°å…¥ã€‚
                3.  **é£æ§**ï¼šæ­¢æŸ -{cfg_stop_loss}%ï¼ŒæŒè‚¡ {cfg_max_hold} å¤©ã€‚
                """)
            else:
                st.warning(f"åœ¨ {real_date_str} æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ ‡çš„ã€‚å»ºè®®é€‚å½“æ”¾å®½â€˜æ¢æ‰‹ç‡â€™æˆ–â€˜ä»·æ ¼â€™å‚æ•°ã€‚")

# --- Tab 2: å›æµ‹ ---
with tab2:
    if st.button("ğŸš€ è¿è¡Œå›æµ‹", type="primary", use_container_width=True):
        if not pro:
            st.error("Token æ— æ•ˆ")
            st.stop()
            
        cal_df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date, is_open='1')
        dates = sorted(cal_df['cal_date'].tolist())
        market_safe_map = get_market_sentiment(start_date, end_date, pro)
        
        active_signals = [] 
        finished_signals = [] 
        
        progress_bar = st.progress(0)
        
        for i, date in enumerate(dates):
            progress_bar.progress((i + 1) / len(dates))
            if i % 20 == 0: gc.collect()
            
            snap = fetch_daily_atomic_data(date, pro)
            price_map = {}
            if snap and not snap['daily'].empty:
                price_map = snap['daily'].set_index('ts_code')[['open','high','low','close']].to_dict('index')
            
            is_market_safe = market_safe_map.get(date, False)
            
            # æŒä»“
            signals_still_active = []
            curr_dt = pd.to_datetime(date)
            
            for sig in active_signals:
                code = sig['code']
                if curr_dt <= pd.to_datetime(sig['buy_date']):
                    if code in price_map: sig['highest'] = max(sig['highest'], price_map[code]['high'])
                    signals_still_active.append(sig)
                    continue

                if code in price_map:
                    ph, pl, pc = price_map[code]['high'], price_map[code]['low'], price_map[code]['close']
                    if ph > sig['highest']: sig['highest'] = ph
                    
                    cost = sig['buy_price']
                    peak = sig['highest']
                    
                    reason = ""
                    sell_p = pc
                    
                    if (pl - cost) / cost <= -stop_loss_decimal:
                        reason = "æ­¢æŸ"
                        sell_p = cost * (1 - stop_loss_decimal)
                    elif (peak - cost)/cost >= cfg_trail_start and (peak - pc)/peak >= cfg_trail_drop:
                        reason = "æ­¢ç›ˆ"
                        sell_p = peak * (1 - cfg_trail_drop)
                    elif (curr_dt - pd.to_datetime(sig['buy_date'])).days >= cfg_max_hold:
                        reason = "è¶…æ—¶"
                    
                    if reason:
                        ret = (sell_p - cost) / cost - 0.0006
                        finished_signals.append({
                            'code': code, 'buy_date': sig['buy_date'], 
                            'ret': ret, 'reason': reason, 'rank': sig['rank']
                        })
                    else:
                        signals_still_active.append(sig)
                else:
                    signals_still_active.append(sig)
            active_signals = signals_still_active
            
            # ä¹°å…¥
            if is_market_safe:
                fleet = run_strategy_logic(snap, cfg_min_price, cfg_max_price, cfg_max_turnover, cfg_position_count)
                if fleet is not None and not fleet.empty:
                    for rank_idx, (_, row) in enumerate(fleet.iterrows()):
                        code = row['ts_code']
                        if code in price_map:
                            active_signals.append({
                                'code': code, 'buy_date': date, 
                                'buy_price': price_map[code]['open'], 'highest': price_map[code]['open'],
                                'rank': rank_idx + 1
                            })
        
        progress_bar.empty()
        
        if finished_signals:
            df_res = pd.DataFrame(finished_signals)
            df_res['ret_pct'] = df_res['ret'] * 100
            
            st.divider()
            st.markdown(f"### ğŸ“Š æŠ¥å‘Š (Top {cfg_position_count})")
            
            avg_ret = df_res['ret'].mean() * 100
            win_rate = (df_res['ret'] > 0).mean() * 100
            
            c1, c2, c3 = st.columns(3)
            c1.metric("å•ç¬”å¹³å‡æœŸæœ›", f"{avg_ret:.2f}%")
            c2.metric("èƒœç‡", f"{win_rate:.1f}%")
            c3.metric("æ€»äº¤æ˜“æ¬¡æ•°", f"{len(df_res)}")
            
            st.subheader("ğŸ† å„åæ¬¡è¡¨ç°")
            rank_stats = df_res.groupby('rank')['ret_pct'].agg(['count', 'mean', 'sum', lambda x: (x>0).mean()*100])
            rank_stats.columns = ['äº¤æ˜“æ•°', 'å•ç¬”æœŸæœ›%', 'æ€»æ”¶ç›Š%', 'èƒœç‡%']
            st.table(rank_stats.style.format("{:.2f}").background_gradient(subset=['å•ç¬”æœŸæœ›%'], cmap='Greens'))
        else:
            st.warning("æ— äº¤æ˜“æ•°æ®")
