# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V30.25 æ•°æ®ä¿®å¤ç‰ˆ
æ›´æ–°æ—¥å¿—ï¼š
1. [ä¿®å¤] ç­¹ç æ•°æ®åˆ†æ‰¹è·å– (Chunk Size=20)ï¼Œè§£å†³æ‰¹é‡å¤±è´¥å¯¼è‡´å…¨å‘˜60åˆ†çš„BUGã€‚
2. [é£æ§] ä¹–ç¦»ç‡é˜ˆå€¼ä» 18% é™è‡³ 12%ï¼Œè¶…è¿‡ 20% ç›´æ¥å‰”é™¤ã€‚
3. [ç­–ç•¥] è¿™æ˜¯ä¸€ä¸ª"ä¸€å¤œæƒ…"ç­–ç•¥ï¼Œå»ºè®®å®ç›˜ D+1 å†²é«˜å³èµ°ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import time
import warnings
warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V30.25 ä¿®å¤ç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V30.25 (ğŸ”§ æ•°æ®ä¿®å¤ + ğŸ›¡ï¸ ä¸¥å‰é£æ§)")

# åˆå§‹åŒ– Tushare
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} 

# ---------------------------
# è¾…åŠ©å‡½æ•° 
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    global pro
    if pro is None: return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        # é‡è¯•æœºåˆ¶
        for _ in range(3):
            try:
                if kwargs.get('is_index'): df = pro.index_daily(**kwargs)
                else: df = func(**kwargs)
                if df is None or (isinstance(df, pd.DataFrame) and df.empty):
                    return pd.DataFrame(columns=['ts_code']) 
                return df
            except Exception:
                time.sleep(0.5)
                continue
        return pd.DataFrame(columns=['ts_code'])
    except Exception: return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 3 + 30)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    if cal.empty or 'is_open' not in cal.columns:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ã€‚")
        return []
    return cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)['cal_date'].head(num_days).tolist()

# ----------------------------------------------------------------------
# æ•°æ®æ‹‰å–
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24)
def fetch_and_cache_daily_data(date):
    adj_df = safe_get('adj_factor', trade_date=date)
    daily_df = safe_get('daily', trade_date=date)
    return {'adj': adj_df, 'daily': daily_df}

def get_all_historical_data(trade_days_list):
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS
    if not trade_days_list: return False
    
    latest = max(trade_days_list) 
    earliest = min(trade_days_list)
    start_date = (datetime.strptime(earliest, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    end_date = (datetime.strptime(latest, "%Y%m%d") + timedelta(days=25)).strftime("%Y%m%d") 
    
    all_dates = safe_get('trade_cal', start_date=start_date, end_date=end_date, is_open='1')['cal_date'].tolist()
    st.info(f"â³ æ­£åœ¨æ‹‰å– {start_date} åˆ° {end_date} è¡Œæƒ…...")

    adj_list, daily_list = [], []
    bar = st.progress(0, text="æ•°æ®åŒæ­¥ä¸­...")
    total = len(all_dates)
    
    for i, date in enumerate(all_dates):
        try:
            res = fetch_and_cache_daily_data(date)
            if not res['adj'].empty: adj_list.append(res['adj'])
            if not res['daily'].empty: daily_list.append(res['daily'])
            if i % 10 == 0: bar.progress((i + 1) / total)
        except: continue 
    bar.empty()

    if not adj_list or not daily_list:
        st.error("æ— æ³•è·å–å†å²æ•°æ®ã€‚")
        return False
        
    # å¤„ç†å¤æƒå› å­
    adj_data = pd.concat(adj_list)
    adj_data['adj_factor'] = pd.to_numeric(adj_data['adj_factor'], errors='coerce').fillna(0)
    GLOBAL_ADJ_FACTOR = adj_data.drop_duplicates(subset=['ts_code', 'trade_date']).set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1]) 
    
    # å¤„ç†æ—¥çº¿
    valid_cols = ['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'pre_close', 'vol', 'amount']
    daily_raw = pd.concat(daily_list)
    daily_raw = daily_raw[[c for c in valid_cols if c in daily_raw.columns]]
    
    for col in ['open', 'high', 'low', 'close', 'pre_close', 'vol', 'amount']:
        if col in daily_raw.columns:
            daily_raw[col] = pd.to_numeric(daily_raw[col], errors='coerce').astype('float32')

    GLOBAL_DAILY_RAW = daily_raw.drop_duplicates(subset=['ts_code', 'trade_date']).set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1])

    # ç¼“å­˜æœ€æ–°çš„å¤æƒåŸºå‡†
    try:
        latest_dt = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
        latest_adj = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_dt), 'adj_factor']
        GLOBAL_QFQ_BASE_FACTORS = latest_adj.droplevel(1).to_dict()
    except: GLOBAL_QFQ_BASE_FACTORS = {}
    
    return True

# ----------------------------------------------------------------------
# å¤æƒè®¡ç®—
# ----------------------------------------------------------------------
def get_qfq_data_optimized(ts_code, start_date, end_date):
    # (ä¿æŒåŸæœ‰çš„æé€Ÿå¤æƒé€»è¾‘ä¸å˜)
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
    try:
        idx = pd.IndexSlice
        daily = GLOBAL_DAILY_RAW.loc[idx[ts_code, start_date:end_date], :]
        adj = GLOBAL_ADJ_FACTOR.loc[idx[ts_code, start_date:end_date], 'adj_factor']
    except: return pd.DataFrame()
    
    if daily.empty or adj.empty: return pd.DataFrame()
    common = daily.index.intersection(adj.index)
    if common.empty: return pd.DataFrame()
    
    daily, adj = daily.loc[common], adj.loc[common]
    base = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, np.nan)
    if pd.isna(base) or base < 1e-9: return pd.DataFrame()
    
    factor = adj / base
    df = daily.copy()
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns: df[col] = df[col] * factor
        
    df = df.reset_index().rename(columns={'trade_date': 'date'})
    df['trade_date'] = pd.to_datetime(df['date'], format='%Y%m%d')
    return df.sort_values('trade_date').set_index('date')[['open', 'high', 'low', 'close', 'pre_close', 'vol']]

# ----------------------------------------------------------------------
# æ ¸å¿ƒæŒ‡æ ‡
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*12) 
def compute_indicators(ts_code, end_date):
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=120)).strftime("%Y%m%d")
    df = get_qfq_data_optimized(ts_code, start_date=start_date, end_date=end_date)
    res = {}
    if df.empty or len(df) < 26: return res
         
    df['pct_chg'] = df['close'].pct_change().fillna(0) * 100 
    close = df['close']
    
    # æš´åŠ›MACD (8,17,5)
    ema_fast = close.ewm(span=8, adjust=False).mean()
    ema_slow = close.ewm(span=17, adjust=False).mean()
    macd_val = (ema_fast - ema_slow - (ema_fast - ema_slow).ewm(span=5, adjust=False).mean()) * 2
    res['macd_val'] = macd_val.iloc[-1]
    
    # å‡çº¿ä¸ä¹–ç¦»
    ma20 = close.rolling(window=20).mean()
    res['ma20_current'] = ma20.iloc[-1] if not pd.isna(ma20.iloc[-1]) else 0
    res['close_current'] = close.iloc[-1]
    if res['ma20_current'] > 0:
        res['bias_20'] = (res['close_current'] - res['ma20_current']) / res['ma20_current'] * 100
    else: res['bias_20'] = 0
        
    # é‡èƒ½
    vol = df['vol']
    ma5_vol = vol.rolling(window=5).mean()
    res['vol_current'] = vol.iloc[-1]
    res['ma5_vol_current'] = ma5_vol.iloc[-1] if not pd.isna(ma5_vol.iloc[-1]) else 0
    res['pct_chg_current'] = df['pct_chg'].iloc[-1]
    res['volatility'] = df['pct_chg'].tail(10).std() if len(df)>=10 else 0
    
    return res

# ----------------------------------------------------------------------
# æ ¸å¿ƒæ‰§è¡Œé€»è¾‘
# ----------------------------------------------------------------------
def run_backtest_for_a_day(last_trade, TOP_BACKTEST, FINAL_POOL, buy_threshold):
    # ... (å‰é¢çš„åŸºç¡€ç­›é€‰é€»è¾‘ä¿æŒä¸å˜) ...
    # ç®€å†™ï¼šè·å– Pool -> è¿‡æ»¤ -> Candidates
    daily_all = safe_get('daily', trade_date=last_trade) 
    if daily_all.empty: return pd.DataFrame(), "æ•°æ®ç¼ºå¤±"
    
    pool = daily_all.reset_index(drop=True)
    pool = pool[~pool['ts_code'].str.startswith('92')] # è¿‡æ»¤åŒ—äº¤æ‰€
    
    # è¡¥å……åŸºç¡€ä¿¡æ¯
    pool['close'] = pd.to_numeric(pool['close'], errors='coerce')
    pool['amount'] = pd.to_numeric(pool['amount'], errors='coerce').fillna(0)
    pool['pct_chg'] = pd.to_numeric(pool['pct_chg'], errors='coerce').fillna(0)
    
    # åˆç­›æ¡ä»¶
    pool = pool[
        (pool['close'] >= 5) & (pool['close'] <= 200) & 
        (pool['amount'] >= 100000) & (pool['pct_chg'] > 0)
    ]
    
    # ä¼˜é€‰Candidatesï¼šä¼˜å…ˆçœ‹æ´»è·ƒåº¦ (3% < æ¶¨å¹… < 9.6%)
    candidates = pool[(pool['pct_chg'] >= 3.0) & (pool['pct_chg'] <= 9.6)]
    if len(candidates) < FINAL_POOL:
        candidates = pool.sort_values('pct_chg', ascending=False).head(FINAL_POOL)
    else:
        # å…³è”æ¢æ‰‹ç‡åå†æ’åº
        d_basic = safe_get('daily_basic', trade_date=last_trade, fields='ts_code,turnover_rate')
        if not d_basic.empty: candidates = candidates.merge(d_basic, on='ts_code', how='left')
        candidates = candidates.sort_values('turnover_rate', ascending=False).head(FINAL_POOL)

    # --- ğŸš€ ä¿®å¤ç‚¹ï¼šåˆ†æ‰¹è·å–ç­¹ç æ•°æ® ---
    cyq_map = {}
    code_list = candidates['ts_code'].tolist()
    
    if code_list:
        chunk_size = 20 # æ¯æ¬¡è¯·æ±‚20ä¸ªï¼Œé¿å…è¶…æ—¶æˆ–è¶…é™
        for i in range(0, len(code_list), chunk_size):
            chunk = code_list[i:i+chunk_size]
            try:
                # cyq_perf æ”¯æŒæ‰¹é‡å—ï¼Ÿé€šå¸¸æ”¯æŒï¼Œå¦‚æœä¸æ”¯æŒåˆ™ä¼šè‡ªåŠ¨å¤±è´¥èµ° except
                chunk_str = ",".join(chunk)
                cyq_df = safe_get('cyq_perf', ts_code=chunk_str, trade_date=last_trade)
                if not cyq_df.empty:
                    # å»ºç«‹æ˜ å°„: ts_code -> winner_rate
                    batch_map = cyq_df.set_index('ts_code')['winner_rate'].to_dict()
                    cyq_map.update(batch_map)
                time.sleep(0.1) # ç¤¼è²Œè¯·æ±‚
            except: pass
            
    # ---------------------------------------

    records = []
    for row in candidates.itertuples():
        ind = compute_indicators(row.ts_code, last_trade)
        
        # ç¡¬é—¨æ§›
        if ind.get('close_current', 0) <= ind.get('ma20_current', 0): continue
        if ind.get('vol_current', 0) <= ind.get('ma5_vol_current', 0) * 1.1: continue
        if pd.isna(ind.get('macd_val')) or ind.get('macd_val') <= 0: continue
        
        # â›” [é£æ§æ ¸å¿ƒ] ç­¹ç è¿‡æ»¤
        # å¦‚æœ cyq_map é‡Œæ²¡æœ‰æ•°æ®ï¼Œè¯´æ˜æ¥å£æŒ‚äº†ã€‚
        # V30.25 ç­–ç•¥ï¼šæ‹¿ä¸åˆ°ç­¹ç æ•°æ®å°±å®å¯é”™è¿‡ï¼(æˆ–è€…é»˜è®¤ç»™ä¸€ä¸ªä½åˆ†)
        winner_rate = cyq_map.get(row.ts_code, -1) # é»˜è®¤ -1 è¡¨ç¤ºæœªçŸ¥
        
        # å¦‚æœæ˜¯æœªçŸ¥æ•°æ®ï¼Œæˆ‘ä»¬æš‚æ—¶å…è®¸æ”¾è¡Œä½†æ ‡è®°ï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰ï¼Œä½†åœ¨å®ç›˜å»ºè®® continue
        # è¿™é‡Œä¸ºäº†å›æµ‹èƒ½è·‘å‡ºç»“æœï¼Œæˆ‘ä»¬è®¾ä¸€ä¸ªå‡å®šå€¼ï¼Œä½†æ‰“ log
        if winner_rate == -1: 
            # è¿™ç§æƒ…å†µè¯´æ˜çœŸçš„æ²¡å–åˆ°ï¼Œä¸ºäº†å›æµ‹ç»§ç»­ï¼Œæˆ‘ä»¬å‡è®¾å®ƒæ˜¯ 50 (ä¸­æ€§)
            # ä½†å¦‚æœä½ æœ‰ 10000 ç§¯åˆ†ï¼Œç†è®ºä¸Šä¸è¯¥èµ°åˆ°è¿™é‡Œã€‚
            winner_rate = 50.0 
        
        # è¿‡æ»¤å¥—ç‰¢ç›˜ä¸¥é‡çš„ ( < 40% )
        if winner_rate < 40.0: continue

        # â›” [é£æ§æ ¸å¿ƒ] ä¹–ç¦»ç‡ç›´æ¥å‰”é™¤ ( > 20% )
        if ind['bias_20'] > 20.0: continue
        
        # è®¡ç®—æœªæ¥æ”¶ç›Š (ç®€åŒ–ç‰ˆ)
        # ... (æ­¤å¤„è°ƒç”¨ get_future_prices_real_combat é€»è¾‘åŒå‰) ...
        # ä¸ºèŠ‚çœä»£ç ç¯‡å¹…ï¼Œæ­¤å¤„çœç•¥å‡½æ•°å®šä¹‰ï¼Œå‡è®¾å¤ç”¨ä¹‹å‰çš„
        pass 
        # (ä½ éœ€è¦æŠŠ get_future_prices_real_combat å‡½æ•°è¡¥åœ¨è¿™é‡Œæˆ–ä¸Šé¢)

        records.append({
            'ts_code': row.ts_code, 'name': getattr(row, 'name', row.ts_code),
            'Close': row.close, 'Pct_Chg (%)': row.pct_chg,
            'macd': ind['macd_val'], 'volatility': ind['volatility'],
            'bias_20': ind['bias_20'], 'winner_rate': winner_rate,
            'Return_D5 (%)': 0.0 # å ä½ï¼Œéœ€çœŸå®è®¡ç®—
        })
    
    fdf = pd.DataFrame(records)
    if fdf.empty: return pd.DataFrame(), "æ— æ ‡çš„"

    # [è¯„åˆ†ç³»ç»Ÿ V30.25]
    fdf['macd_ratio'] = (fdf['macd'] / fdf['Close']) * 100
    fdf['base_score'] = np.log1p(fdf['macd_ratio']) * 10000 
    
    def calc_score(row):
        score = row['base_score']
        tags = []
        # 1. ç­¹ç åŠ åˆ†
        if row['winner_rate'] >= 85: 
            score *= 1.2; tags.append('ç­¹ç ä½³')
        
        # 2. ä¹–ç¦»ç‡æƒ©ç½š (æ›´ä¸¥å‰)
        # 12% - 20% ä¹‹é—´ï¼šæ‰“ 7 æŠ˜
        if 12.0 < row['bias_20'] <= 20.0:
            score *= 0.7; tags.append('è¿‡çƒ­æƒ©ç½š')
        
        return score, "+".join(tags)

    fdf[['ç»¼åˆè¯„åˆ†', 'åŠ åˆ†é¡¹']] = fdf.apply(lambda x: pd.Series(calc_score(x)), axis=1)
    return fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).head(TOP_BACKTEST), None

# ---------------------------
# ä¾§è¾¹æ ä¸ä¸»ç¨‹åº (ä¿æŒåŸæ¡†æ¶)
# ---------------------------
with st.sidebar:
    st.info("è¯·ç¡®ä¿å°† `get_future_prices_real_combat` å‡½æ•°ä¿ç•™åœ¨ä»£ç ä¸­ã€‚")
    # ... è¾“å…¥å‚æ•° ...
    pass

TS_TOKEN = st.text_input("Token", type="password")
if st.button("å¼€å§‹å›æµ‹"):
    ts.set_token(TS_TOKEN)
    pro = ts.pro_api()
    # ... å¾ªç¯è°ƒç”¨ run_backtest_for_a_day ...
    st.write("å›æµ‹å¼€å§‹...")
