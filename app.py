# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V6.0 ç»ˆæå½¢æ€ç­–ç•¥ï¼šè¶…çº§æ¨ªç›˜çªç ´ç‰ˆ
æ›´æ–°è¯´æ˜ï¼š
1. ã€**ç­–ç•¥ç²¾è°ƒ V6.0**ã€‘ï¼šæ ¸å¿ƒå˜åŠ¨ï¼š
   - ç›®æ ‡ï¼šå½»åº•æ”¾å¼ƒâ€œç¼“æ…¢ä¸Šæ¶¨è¶‹åŠ¿â€ï¼Œè½¬å‘â€œæ¨ªç›˜æ•´ç†åçš„åŠ é€Ÿä¸Šæ¶¨â€ï¼ˆåº•éƒ¨å¸ç­¹çªç ´ï¼‰ã€‚
   - **æ³¢åŠ¨ç‡ (w_volatility)** æƒé‡æå‡è‡³ **0.30** (æ ¸å¿ƒå½¢æ€ç¡®è®¤ï¼šä½æ³¢åŠ¨ï¼Œç¡®ä¿æ¨ªç›˜)ã€‚
   - **èµ„é‡‘æµ (w_mf)** ä¿æŒ **0.40** (æ ¸å¿ƒå¯åŠ¨ç¡®è®¤ï¼šå¤§èµ„é‡‘çªç ´)ã€‚
   - **MACD (w_macd)**ã€**10æ—¥å›æŠ¥ (w_trend)** å½’é›¶ã€‚
   - **60 æ—¥ä½ç½® (w_position)** é™è‡³ **0.10** (åªä½œåº•éƒ¨åŒºåŸŸå‚è€ƒï¼Œå½¢æ€ä¼˜å…ˆ)ã€‚
   - **æ¢æ‰‹ç‡ (w_turn)** æå‡è‡³ **0.10** (ç¡®è®¤çªç ´å½“æ—¥çš„æ‰¿æ¥åŠ›)ã€‚
   
   æ–°æƒé‡ç»“æ„ï¼šæ ¸å¿ƒå½¢æ€(0.30) + è¶…çº§èµ„é‡‘(0.40) + æ´»è·ƒåº¦/é˜²å¾¡(0.30)
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import time  
warnings.filterwarnings("ignore")

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V6.0 ç»ˆæå½¢æ€ç­–ç•¥", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V6.0 ç»ˆæå½¢æ€ç­–ç•¥ï¼ˆè¶…çº§æ¨ªç›˜çªç ´ç‰ˆï¼‰")
st.markdown("âœ… **V6.0 ç­–ç•¥ï¼šå½»åº•æ”¾å¼ƒè¶‹åŠ¿è¿½è¸ªï¼Œè½¬å‘â€œæä½æ³¢åŠ¨ç‡ ($\mathbf{0.30}$) + è¶…çº§èµ„é‡‘æµ ($\mathbf{0.40}$) çªç ´â€å½¢æ€é€‰è‚¡ã€‚**")

# ---------------------------
# å…¨å±€å˜é‡åˆå§‹åŒ–
# ---------------------------
pro = None 

# ---------------------------
# è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜ï¼Œçœç•¥éƒ¨åˆ†é‡å¤ä»£ç )
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    """å®‰å…¨è°ƒç”¨ Tushare API"""
    global pro
    if pro is None:
        return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            time.sleep(0.5) 
            return pd.DataFrame(columns=['ts_code']) 
        time.sleep(0.5) 
        return df
    except Exception as e:
        time.sleep(0.5) 
        return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    """è·å– num_days ä¸ªäº¤æ˜“æ—¥ä½œä¸ºé€‰è‚¡æ—¥"""
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 2)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    if cal.empty or 'is_open' not in cal.columns:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œè¯·æ£€æŸ¥ Token æˆ– Tushare æƒé™ã€‚")
        return []
    trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)
    trade_days_df = trade_days_df[trade_days_df['cal_date'] <= end_date_str]
    return trade_days_df['cal_date'].head(num_days).tolist()

@st.cache_data(ttl=3600*24)
def get_adj_factor(ts_code, start_date, end_date):
    df = safe_get('adj_factor', ts_code=ts_code, start_date=start_date, end_date=end_date)
    if df.empty or 'adj_factor' not in df.columns: return pd.DataFrame()
    df['adj_factor'] = pd.to_numeric(df['adj_factor'], errors='coerce').fillna(0)
    df = df.set_index('trade_date').sort_index() 
    return df['adj_factor']

@st.cache_data(ttl=3600*12)
def get_qfq_data_v4(ts_code, start_date, end_date):
    daily_df = safe_get('daily', ts_code=ts_code, start_date=start_date, end_date=end_date)
    if daily_df.empty: return pd.DataFrame()
    daily_df = daily_df.set_index('trade_date').sort_index()
    adj_factor_series = get_adj_factor(ts_code, start_date, end_date)
    if adj_factor_series.empty: return pd.DataFrame()
    df = daily_df.merge(adj_factor_series.rename('adj_factor'), left_index=True, right_index=True, how='left')
    df = df.dropna(subset=['adj_factor'])
    if df.empty: return pd.DataFrame()
    latest_adj_factor = df['adj_factor'].iloc[-1]
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns:
            if latest_adj_factor > 1e-9:
                df[col + '_qfq'] = df[col] * df['adj_factor'] / latest_adj_factor
            else:
                df[col + '_qfq'] = df[col] 
    df = df.reset_index().rename(columns={'trade_date': 'trade_date_str'})
    df['trade_date'] = pd.to_datetime(df['trade_date_str'], format='%Y%m%d')
    df = df.sort_values('trade_date').set_index('trade_date_str')
    for col in ['open', 'high', 'low', 'close']:
        df[col] = df[col + '_qfq']
    return df[['open', 'high', 'low', 'close', 'vol']].copy() 

def get_future_prices(ts_code, selection_date, days_ahead=[1, 3, 5]):
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    start_date = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_date = (d0 + timedelta(days=15)).strftime("%Y%m%d")
    hist = get_qfq_data_v4(ts_code, start_date=start_date, end_date=end_date)
    if hist.empty or 'close' not in hist.columns:
        results = {}
        for n in days_ahead: results[f'Return_D{n}'] = np.nan
        return results
    hist['close'] = pd.to_numeric(hist['close'], errors='coerce')
    hist = hist.dropna(subset=['close'])
    hist = hist.reset_index(drop=True) 
    results = {}
    selection_price_adj = get_qfq_data_v4(ts_code, (d0 - timedelta(days=1)).strftime("%Y%m%d"), selection_date)['close'].iloc[-1] if not get_qfq_data_v4(ts_code, (d0 - timedelta(days=1)).strftime("%Y%m%d"), selection_date).empty else np.nan
    for n in days_ahead:
        col_name = f'Return_D{n}'
        if len(hist) >= n:
            future_price = hist.iloc[n-1]['close']
            if pd.notna(selection_price_adj) and selection_price_adj > 1e-9:
                results[col_name] = (future_price / selection_price_adj - 1) * 100
            else:
                results[col_name] = np.nan
        else:
            results[col_name] = np.nan
    return results


@st.cache_data(ttl=3600*12) 
def compute_indicators(ts_code, end_date):
    """è®¡ç®— MACD, 10æ—¥å›æŠ¥, æ³¢åŠ¨ç‡, 60æ—¥ä½ç½®ç­‰æŒ‡æ ‡"""
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=120)).strftime("%Y%m%d")
    df = get_qfq_data_v4(ts_code, start_date=start_date, end_date=end_date)
    res = {}
    if df.empty or len(df) < 3 or 'close' not in df.columns: return res
    df['close'] = pd.to_numeric(df['close'], errors='coerce').astype(float)
    df['low'] = pd.to_numeric(df['low'], errors='coerce').astype(float)
    df['high'] = pd.to_numeric(df['high'], errors='coerce').astype(float)
    df['vol'] = pd.to_numeric(df['vol'], errors='coerce').fillna(0)
    df['pct_chg'] = df['close'].pct_change().fillna(0) * 100 
    close = df['close']
    res['last_close'] = close.iloc[-1]
    
    # MACD è®¡ç®— (ä¿ç•™ï¼Œä½†æƒé‡å½’é›¶)
    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        res['macd_val'] = ((diff - dea) * 2).iloc[-1]
    else: res['macd_val'] = np.nan
        
    # é‡æ¯”è®¡ç®—
    vols = df['vol'].tolist()
    if len(vols) >= 6 and vols[-6:-1] and np.mean(vols[-6:-1]) > 1e-9:
        res['vol_ratio'] = vols[-1] / np.mean(vols[-6:-1])
    else: res['vol_ratio'] = np.nan
        
    # 10æ—¥å›æŠ¥ã€æ³¢åŠ¨ç‡è®¡ç®—
    res['10d_return'] = close.iloc[-1]/close.iloc[-10] - 1 if len(close)>=10 and close.iloc[-10]!=0 else 0
    res['volatility'] = df['pct_chg'].tail(10).std() if len(df)>=10 else 0
    
    # 60æ—¥ä½ç½®è®¡ç®—
    if len(df) >= 60:
        hist_60 = df.tail(60)
        min_low = hist_60['low'].min()
        max_high = hist_60['high'].max()
        current_close = hist_60['close'].iloc[-1]
        
        if max_high == min_low: res['position_60d'] = 50.0 
        else: res['position_60d'] = (current_close - min_low) / (max_high - min_low) * 100
    else: res['position_60d'] = np.nan 
    
    return res
# ----------------------------------------------------


# ----------------------------------------------------
# ä¾§è¾¹æ å‚æ•° (å®šä¹‰ BACKTEST_DAYS ç­‰å˜é‡)
# ----------------------------------------------------
with st.sidebar:
    st.header("æ¨¡å¼ä¸æ—¥æœŸé€‰æ‹©")
    backtest_date_end = st.date_input("é€‰æ‹©**å›æµ‹ç»“æŸæ—¥æœŸ**", value=datetime.now().date(), max_value=datetime.now().date())
    BACKTEST_DAYS = int(st.number_input("**è‡ªåŠ¨å›æµ‹å¤©æ•° (N)**", value=20, step=1, min_value=1, max_value=50, help="ç¨‹åºå°†è‡ªåŠ¨å›æµ‹æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥ã€‚å»ºè®®è®¾ç½®ä¸º 20 å¤©ä»¥è·å¾—æ›´å¯é çš„ç»Ÿè®¡æ•°æ®ã€‚"))
    
    st.markdown("---")
    st.header("æ ¸å¿ƒå‚æ•°")
    FINAL_POOL = int(st.number_input("æœ€ç»ˆå…¥å›´è¯„åˆ†æ•°é‡ (M)", value=10, step=1, min_value=1)) 
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=10, step=1))
    TOP_BACKTEST = int(st.number_input("å›æµ‹åˆ†æ Top K", value=3, step=1, min_value=1)) 
    
    st.markdown("---")
    st.header("ğŸ›’ çµæ´»è¿‡æ»¤æ¡ä»¶")
    MIN_PRICE = st.number_input("æœ€ä½è‚¡ä»· (å…ƒ)", value=10.0, step=0.5, min_value=0.1)
    MAX_PRICE = st.number_input("æœ€é«˜è‚¡ä»· (å…ƒ)", value=300.0, step=5.0, min_value=1.0)
    MIN_TURNOVER = st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=3.0, step=0.5, min_value=0.1)
    MIN_CIRC_MV_BILLIONS = st.number_input("æœ€ä½æµé€šå¸‚å€¼ (äº¿å…ƒ)", value=20.0, step=1.0, min_value=1.0, help="ä¾‹å¦‚ï¼šè¾“å…¥ 20 ä»£è¡¨æµé€šå¸‚å€¼å¿…é¡»å¤§äºç­‰äº 20 äº¿å…ƒã€‚")
    MIN_AMOUNT_MILLIONS = st.number_input("æœ€ä½æˆäº¤é¢ (äº¿å…ƒ)", value=0.6, step=0.1, min_value=0.1)
    MIN_AMOUNT = MIN_AMOUNT_MILLIONS * 100000000 

# ---------------------------
# Token è¾“å…¥ä¸åˆå§‹åŒ– 
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()
ts.set_token(TS_TOKEN)
pro = ts.pro_api() 

# ---------------------------
# æ ¸å¿ƒå›æµ‹é€»è¾‘å‡½æ•° 
# ---------------------------
def run_backtest_for_a_day(last_trade, TOP_BACKTEST, FINAL_POOL, MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, MIN_CIRC_MV_BILLIONS):
    """ä¸ºå•ä¸ªäº¤æ˜“æ—¥è¿è¡Œé€‰è‚¡å’Œå›æµ‹é€»è¾‘"""
    
    # 1. æ‹‰å–å…¨å¸‚åœº Daily æ•°æ® (çœç•¥åˆå¹¶å’Œè¿‡æ»¤çš„é‡å¤ä»£ç )
    daily_all = safe_get('daily', trade_date=last_trade) 
    if daily_all.empty or 'ts_code' not in daily_all.columns: return pd.DataFrame(), f"æ•°æ®ç¼ºå¤±æˆ–æ‹‰å–å¤±è´¥ï¼š{last_trade}"

    pool_raw = daily_all.reset_index(drop=True) 
    stock_basic = safe_get('stock_basic', list_status='L', fields='ts_code,name,list_date') 
    REQUIRED_BASIC_COLS = ['ts_code','turnover_rate','amount','total_mv','circ_mv'] 
    daily_basic = safe_get('daily_basic', trade_date=last_trade, fields=','.join(REQUIRED_BASIC_COLS))
    mf_raw = safe_get('moneyflow', trade_date=last_trade)
    pool_merged = pool_raw.copy()

    if not stock_basic.empty and 'name' in stock_basic.columns:
        pool_merged = pool_merged.merge(stock_basic[['ts_code','name','list_date']], on='ts_code', how='left')
    else:
        pool_merged['name'] = pool_merged['ts_code']
        pool_merged['list_date'] = '20000101'
        
    if not daily_basic.empty:
        cols_to_merge = [c for c in REQUIRED_BASIC_COLS if c in daily_basic.columns]
        if 'amount' in pool_merged.columns and 'amount' in cols_to_merge: 
            pool_merged = pool_merged.drop(columns=['amount'])
        pool_merged = pool_merged.merge(daily_basic[cols_to_merge], on='ts_code', how='left')
    
    moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])
    if not mf_raw.empty:
        possible = ['net_mf','net_mf_amount','net_mf_in']
        for c in possible:
            if c in mf_raw.columns:
                moneyflow = mf_raw[['ts_code', c]].rename(columns={c:'net_mf'}).fillna(0)
                break            
    if not moneyflow.empty:
        pool_merged = pool_merged.merge(moneyflow, on='ts_code', how='left')
        
    pool_merged['net_mf'] = pool_merged['net_mf'].fillna(0) 
    pool_merged['turnover_rate'] = pool_merged['turnover_rate'].fillna(0) 
    
    # 3. æ‰§è¡Œç¡¬æ€§æ¡ä»¶è¿‡æ»¤
    df = pool_merged.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce') 
    df['turnover_rate'] = pd.to_numeric(df['turnover_rate'], errors='coerce').fillna(0)
    df['amount'] = pd.to_numeric(df['amount'], errors='coerce').fillna(0) * 1000 # è½¬æ¢ä¸ºä¸‡å…ƒ
    df['circ_mv_billion'] = pd.to_numeric(df['circ_mv'], errors='coerce').fillna(0) / 10000 
    df['name'] = df['name'].astype(str)
    
    mask_st = df['name'].str.contains('ST|é€€', case=False, na=False)
    df = df[~mask_st]
    mask_bj = df['ts_code'].str.startswith('92') 
    df = df[~mask_bj]
    TODAY = datetime.strptime(last_trade, "%Y%m%d")
    MIN_LIST_DAYS = 120 
    df['list_date_dt'] = pd.to_datetime(df['list_date'], format='%Y%m%d', errors='coerce')
    df['days_listed'] = (TODAY - df['list_date_dt']).dt.days
    mask_cyb_kcb = df['ts_code'].str.startswith(('30','68'))
    mask_new = df['days_listed'] < MIN_LIST_DAYS
    df = df[~((mask_cyb_kcb) & (mask_new))]

    mask_price = (df['close'] >= MIN_PRICE) & (df['close'] <= MAX_PRICE)
    df = df[mask_price]
    mask_circ_mv = df['circ_mv_billion'] >= MIN_CIRC_MV_BILLIONS
    df = df[mask_circ_mv] 
    mask_turn = df['turnover_rate'] >= MIN_TURNOVER
    df = df[mask_turn]
    mask_amt = df['amount'] * 1000 >= MIN_AMOUNT
    df = df[mask_amt]
    
    df = df.reset_index(drop=True)

    if len(df) == 0: return pd.DataFrame(), f"è¿‡æ»¤åæ— è‚¡ç¥¨ï¼š{last_trade}"

    # 4. é´é€‰å†³èµ›åå• (é€»è¾‘ä¸å˜)
    limit_pct = int(FINAL_POOL * 0.7)
    df_pct = df.sort_values('pct_chg', ascending=False).head(limit_pct).copy()
    limit_turn = FINAL_POOL - len(df_pct)
    existing_codes = set(df_pct['ts_code'])
    df_turn = df[~df['ts_code'].isin(existing_codes)].sort_values('turnover_rate', ascending=False).head(limit_turn).copy()
    final_candidates = pd.concat([df_pct, df_turn]).reset_index(drop=True)

    # 5. æ·±åº¦è¯„åˆ† 
    records = []
    for row in final_candidates.itertuples():
        ts_code = row.ts_code
        
        rec = {
            'ts_code': ts_code, 'name': getattr(row, 'name', ts_code),
            'Close': getattr(row, 'close', np.nan),
            'Circ_MV (äº¿)': getattr(row, 'circ_mv_billion', np.nan),
            'Pct_Chg (%)': getattr(row, 'pct_chg', 0), 
            'turnover': getattr(row, 'turnover_rate', 0),
            'net_mf': getattr(row, 'net_mf', 0)
        }
        
        ind = compute_indicators(ts_code, last_trade)
        rec.update({
            'vol_ratio': ind.get('vol_ratio', 0), 'macd': ind.get('macd_val', 0),
            '10d_return': ind.get('10d_return', 0),
            'volatility': ind.get('volatility', 0), 'position_60d': ind.get('position_60d', np.nan)
        })
        
        future_returns = get_future_prices(ts_code, last_trade) # ç›´æ¥è·å–æ”¶ç›Šç‡
        rec.update({
            'Return_D1 (%)': future_returns.get('Return_D1', np.nan),
            'Return_D3 (%)': future_returns.get('Return_D3', np.nan),
            'Return_D5 (%)': future_returns.get('Return_D5', np.nan),
        })

        records.append(rec)
    
    fdf = pd.DataFrame(records)
    if fdf.empty: return pd.DataFrame(), f"è¯„åˆ†åˆ—è¡¨ä¸ºç©ºï¼š{last_trade}"

    # 6. å½’ä¸€åŒ–ä¸ V6.0 ç­–ç•¥ç²¾è°ƒè¯„åˆ† 
    def normalize(series):
        series_nn = series.dropna() 
        if series_nn.max() == series_nn.min(): return pd.Series([0.5] * len(series), index=series.index)
        return (series - series_nn.min()) / (series_nn.max() - series_nn.min() + 1e-9)

    fdf['s_pct'] = normalize(fdf['Pct_Chg (%)'])
    fdf['s_turn'] = normalize(fdf['turnover'])
    fdf['s_vol'] = normalize(fdf['vol_ratio'])
    fdf['s_mf'] = normalize(fdf['net_mf'])
    fdf['s_macd'] = normalize(fdf['macd'])
    fdf['s_trend'] = normalize(fdf['10d_return'])
    fdf['s_volatility'] = normalize(fdf['volatility'])
    fdf['s_position'] = fdf['position_60d'] / 100 

    # ğŸš¨ V6.0 ç»ˆæå½¢æ€ç­–ç•¥ï¼šè¶…çº§æ¨ªç›˜çªç ´ç‰ˆ
    
    # æ ¸å¿ƒæƒé‡
    w_mf = 0.40             # 40% - èµ„é‡‘æµ (è¶…çº§å¯åŠ¨ç¡®è®¤)
    w_volatility = 0.30     # 30% - æ³¢åŠ¨ç‡ (**æ ¸å¿ƒå½¢æ€ï¼šä½æ³¢åŠ¨å¾—åˆ†é«˜**)
    
    # è¾…åŠ©æƒé‡
    w_turn = 0.10           # 10% - æ¢æ‰‹ç‡ (çªç ´æ´»è·ƒåº¦)
    w_vol = 0.05            # 5% - é‡æ¯” (é‡èƒ½è¾…åŠ©)
    w_position = 0.10       # 10% - 60æ—¥ä½ç½® (åº•éƒ¨åŒºåŸŸé˜²å¾¡ï¼Œå¼±åŒ–)
    w_trend = 0.05          # 5% - 10æ—¥å›æŠ¥ (å¼±åŠ¨èƒ½è¾…åŠ©)

    # å½’é›¶é¡¹
    w_macd = 0.00           # 0% - MACD (å½’é›¶)
    w_pct = 0.00            # 0% - å½“æ—¥æ¶¨å¹… (å½’é›¶)
    
    # Sum: 0.40+0.30 + 0.10+0.05+0.10+0.05 = 1.00
    
    score = (
        fdf['s_pct'] * w_pct + fdf['s_turn'] * w_turn + fdf['s_vol'] * w_vol + 
        fdf['s_mf'] * w_mf + fdf['s_macd'] * w_macd + 
        fdf['s_trend'] * w_trend +     
        (1 - fdf['s_volatility']) * w_volatility +          # **ä½æ³¢åŠ¨ç‡å¾—åˆ†é«˜ (å½¢æ€ç¡®è®¤)**
        (1 - fdf['s_position']) * w_position                # ä½ä½ç½®å¾—åˆ†é«˜ (åº•éƒ¨åŒºåŸŸé˜²å¾¡)
    )
    fdf['ç»¼åˆè¯„åˆ†'] = score * 100
    fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
    fdf.index += 1

    return fdf.head(TOP_BACKTEST).copy(), None

# ---------------------------
# ä¸»è¿è¡Œå— (ä¿æŒä¸å˜)
# ---------------------------
if st.button(f"ğŸš€ å¼€å§‹ {BACKTEST_DAYS} æ—¥è‡ªåŠ¨å›æµ‹"):
    
    st.warning("âš ï¸ **V6.0 ç‰ˆæœ¬å·²æ›´æ¢ä¸ºè¶…çº§æ¨ªç›˜çªç ´ç­–ç•¥ï¼Œæ ¸å¿ƒæ˜¯ä½æ³¢åŠ¨ç‡ (0.30) + èµ„é‡‘æµ (0.40)ã€‚**")
    
    trade_days_str = get_trade_days(backtest_date_end.strftime("%Y%m%d"), BACKTEST_DAYS)
    if not trade_days_str:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥æ—¥æœŸæˆ– Tokenã€‚")
        st.stop()
    
    st.header(f"ğŸ“ˆ æ­£åœ¨è¿›è¡Œ {BACKTEST_DAYS} ä¸ªäº¤æ˜“æ—¥çš„å›æµ‹...")
    
    results_list = []
    total_days = len(trade_days_str)
    
    progress_text = st.empty()
    my_bar = st.progress(0)
    
    for i, trade_date in enumerate(trade_days_str):
        progress_text.text(f"ğŸš€ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{total_days} ä¸ªäº¤æ˜“æ—¥ï¼š{trade_date}")
        
        daily_result_df, error = run_backtest_for_a_day(
            trade_date, TOP_BACKTEST, FINAL_POOL, MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, MIN_CIRC_MV_BILLIONS
        )
        
        if error:
            st.warning(f"è·³è¿‡ {trade_date}ï¼š{error}")
        elif not daily_result_df.empty:
            daily_result_df['Trade_Date'] = trade_date
            results_list.append(daily_result_df)
            
        my_bar.progress((i + 1) / total_days)

    progress_text.text("âœ… å›æµ‹å®Œæˆï¼Œæ­£åœ¨æ±‡æ€»ç»“æœ...")
    my_bar.empty()
    
    if not results_list:
        st.error("æ‰€æœ‰äº¤æ˜“æ—¥çš„å›æµ‹å‡å¤±è´¥æˆ–æ— ç»“æœã€‚")
        st.stop()
        
    all_results = pd.concat(results_list)
    
    st.header(f"ğŸ“Š æœ€ç»ˆå¹³å‡å›æµ‹ç»“æœ (Top {TOP_BACKTEST}ï¼Œå…± {total_days} ä¸ªäº¤æ˜“æ—¥)")
    
    for n in [1, 3, 5]:
        col = f'Return_D{n} (%)' 
        
        filtered_returns = all_results.copy()
        valid_returns = filtered_returns.dropna(subset=[col])

        if not valid_returns.empty:
            avg_return = valid_returns[col].mean()
            hit_rate = (valid_returns[col] > 0).sum() / len(valid_returns) * 100 if len(valid_returns) > 0 else 0.0
            total_count = len(valid_returns)
        else:
            avg_return = np.nan
            hit_rate = 0.0
            total_count = 0
            
        st.metric(f"Top {TOP_BACKTEST}ï¼šD+{n} å¹³å‡æ”¶ç›Š / å‡†ç¡®ç‡", 
                  f"{avg_return:.2f}% / {hit_rate:.1f}%", 
                  help=f"æ€»æœ‰æ•ˆæ ·æœ¬æ•°ï¼š{total_count}ã€‚**V6.0 å·²åº”ç”¨è¶…çº§æ¨ªç›˜çªç ´ç­–ç•¥ã€‚**")

    st.header("ğŸ“‹ æ¯æ—¥å›æµ‹è¯¦æƒ… (Top K æ˜ç»†)")
    
    display_cols = ['Trade_Date', 'name', 'ts_code', 'ç»¼åˆè¯„åˆ†', 
                    'Close', 'Pct_Chg (%)', 'Circ_MV (äº¿)',
                    'Return_D1 (%)', 'Return_D3 (%)', 'Return_D5 (%)']
    
    st.dataframe(all_results[display_cols].sort_values('Trade_Date', ascending=False), use_container_width=True)
