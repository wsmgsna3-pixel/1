# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V30.12.3 Pro (ç¡¬ç›˜æ–­ç‚¹ç»­ä¼ Â·ç»ˆæä¿®æ­£ç‰ˆ)
------------------------------------------------
ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼š
1. **ç¡¬ç›˜æ–­ç‚¹ç»­ä¼ **ï¼šæ•°æ®æ‹‰å–åå­˜å…¥æœ¬åœ° 'data_cache_2025' æ–‡ä»¶å¤¹ã€‚
   - å³ä½¿ç¨‹åºå´©æºƒï¼Œé‡å¯åä¹Ÿä¼šç›´æ¥è¯»å–æœ¬åœ°æ–‡ä»¶ï¼Œç»ä¸ä»å¤´å¼€å§‹ï¼
2. **ä»£ç é€»è¾‘å›å¡«**ï¼šæ¢å¤äº†ä¹‹å‰è¢«ç²¾ç®€æ‰çš„ç¼“å­˜ç®¡ç†é€»è¾‘ï¼Œä»£ç é‡æ¢å¤ï¼ŒåŠŸèƒ½å®Œæ•´ã€‚
3. **æ”¶ç›Šä¿®æ­£**ï¼šä¿æŒ .loc è¯»å–æ–¹å¼ï¼Œæœç»æ”¶ç›Šä¸º 0ã€‚
------------------------------------------------
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import time
import os
import pickle

warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€é…ç½® & ç¼“å­˜åˆå§‹åŒ–
# ---------------------------
# å®šä¹‰ç¼“å­˜ç›®å½•
CACHE_DIR = "data_cache_2025"
if not os.path.exists(CACHE_DIR):
    os.makedirs(CACHE_DIR)

# å…¨å±€æ•°æ®å®¹å™¨
GLOBAL_DATA = {
    'daily': pd.DataFrame(),
    'daily_basic': pd.DataFrame(),
    'moneyflow': pd.DataFrame()
}
pro = None

st.set_page_config(page_title="é€‰è‚¡ç‹ ç¡¬ç›˜ç»­ä¼ ç‰ˆ", layout="wide")

# ---------------------------
# 1. åŸºç¡€å·¥å…·å‡½æ•°
# ---------------------------
@st.cache_resource
def init_tushare(token):
    if not token: return None
    try:
        api = ts.pro_api(token)
        # æµ‹è¯•è¿é€šæ€§
        api.trade_cal(start_date='20250101', end_date='20250101')
        return api
    except Exception as e:
        st.error(f"Token è¿æ¥å¤±è´¥: {e}")
        return None

def get_real_trade_date(date_str):
    """è‡ªåŠ¨ä¿®æ­£éäº¤æ˜“æ—¥"""
    if pro is None: return date_str
    try:
        start = (datetime.strptime(date_str, '%Y%m%d') - timedelta(days=10)).strftime('%Y%m%d')
        end = date_str
        df = pro.trade_cal(exchange='', start_date=start, end_date=end, is_open='1')
        if not df.empty: return df['cal_date'].iloc[-1]
        return date_str
    except:
        return date_str

def get_trade_cal(start_date, end_date):
    """è·å–äº¤æ˜“æ—¥å†"""
    if pro is None: return []
    try:
        df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date)
        df = df[df['is_open'] == 1]
        return sorted(df['cal_date'].tolist())
    except:
        return []

# ---------------------------
# 2. æ ¸å¿ƒï¼šå¸¦ç¡¬ç›˜ç¼“å­˜çš„æ•°æ®æ‹‰å–
# ---------------------------
def fetch_and_cache(api_func, date, data_type, **kwargs):
    """
    æ™ºèƒ½æ‹‰å–å‡½æ•°ï¼š
    1. æ£€æŸ¥æœ¬åœ°ç¡¬ç›˜æœ‰æ²¡æœ‰ç¼“å­˜æ–‡ä»¶
    2. æœ‰ -> è¯»å–å¹¶è¿”å› (0æµé‡, 0è€—æ—¶)
    3. æ—  -> è”ç½‘ä¸‹è½½ -> å­˜å…¥ç¡¬ç›˜ -> è¿”å›
    """
    # ç¼“å­˜æ–‡ä»¶å: data_cache_2025/20250101_daily.pkl
    cache_file = os.path.join(CACHE_DIR, f"{date}_{data_type}.pkl")
    
    # --- A. å°è¯•è¯»å–ç¼“å­˜ ---
    if os.path.exists(cache_file):
        try:
            df = pd.read_pickle(cache_file)
            # ç®€å•æ ¡éªŒï¼Œé˜²æ­¢è¯»å–ç©ºæ–‡ä»¶
            if df is not None: 
                return df, True # True ä»£è¡¨æ¥è‡ªç¼“å­˜
        except Exception:
            # å¦‚æœç¼“å­˜æ–‡ä»¶æŸåï¼Œåˆ æ‰å®ƒï¼Œå‡†å¤‡é‡æ–°ä¸‹è½½
            os.remove(cache_file)
    
    # --- B. è”ç½‘ä¸‹è½½ (å¸¦é‡è¯•) ---
    for retries in range(3): # é‡è¯•3æ¬¡
        try:
            df = api_func(**kwargs)
            if df is not None and not df.empty:
                # ä¸‹è½½æˆåŠŸï¼Œå†™å…¥ç¡¬ç›˜ç¼“å­˜
                df.to_pickle(cache_file)
                return df, False # False ä»£è¡¨æ¥è‡ªç½‘ç»œ
            elif df is not None and df.empty:
                # ç©ºæ•°æ®ä¹Ÿç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚ç©ºå€¼
                df.to_pickle(cache_file)
                return df, False
        except Exception as e:
            time.sleep(1) # å¤±è´¥æ­‡1ç§’
            continue
            
    return None, False

def prefetch_data_stable(trade_days):
    """
    æå…¶ç¨³å®šçš„æ•°æ®é¢„åŠ è½½æµç¨‹
    """
    global pro, GLOBAL_DATA
    if not trade_days: return False
    
    status_text = st.empty()
    progress_bar = st.progress(0)
    
    all_daily = []
    all_basic = []
    all_mf = []
    
    total_days = len(trade_days)
    cache_hits = 0
    network_hits = 0
    
    # é€æ—¥å¾ªç¯
    for i, date in enumerate(trade_days):
        # 1. Daily è¡Œæƒ…
        df_d, is_cache = fetch_and_cache(pro.daily, date, 'daily', trade_date=date)
        if df_d is not None and not df_d.empty:
            all_daily.append(df_d)
        
        # 2. Daily Basic æŒ‡æ ‡
        df_b, _ = fetch_and_cache(pro.daily_basic, date, 'basic', trade_date=date, fields='ts_code,trade_date,turnover_rate,circ_mv,total_mv,pe,pb')
        if df_b is not None and not df_b.empty:
            all_basic.append(df_b)
            
        # 3. Moneyflow èµ„é‡‘æµ
        df_m, _ = fetch_and_cache(pro.moneyflow, date, 'moneyflow', trade_date=date)
        if df_m is not None and not df_m.empty:
            all_mf.append(df_m)
        
        # çŠ¶æ€æ›´æ–°
        if is_cache:
            cache_hits += 1
            msg = f"âš¡ å·²è¯»ç¼“å­˜: {date}"
            # è¯»ç¼“å­˜å¤ªå¿«äº†ï¼Œä¸éœ€è¦ sleep
        else:
            network_hits += 1
            msg = f"ğŸŒ ç½‘ç»œä¸‹è½½: {date}"
            # åªæœ‰èµ°ç½‘ç»œæ—¶æ‰éœ€è¦ä¼‘æ¯ï¼Œé˜²æ­¢é™æµ
            time.sleep(0.05)
            
        progress_bar.progress((i + 1) / total_days, text=f"{msg} ({i+1}/{total_days})")

    status_text.info(f"æ•°æ®å‡†å¤‡å®Œæ¯•ï¼æœ¬åœ°ç¼“å­˜å‘½ä¸­: {cache_hits} å¤© | ç½‘ç»œä¸‹è½½: {network_hits} å¤©")
    
    # åˆå¹¶æ•°æ®
    status_text.text("æ­£åœ¨åˆå¹¶æ•°æ®è¡¨...")
    
    if all_daily:
        full_daily = pd.concat(all_daily)
        # æ¸…æ´—
        full_daily['trade_date'] = full_daily['trade_date'].astype(str).str.strip()
        full_daily['ts_code'] = full_daily['ts_code'].astype(str).str.strip()
        full_daily.drop_duplicates(subset=['trade_date', 'ts_code'], inplace=True)
        full_daily.set_index(['trade_date', 'ts_code'], inplace=True)
        full_daily.sort_index(inplace=True)
        GLOBAL_DATA['daily'] = full_daily
    else:
        st.error("âŒ è¡Œæƒ…æ•°æ®ä¸ºç©º")
        return False
        
    if all_basic:
        full_basic = pd.concat(all_basic)
        full_basic['trade_date'] = full_basic['trade_date'].astype(str).str.strip()
        full_basic['ts_code'] = full_basic['ts_code'].astype(str).str.strip()
        full_basic.drop_duplicates(subset=['trade_date', 'ts_code'], inplace=True)
        full_basic.set_index(['trade_date', 'ts_code'], inplace=True)
        full_basic.sort_index(inplace=True)
        GLOBAL_DATA['daily_basic'] = full_basic
    else:
        st.error("âŒ æŒ‡æ ‡æ•°æ®ä¸ºç©º")
        return False
        
    if all_mf:
        full_mf = pd.concat(all_mf)
        full_mf['trade_date'] = full_mf['trade_date'].astype(str).str.strip()
        full_mf['ts_code'] = full_mf['ts_code'].astype(str).str.strip()
        full_mf.set_index(['trade_date', 'ts_code'], inplace=True)
        full_mf.sort_index(inplace=True)
        GLOBAL_DATA['moneyflow'] = full_mf
        
    status_text.success("âœ… æ•°æ®åŠ è½½æˆåŠŸï¼")
    time.sleep(0.5)
    status_text.empty()
    progress_bar.empty()
    return True

# ---------------------------
# 3. ç­–ç•¥æ‰§è¡Œé€»è¾‘
# ---------------------------
def run_strategy(current_date, params):
    try:
        idx = pd.IndexSlice
        # æ£€æŸ¥
        if current_date not in GLOBAL_DATA['daily'].index.get_level_values(0): return pd.DataFrame()
        if current_date not in GLOBAL_DATA['daily_basic'].index.get_level_values(0): return pd.DataFrame()
            
        # æå– Copy
        daily_today = GLOBAL_DATA['daily'].loc[idx[current_date, :]].copy()
        basic_today = GLOBAL_DATA['daily_basic'].loc[idx[current_date, :]].copy()
        
        # é‡ç½®ç´¢å¼•
        daily_today = daily_today.reset_index()
        if 'ts_code' not in daily_today.columns: daily_today['ts_code'] = daily_today.index
        basic_today = basic_today.reset_index()
        if 'ts_code' not in basic_today.columns: basic_today['ts_code'] = basic_today.index
        
        # 1. åŸºç¡€åˆå¹¶ (Inner Join)
        df = pd.merge(daily_today, basic_today[['ts_code', 'circ_mv', 'turnover_rate']], on='ts_code', how='inner')
        
        # 2. èµ„é‡‘æµåˆå¹¶ (Left Join)
        try:
            if 'moneyflow' in GLOBAL_DATA and not GLOBAL_DATA['moneyflow'].empty:
                if current_date in GLOBAL_DATA['moneyflow'].index.get_level_values(0):
                    mf_today = GLOBAL_DATA['moneyflow'].loc[idx[current_date, :]].copy()
                    mf_today = mf_today.reset_index()
                    if 'ts_code' not in mf_today.columns: mf_today['ts_code'] = mf_today.index
                    mf_today['net_mf'] = mf_today['buy_lg_vol'] + mf_today['buy_elg_vol'] - mf_today['sell_lg_vol'] - mf_today['sell_elg_vol']
                    df = pd.merge(df, mf_today[['ts_code', 'net_mf']], on='ts_code', how='left')
                else:
                    df['net_mf'] = 0
            else:
                df['net_mf'] = 0
        except:
            df['net_mf'] = 0

        # --- ç­›é€‰ä¸è¯„åˆ† ---
        
        # è¿‡æ»¤æ¡ä»¶
        df = df[df['close'] >= params['min_price']]
        df = df[df['pct_chg'] < 9.5] 
        df = df[df['pct_chg'] > -9.5]
        df = df[(df['turnover_rate'] >= params['min_turnover']) & (df['turnover_rate'] <= params['max_turnover'])]
        df['circ_mv_yi'] = df['circ_mv'] / 10000
        df = df[(df['circ_mv_yi'] >= params['min_mv']) & (df['circ_mv_yi'] <= params['max_mv'])]
        
        # å½¢æ€ï¼šä¸Šå½±çº¿
        df['max_oc'] = df[['open', 'close']].max(axis=1)
        df['upper_shadow'] = (df['high'] - df['max_oc']) / df['close']
        df = df[df['upper_shadow'] <= 0.05]
        
        # è¯„åˆ†
        df['score'] = df['turnover_rate']
        df.loc[df['net_mf'] > 0, 'score'] += 20
        df.loc[df['close'] > df['open'], 'score'] += 10
        
        return df.sort_values(by='score', ascending=False).head(params['top_k'])

    except Exception:
        return pd.DataFrame()

# ---------------------------
# 4. ä¸»ç¨‹åºå…¥å£
# ---------------------------
def main():
    st.title("ğŸš€ é€‰è‚¡ç‹ 2025 (ç¡¬ç›˜æ–­ç‚¹ç»­ä¼ ç‰ˆ)")
    st.caption("âœ… å·²å¯ç”¨æœ¬åœ°ç¼“å­˜ï¼šç¨‹åºå´©æºƒé‡å¯åå°†è‡ªåŠ¨è·³è¿‡å·²ä¸‹è½½æ—¥æœŸ")
    
    c1, c2 = st.columns([3, 1])
    with c1:
        token = st.text_input("Tushare Token", value="", type="password")
    with c2:
        st.write("") 
        st.write("") 
        start_btn = st.button("å¼€å§‹å›æµ‹ â–¶", type="primary", use_container_width=True)

    with st.sidebar:
        st.header("âš™ï¸ å‚æ•°è®¾ç½®")
        start_date = st.date_input("å¼€å§‹æ—¥æœŸ", datetime(2025, 1, 1))
        end_date = st.date_input("ç»“æŸæ—¥æœŸ", datetime(2025, 12, 31))
        
        st.subheader("æ ¸å¿ƒé—¨æ§›")
        min_price = st.number_input("æœ€ä½è‚¡ä»· (å…ƒ)", 0.0, 500.0, 10.0)
        min_mv = st.number_input("æœ€å°æµé€šå¸‚å€¼ (äº¿)", 0.0, 1000.0, 20.0)
        max_mv = st.number_input("æœ€å¤§æµé€šå¸‚å€¼ (äº¿)", 0.0, 5000.0, 500.0)
        top_k = st.slider("æ¯æ—¥æŒä»“æ•°", 1, 10, 5)

    if start_btn:
        if not token:
            st.error("è¯·è¾“å…¥ Token")
            return
            
        global pro
        with st.spinner("è¿æ¥ Tushare..."):
            pro = init_tushare(token)
            if not pro: return
        
        # æ—¥æœŸå¤„ç†
        start_str = start_date.strftime('%Y%m%d')
        end_str = end_date.strftime('%Y%m%d')
        today_str = datetime.now().strftime('%Y%m%d')
        if end_str >= today_str: end_str = get_real_trade_date(today_str)
        
        trade_days = get_trade_cal(start_str, end_str)
        if not trade_days:
            st.error("æ— æœ‰æ•ˆäº¤æ˜“æ—¥")
            return
        
        st.info(f"å›æµ‹åŒºé—´: {trade_days[0]} - {trade_days[-1]} | {len(trade_days)} å¤©")
        
        # 1. æ™ºèƒ½é¢„åŠ è½½ (Disk Cache)
        if not prefetch_data_stable(trade_days): return
        
        # 2. æ‰§è¡Œå›æµ‹
        params = {'min_price': min_price, 'min_mv': min_mv, 'max_mv': max_mv, 
                  'min_turnover': 3.0, 'max_turnover': 30.0, 'top_k': top_k}
        
        results = []
        progress = st.progress(0)
        
        for i, date in enumerate(trade_days):
            progress.progress((i+1)/len(trade_days), text=f"å›æµ‹åˆ†æ: {date}")
            selected = run_strategy(date, params)
            
            if not selected.empty:
                # æ”¶ç›Šè®¡ç®— (ä¿ç•™ Loc ä¿®å¤)
                if i + 1 < len(trade_days):
                    next_date = trade_days[i+1]
                    try:
                        idx = pd.IndexSlice
                        if next_date in GLOBAL_DATA['daily'].index.get_level_values(0):
                            next_quotes = GLOBAL_DATA['daily'].loc[idx[next_date, :]]
                            for _, row in selected.iterrows():
                                code = row['ts_code']
                                ret = 0.0
                                if code in next_quotes.index:
                                    try:
                                        nb = next_quotes.loc[code]
                                        if isinstance(nb, pd.DataFrame): nb = nb.iloc[0]
                                        if nb['open'] > 0:
                                            ret = (nb['close'] - nb['open']) / nb['open'] * 100
                                    except: pass
                                results.append({'æ—¥æœŸ': date, 'ä»£ç ': code, 'æ”¶ç›Š(%)': ret})
                    except: pass
        
        progress.empty()
        
        # 3. ç»“æœå±•ç¤º
        if results:
            df_res = pd.DataFrame(results)
            st.divider()
            
            daily_ret = df_res.groupby('æ—¥æœŸ')['æ”¶ç›Š(%)'].mean().reset_index()
            daily_ret['ç­–ç•¥å‡€å€¼'] = (1 + daily_ret['æ”¶ç›Š(%)']/100).cumprod()
            
            total_ret = (daily_ret['ç­–ç•¥å‡€å€¼'].iloc[-1] - 1) * 100
            win_rate = (daily_ret['æ”¶ç›Š(%)'] > 0).mean() * 100
            max_dd = ((daily_ret['ç­–ç•¥å‡€å€¼'].cummax() - daily_ret['ç­–ç•¥å‡€å€¼']) / daily_ret['ç­–ç•¥å‡€å€¼'].cummax()).max() * 100
            
            k1, k2, k3, k4 = st.columns(4)
            k1.metric("ç´¯è®¡æ”¶ç›Š", f"{total_ret:.2f}%")
            k2.metric("æ—¥èƒœç‡", f"{win_rate:.1f}%")
            k3.metric("æœ€å¤§å›æ’¤", f"{max_dd:.2f}%")
            k4.metric("äº¤æ˜“å¤©æ•°", len(daily_ret))
            
            st.area_chart(daily_ret.set_index('æ—¥æœŸ')['ç­–ç•¥å‡€å€¼'])
            st.dataframe(df_res)
        else:
            st.warning("æœªè§¦å‘é€‰è‚¡ä¿¡å·")

if __name__ == '__main__':
    main()
