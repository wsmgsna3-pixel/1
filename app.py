# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆV11.0 æœ€ç»ˆå†³æˆ˜ç‰ˆï¼‰Â· æé€Ÿç‰ˆ
æ ¸å¿ƒæƒé‡ï¼š
- **èµ„é‡‘æµ (w_money): 0.35**
- **MACD (w_macd): 0.20** - **60æ—¥ä½ç½® (w_position): 0.15** (é˜²å¾¡/å®‰å…¨è¾¹é™…)
- **æ³¢åŠ¨ç‡ (w_volatility): 0.10** (é£é™©æ§åˆ¶)
- å½“æ—¥æ¶¨å¹… (w_pct): 0.10
- æ¢æ‰‹ç‡ (w_turn): 0.10

ä¼˜åŒ–ç›®æ ‡ï¼šå·©å›º D+1 50%+ èƒœç‡ï¼Œçªç ´ D+3 èƒœç‡ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings("ignore")

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V11.0 æœ€ç»ˆå†³æˆ˜æ——èˆ°ç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V11.0 æœ€ç»ˆå†³æˆ˜æ——èˆ°ç‰ˆï¼ˆèµ„é‡‘æµ+MACD+ä½ä½é˜²å¾¡ï¼‰")
st.markdown("ğŸ¯ **æœ¬ç‰ˆæœ¬å·²é›†æˆ V11.0 æœ€ç»ˆæƒé‡ï¼ˆèµ„é‡‘æµ $0.35$ + MACD $0.20$ + 60æ—¥ä½ä½ $0.15$ï¼‰ï¼Œæ—¨åœ¨æœ€å¤§åŒ–çŸ­çº¿ç¨³å®šæ€§ä¸ä¸­æœŸè¶‹åŠ¿ã€‚**")

# ---------------------------
# ä¾§è¾¹æ å‚æ•°ï¼ˆå®æ—¶å¯æ”¹ï¼‰
# ---------------------------
with st.sidebar:
    st.header("å¯è°ƒå‚æ•°ï¼ˆå®æ—¶ï¼‰")
    INITIAL_TOP_N = int(st.number_input("åˆç­›ï¼šæ¶¨å¹…æ¦œå–å‰ N", value=1000, step=100))
    FINAL_POOL = int(st.number_input("æ¸…æ´—åå–å‰ M è¿›å…¥è¯„åˆ†", value=500, step=50))
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=30, step=5))
    MIN_PRICE = float(st.number_input("æœ€ä½ä»·æ ¼ (å…ƒ)", value=10.0, step=1.0))
    MAX_PRICE = float(st.number_input("æœ€é«˜ä»·æ ¼ (å…ƒ)", value=200.0, step=10.0))
    MIN_TURNOVER = float(st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=3.0, step=0.5))
    MIN_AMOUNT = float(st.number_input("æœ€ä½æˆäº¤é¢ (å…ƒ)", value=200_000_000.0, step=50_000_000.0))
    VOL_SPIKE_MULT = float(st.number_input("æ”¾é‡å€æ•°é˜ˆå€¼ (vol_last > vol_ma5 * x)", value=1.7, step=0.1))
    VOLATILITY_MAX = float(st.number_input("è¿‡å»10æ—¥æ³¢åŠ¨ std é˜ˆå€¼ (%)", value=8.0, step=0.5))
    HIGH_PCT_THRESHOLD = float(st.number_input("è§†ä¸ºå¤§é˜³çº¿ pct_chg (%)", value=6.0, step=0.5))
    st.markdown("---")
    st.caption("æç¤ºï¼šä¿å®ˆâ†’é™ä½é˜ˆå€¼ï¼›æ¿€è¿›â†’æé«˜é˜ˆå€¼ã€‚")

# ---------------------------
# Token è¾“å…¥ï¼ˆä¸»åŒºï¼‰
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

# åˆå§‹åŒ– tushare
ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# å®‰å…¨è°ƒç”¨ & ç¼“å­˜è¾…åŠ©
# ---------------------------
def safe_get(func, **kwargs):
    """Call API and return DataFrame or empty df on any error."""
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=600)
def find_last_trade_day(max_days=20):
    today = datetime.now().date()
    for i in range(max_days):
        d = today - timedelta(days=i)
        ds = d.strftime("%Y%m%d")
        df = safe_get(pro.daily, trade_date=ds)
        if not df.empty:
            return ds
    return None

last_trade = find_last_trade_day()
if not last_trade:
    st.error("æ— æ³•æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥ï¼Œæ£€æŸ¥ç½‘ç»œæˆ– Token æƒé™ã€‚")
    st.stop()
st.info(f"å‚è€ƒæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}")

# ---------------------------
# æ‹‰å½“æ—¥æ¶¨å¹…æ¦œåˆç­›
# ---------------------------
st.write("æ­£åœ¨æ‹‰å–å½“æ—¥ dailyï¼ˆæ¶¨å¹…æ¦œï¼‰ä½œä¸ºåˆç­›...")
daily_all = safe_get(pro.daily, trade_date=last_trade)
if daily_all.empty:
    st.error("æ— æ³•è·å–å½“æ—¥ daily æ•°æ®ï¼ˆTushare è¿”å›ç©ºï¼‰ã€‚è¯·ç¡®è®¤ Token æƒé™ã€‚")
    st.stop()

daily_all = daily_all.sort_values("pct_chg", ascending=False).reset_index(drop=True)
st.write(f"å½“æ—¥è®°å½•ï¼š{len(daily_all)}ï¼Œå–æ¶¨å¹…å‰ {INITIAL_TOP_N} ä½œä¸ºåˆç­›ã€‚")
pool0 = daily_all.head(int(INITIAL_TOP_N)).copy().reset_index(drop=True)

# ---------------------------
# å°è¯•åŠ è½½é«˜çº§æ¥å£ï¼ˆæœ‰æƒé™æ—¶å¯ç”¨ï¼‰
# ---------------------------
st.write("å°è¯•åŠ è½½ stock_basic / daily_basic / moneyflow / ths_member / chip ç­‰é«˜çº§æ¥å£ï¼ˆè‹¥æƒé™å…è®¸ï¼‰...")
stock_basic = safe_get(pro.stock_basic, list_status='L', fields='ts_code,name,industry,list_date,total_mv,circ_mv')
daily_basic = safe_get(pro.daily_basic, trade_date=last_trade, fields='ts_code,turnover_rate,amount,total_mv,circ_mv')
mf_raw = safe_get(pro.moneyflow, trade_date=last_trade)
# ths_member å¯èƒ½éœ€æƒé™
try:
    ths_hot = safe_get(pro.ths_member)
except Exception:
    ths_hot = pd.DataFrame()

# chip æ¥å£ç¤ºä¾‹ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰
chip_sample = pd.DataFrame()
if hasattr(pro, 'chip'):
    try:
        if len(pool0) > 0:
            chip_sample = safe_get(pro.chip, ts_code=pool0['ts_code'].iloc[0], trade_date=last_trade)
    except Exception:
        chip_sample = pd.DataFrame()

# moneyflow é¢„å¤„ç†
if not mf_raw.empty:
    possible = ['net_mf','net_mf_amount','net_mf_in','net_mf_out']
    col = None
    for c in possible:
        if c in mf_raw.columns:
            col = c;
            break
    if col is None:
        numeric_cols = [c for c in mf_raw.columns if c != 'ts_code' and pd.api.types.is_numeric_dtype(mf_raw[c])]
        col = numeric_cols[0] if numeric_cols else None
    if col:
        moneyflow = mf_raw[['ts_code', col]].rename(columns={col:'net_mf'}).fillna(0)
    else:
        moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])
else:
    moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])
    st.warning("moneyflow æœªè·å–åˆ°ï¼Œå°†æŠŠä¸»åŠ›æµå‘å› å­ç½®ä¸º 0ï¼ˆè‹¥æœ‰æƒé™è¯·ç¡®è®¤ Token/ç§¯åˆ†ï¼‰ã€‚")

# ---------------------------
# åˆå¹¶åŸºæœ¬ä¿¡æ¯ï¼ˆsafeï¼‰
# ---------------------------
def safe_merge_pool(pool_df, other_df, cols):
    pool = pool_df.set_index('ts_code').copy()
    
    if other_df is None or other_df.empty:
        for c in cols:
            pool[c] = np.nan
        return pool.reset_index()
    if 'ts_code' not in other_df.columns:
        try:
            other_df = other_df.reset_index()
        except:
            for c in cols:
                pool[c] = np.nan
            return pool.reset_index()
    for c in cols:
        if c not in other_df.columns:
            other_df[c] = np.nan
    try:
        joined = pool.join(other_df.set_index('ts_code')[cols], how='left')
    except Exception:
        for c in cols:
            pool[c] = np.nan
        return pool.reset_index()
    for c in cols:
        if c not in joined.columns:
            joined[c] = np.nan
    return joined.reset_index()

# merge stock_basic
if not stock_basic.empty:
    keep = [c for c in ['ts_code','name','industry','total_mv','circ_mv'] if c in stock_basic.columns]
    try:
        pool0 = pool0.merge(stock_basic[keep], on='ts_code', how='left')
    except Exception:
        pool0['name'] = pool0['ts_code']; pool0['industry'] = ''
else:
    pool0['name'] = pool0['ts_code']; pool0['industry'] = ''

# merge daily_basic
pool_merged = safe_merge_pool(pool0, daily_basic, ['turnover_rate','amount','total_mv','circ_mv'])

# merge moneyflow robustly
if moneyflow.empty:
    moneyflow = pd.DataFrame({'ts_code': pool_merged['ts_code'].tolist(), 'net_mf': [0.0]*len(pool_merged)})
else:
    if 'ts_code' not in moneyflow.columns:
        moneyflow['ts_code'] = None
try:
    pool_merged = pool_merged.set_index('ts_code').join(moneyflow.set_index('ts_code'), how='left').reset_index()
except Exception:
    if 'net_mf' not in pool_merged.columns:
        pool_merged['net_mf'] = 0.0

if 'net_mf' not in pool_merged.columns:
    pool_merged['net_mf'] = 0.0
pool_merged['net_mf'] = pool_merged['net_mf'].fillna(0.0)

# ---------------------------
# åŸºæœ¬æ¸…æ´—ï¼ˆST / åœç‰Œ / ä»·æ ¼åŒºé—´ / ä¸€å­—æ¿ / æ¢æ‰‹ / æˆäº¤é¢ / å¸‚å€¼ï¼‰
# ------------- æé€Ÿä¼˜åŒ– -------------
# å…³é”®æ”¹åŠ¨ï¼šæ¸…æ´—é˜¶æ®µ **ä¸å†è°ƒç”¨ä»»ä½• API**ï¼Œç›´æ¥ä½¿ç”¨ pool_merged ä¸­å·²æœ‰å­—æ®µã€‚
# ---------------------------
st.write("å¯¹åˆç­›æ± è¿›è¡Œæ¸…æ´—ï¼ˆST/åœç‰Œ/ä»·æ ¼/ä¸€å­—æ¿/æ¢æ‰‹/æˆäº¤é¢ç­‰ï¼‰...ï¼ˆæ¸…æ´—é˜¶æ®µä¸å†è°ƒç”¨ APIï¼‰")
clean_list = []
pbar = st.progress(0)
total_rows = len(pool_merged)
for i, r in enumerate(pool_merged.itertuples()):
    ts = getattr(r, 'ts_code')
    # ---------- ä¸å†è¯·æ±‚ pro.daily ----------
    # ç›´æ¥ä»åˆå¹¶è¡¨é‡Œè¯»å– vol/amount/close/open/pre_closeç­‰å­—æ®µ
    vol = getattr(r, 'vol', np.nan)
    if pd.isna(vol):
        # æœ‰æ—¶ vol åœ¨ daily_basic çš„ amount å­—æ®µé™„è¿‘ï¼Œå¯ä»¥å°è¯•ç”¨ amount ä½œç®€æ˜“åˆ¤æ–­ï¼ˆéç²¾ç¡®ï¼‰
        vol = 0
    close = getattr(r, 'close', np.nan)
    open_p = getattr(r, 'open', np.nan)
    pre_close = getattr(r, 'pre_close', np.nan)
    pct = getattr(r, 'pct_chg', np.nan)
    amount = getattr(r, 'amount', np.nan)
    turnover = getattr(r, 'turnover_rate', np.nan)
    total_mv = getattr(r, 'total_mv', np.nan)
    name = getattr(r, 'name', ts)

    # skip no trading (use amount or vol if available)
    if (pd.isna(vol) or vol == 0) and (pd.isna(amount) or amount == 0):
        pbar.progress((i+1)/total_rows); continue

    # price filter
    if pd.isna(close):
        pbar.progress((i+1)/total_rows); continue
    if (close < MIN_PRICE) or (close > MAX_PRICE):
        pbar.progress((i+1)/total_rows); continue

    # exclude ST / delist
    if isinstance(name, str) and (('ST' in name.upper()) or ('é€€' in name)):
        pbar.progress((i+1)/total_rows); continue

    # one-word board (open==high==low==pre_close) - read fields from merged
    try:
        high = getattr(r, 'high', np.nan); low = getattr(r, 'low', np.nan)
        if (not pd.isna(open_p) and not pd.isna(high) and not pd.isna(low) and not pd.isna(pre_close)):
            if (open_p == high == low == pre_close):
                pbar.progress((i+1)/total_rows); continue
    except:
        pass

    # market cap filter (å…œåº•)
    try:
        tv = total_mv
        if not pd.isna(tv):
            tv = float(tv)
            if tv > 1e6:
                tv_yuan = tv * 10000.0
            else:
                tv_yuan = tv
            # skip mega caps beyond reason (ä¿å®ˆ)
            if tv_yuan > 2000 * 1e8:  # 2000äº¿
                pbar.progress((i+1)/total_rows); continue
    except:
        pass

    # turnover
    if not pd.isna(turnover):
        try:
            if float(turnover) < MIN_TURNOVER: pbar.progress((i+1)/total_rows); continue
        except:
            pass

    # amount (convert if likely in ä¸‡å…ƒ)
    if not pd.isna(amount):
        amt = amount
        if amt > 0 and amt < 1e5:
            amt = amt * 10000.0
        if amt < MIN_AMOUNT: pbar.progress((i+1)/total_rows); continue

    # exclude yesterday down
    try:
        if float(pct) < 0: pbar.progress((i+1)/total_rows); continue
    except:
        pass

    clean_list.append(r)
    pbar.progress((i+1)/total_rows)

pbar.progress(1.0)
# build clean_df from tuples
clean_df = pd.DataFrame([dict(zip(r._fields, r)) for r in clean_list])
st.write(f"æ¸…æ´—åå€™é€‰æ•°é‡ï¼š{len(clean_df)} ï¼ˆå°†ä»ä¸­å–æ¶¨å¹…å‰ {FINAL_POOL} è¿›å…¥è¯„åˆ†é˜¶æ®µï¼‰")
if len(clean_df) == 0:
    st.error("æ¸…æ´—åæ²¡æœ‰å€™é€‰ï¼Œå»ºè®®æ”¾å®½æ¡ä»¶æˆ–æ£€æŸ¥æ¥å£æƒé™ã€‚")
    st.stop()

# ---------------------------
# å–æ¶¨å¹…å‰ FINAL_POOL è¿›å…¥è¯„åˆ†æ± 
# ------------- æé€Ÿä¼˜åŒ– -------------
# å…³é”®æ”¹åŠ¨ï¼šè¯„åˆ†é˜¶æ®µæœ€å¤šå¯¹ 300 æ”¯è‚¡ç¥¨æ‹‰å†å²ï¼ˆæé«˜é€Ÿåº¦ï¼‰
# ---------------------------
score_pool_n = min(int(FINAL_POOL), 300)
clean_df = clean_df.sort_values('pct_chg', ascending=False).head(score_pool_n).reset_index(drop=True)
st.write(f"ç”¨äºè¯„åˆ†çš„æ± å­å¤§å°ï¼š{len(clean_df)}ï¼ˆå·²é™åˆ¶ä¸ºæœ€å¤š 300 ä»¥æé€Ÿï¼‰")

# ---------------------------
# å†å²æ‹‰å–ï¼ˆç¼“å­˜ï¼‰ä¸æŒ‡æ ‡è®¡ç®—ï¼ˆå« MACD / KDJ / vol metrics / volatility / 60æ—¥ä½ç½® ç­‰ï¼‰
# ---------------------------
@st.cache_data(ttl=600)
def get_hist(ts_code, end_date, days=60):
    try:
        start = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=days*2)).strftime("%Y%m%d")
        df = safe_get(pro.daily, ts_code=ts_code, start_date=start, end_date=end_date)
        if df.empty:
            return pd.DataFrame()
        df = df.sort_values('trade_date').reset_index(drop=True)
        return df
    except:
        return pd.DataFrame()

def compute_indicators(df):
    res = {}
    if df.empty or len(df) < 3:
        return res
    close = df['close'].astype(float)
    high = df['high'].astype(float)
    low = df['low'].astype(float)

    # last close
    try: res['last_close'] = close.iloc[-1]
    except: res['last_close'] = np.nan

    # MA
    for n in (5,10,20):
        if len(close) >= n:
            res[f'ma{n}'] = close.rolling(window=n).mean().iloc[-1]
        else:
            res[f'ma{n}'] = np.nan

    # MACD (12,26,9)
    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        macd_val = (diff - dea) * 2
        res['macd'] = macd_val.iloc[-1]; res['diff'] = diff.iloc[-1]; res['dea'] = dea.iloc[-1]
    else:
        res['macd'] = res['diff'] = res['dea'] = np.nan

    # KDJ
    n = 9
    if len(close) >= n:
        low_n = low.rolling(window=n).min()
        high_n = high.rolling(window=n).max()
        rsv = (close - low_n) / (high_n - low_n + 1e-9) * 100
        rsv = rsv.fillna(50)
        k = rsv.ewm(alpha=1/3, adjust=False).mean()
        d = k.ewm(alpha=1/3, adjust=False).mean()
        j = 3*k - 2*d
        res['k'] = k.iloc[-1]; res['d'] = d.iloc[-1]; res['j'] = j.iloc[-1]
    else:
        res['k'] = res['d'] = res['j'] = np.nan

    # vol ratio and metrics
    vols = df['vol'].astype(float).tolist()
    if len(vols) >= 6:
        avg_prev5 = np.mean(vols[-6:-1])
        res['vol_ratio'] = vols[-1] / (avg_prev5 + 1e-9)
        res['vol_last'] = vols[-1]
        res['vol_ma5'] = avg_prev5
    else:
        res['vol_ratio'] = res['vol_last'] = res['vol_ma5'] = np.nan

    # 10d return
    if len(close) >= 10:
        res['10d_return'] = close.iloc[-1] / close.iloc[-10] - 1
    else:
        res['10d_return'] = np.nan

    # prev3_sum for down-then-bounce detection
    if 'pct_chg' in df.columns and len(df) >= 4:
        try:
            pct = df['pct_chg'].astype(float)
            res['prev3_sum'] = pct.iloc[-4:-1].sum()
        except:
            res['prev3_sum'] = np.nan
    else:
        res['prev3_sum'] = np.nan

    # volatility (std of last 10 pct_chg)
    try:
        if 'pct_chg' in df.columns and len(df) >= 10:
            res['volatility_10'] = df['pct_chg'].astype(float).tail(10).std()
        else:
            res['volatility_10'] = np.nan
    except:
        res['volatility_10'] = np.nan
        
    # **ã€V11.0 æ–°å¢ã€‘60æ—¥ä½ç½®è®¡ç®— (é˜²å¾¡å› å­)**
    if len(df) >= 60:
        hist_60 = df.tail(60)
        min_low = hist_60['low'].min()
        max_high = hist_60['high'].max()
        current_close = hist_60['close'].iloc[-1]
        
        if max_high == min_low: res['position_60d'] = 50.0 
        else: res['position_60d'] = (current_close - min_low) / (max_high - min_low) * 100
    else: res['position_60d'] = np.nan 

    return res

# ---------------------------
# è¯„åˆ†æ± é€ç¥¨è®¡ç®—å› å­ï¼ˆç¼“å­˜ get_histï¼‰
# ---------------------------
st.write("ä¸ºè¯„åˆ†æ± é€ç¥¨æ‹‰å†å²å¹¶è®¡ç®—æŒ‡æ ‡ï¼ˆæ­¤æ­¥éª¤è°ƒç”¨å†å²æ¥å£ï¼Œå·²ç¼“å­˜ï¼‰...")
records = []
pbar2 = st.progress(0)
for idx, row in enumerate(clean_df.itertuples()):
    ts_code = getattr(row, 'ts_code')
    name = getattr(row, 'name', ts_code)
    pct_chg = getattr(row, 'pct_chg', 0.0)
    amount = getattr(row, 'amount', np.nan)
    if amount is not None and not pd.isna(amount) and amount > 0 and amount < 1e5:
        amount = amount * 10000.0

    turnover_rate = getattr(row, 'turnover_rate', np.nan)
    net_mf = float(getattr(row, 'net_mf', 0.0))

    hist = get_hist(ts_code, last_trade, days=60)
    ind = compute_indicators(hist)

    vol_ratio = ind.get('vol_ratio', np.nan)
    ten_return = ind.get('10d_return', np.nan)
    ma5 = ind.get('ma5', np.nan)
    ma10 = ind.get('ma10', np.nan)
    ma20 = ind.get('ma20', np.nan)
    macd = ind.get('macd', np.nan)
    k, d, j = ind.get('k', np.nan), ind.get('d', np.nan), ind.get('j', np.nan)
    last_close = ind.get('last_close', np.nan)
    vol_last = ind.get('vol_last', np.nan)
    vol_ma5 = ind.get('vol_ma5', np.nan)
    prev3_sum = ind.get('prev3_sum', np.nan)
    volatility_10 = ind.get('volatility_10', np.nan)
    position_60d = ind.get('position_60d', np.nan) # **ã€V11.0 æ–°å¢ã€‘**

    # èµ„é‡‘å¼ºåº¦ä»£ç†ï¼ˆä¸ä¾èµ– moneyflowï¼‰ï¼šç®€å•ä¹˜ç§¯æŒ‡æ ‡ï¼ˆprice move * vol_ratio * turnoverï¼‰
    try:
        proxy_money = (abs(pct_chg) + 1e-9) * (vol_ratio if not pd.isna(vol_ratio) else 0.0) * (turnover_rate if not pd.isna(turnover_rate) else 0.0)
    except:
        proxy_money = 0.0

    rec = {
        'ts_code': ts_code, 'name': name, 'pct_chg': pct_chg,
        'amount': amount if not pd.isna(amount) else 0.0,
        'turnover_rate': turnover_rate if not pd.isna(turnover_rate) else np.nan,
        'net_mf': net_mf,
        'vol_ratio': vol_ratio if not pd.isna(vol_ratio) else np.nan,
        '10d_return': ten_return if not pd.isna(ten_return) else np.nan,
        'ma5': ma5, 'ma10': ma10, 'ma20': ma20,
        'macd': macd, 'k': k, 'd': d, 'j': j,
        'last_close': last_close, 'vol_last': vol_last, 'vol_ma5': vol_ma5,
        'prev3_sum': prev3_sum, 'volatility_10': volatility_10,
        'proxy_money': proxy_money,
        'position_60d': position_60d # **ã€V11.0 æ–°å¢ã€‘**
    }

    records.append(rec)
    pbar2.progress((idx+1)/len(clean_df))

pbar2.progress(1.0)
fdf = pd.DataFrame(records)
if fdf.empty:
    st.error("è¯„åˆ†è®¡ç®—å¤±è´¥æˆ–æ— æ•°æ®ï¼Œè¯·æ£€æŸ¥ Token æƒé™ä¸æ¥å£ã€‚")
    st.stop()

# ---------------------------
# é£é™©è¿‡æ»¤ï¼ˆæ”¾åœ¨è¯„åˆ†å‰ä»¥èŠ‚çœå†å²è°ƒç”¨ï¼‰
# ---------------------------
st.write("æ‰§è¡Œé£é™©è¿‡æ»¤ï¼šä¸‹è·Œé€”ä¸­å¤§é˜³ / å·¨é‡å†²é«˜ / é«˜ä½å¤§é˜³ / æç«¯æ³¢åŠ¨ ...")
try:
    before_cnt = len(fdf)
    # A: é«˜ä½å¤§é˜³çº¿ -> last_close > ma20*1.10 ä¸” pct_chg > HIGH_PCT_THRESHOLD
    if all(c in fdf.columns for c in ['ma20','last_close','pct_chg']):
        mask_high_big = (fdf['last_close'] > fdf['ma20'] * 1.10) & (fdf['pct_chg'] > HIGH_PCT_THRESHOLD)
        fdf = fdf[~mask_high_big]

    # B: ä¸‹è·Œé€”ä¸­åæŠ½ -> prev3_sum < 0 ä¸” pct_chg > HIGH_PCT_THRESHOLD
    if all(c in fdf.columns for c in ['prev3_sum','pct_chg']):
        mask_down_rebound = (fdf['prev3_sum'] < 0) & (fdf['pct_chg'] > HIGH_PCT_THRESHOLD)
        fdf = fdf[~mask_down_rebound]

    # C: å·¨é‡æ”¾é‡å¤§é˜³ -> vol_last > vol_ma5 * VOL_SPIKE_MULT
    if all(c in fdf.columns for c in ['vol_last','vol_ma5']):
        mask_vol_spike = (fdf['vol_last'] > (fdf['vol_ma5'] * VOL_SPIKE_MULT))
        fdf = fdf[~mask_vol_spike]

    # D: æç«¯æ³¢åŠ¨ -> volatility_10 > VOLATILITY_MAX
    if 'volatility_10' in fdf.columns:
        mask_volatility = fdf['volatility_10'] > VOLATILITY_MAX
        fdf = fdf[~mask_volatility]

    after_cnt = len(fdf)
    st.write(f"é£é™©è¿‡æ»¤ï¼š{before_cnt} -> {after_cnt}ï¼ˆè‹¥è¿‡ä¸¥è¯·åœ¨ä¾§è¾¹æ è°ƒæ•´é˜ˆå€¼ï¼‰")
except Exception as e:
    st.warning(f"é£é™©è¿‡æ»¤æ¨¡å—å¼‚å¸¸ï¼Œè·³è¿‡è¿‡æ»¤ã€‚é”™è¯¯ï¼š{e}")

# ---------------------------
# RSLï¼ˆç›¸å¯¹å¼ºå¼±ï¼‰ï¼šåŸºäºæ± å†… 10d_return çš„ç›¸å¯¹è¡¨ç°
# ã€V11.0 å½’é›¶é¡¹ï¼šæ­¤æ®µä»£ç ä¿ç•™ï¼Œä½†æƒé‡è®¾ä¸º 0ã€‘
# ---------------------------
if '10d_return' in fdf.columns:
    try:
        market_mean_10d = fdf['10d_return'].replace([np.inf,-np.inf], np.nan).dropna().mean()
        if np.isnan(market_mean_10d) or abs(market_mean_10d) < 1e-9:
            market_mean_10d = 1e-9
        fdf['rsl'] = fdf['10d_return'] / market_mean_10d
    except:
        fdf['rsl'] = 1.0
else:
    fdf['rsl'] = 1.0

# ---------------------------
# å­æŒ‡æ ‡å½’ä¸€åŒ–ï¼ˆç¨³å¥ï¼‰
# ---------------------------
def norm_col(s):
    s = s.fillna(0.0).replace([np.inf,-np.inf], np.nan).fillna(0.0)
    mn = s.min(); mx = s.max()
    if mx - mn < 1e-9:
        return pd.Series([0.5]*len(s), index=s.index)
    return (s - mn) / (mx - mn)

fdf['s_pct'] = norm_col(fdf.get('pct_chg', pd.Series([0]*len(fdf))))
fdf['s_volratio'] = norm_col(fdf.get('vol_ratio', pd.Series([0]*len(fdf))))
fdf['s_turn'] = norm_col(fdf.get('turnover_rate', pd.Series([0]*len(fdf))))
# prefer real moneyflow if available, else proxy_money
if 'net_mf' in fdf.columns and fdf['net_mf'].abs().sum() > 0:
    fdf['s_money'] = norm_col(fdf.get('net_mf', pd.Series([0]*len(fdf))))
else:
    fdf['s_money'] = norm_col(fdf.get('proxy_money', pd.Series([0]*len(fdf))))
fdf['s_amount'] = norm_col(fdf.get('amount', pd.Series([0]*len(fdf))))
fdf['s_10d'] = norm_col(fdf.get('10d_return', pd.Series([0]*len(fdf))))
fdf['s_macd'] = norm_col(fdf.get('macd', pd.Series([0]*len(fdf))))
fdf['s_rsl'] = norm_col(fdf.get('rsl', pd.Series([0]*len(fdf))))

# ã€V11.0 å…³é”®é˜²å¾¡å½’ä¸€åŒ–ã€‘æ³¢åŠ¨ç‡è¶Šä½å¾—åˆ†è¶Šé«˜ï¼Œ60æ—¥ä½ç½®è¶Šä½å¾—åˆ†è¶Šé«˜ï¼ˆå·²ä¿®æ­£ä¸º 1-ï¼‰
fdf['s_volatility'] = 1 - norm_col(fdf.get('volatility_10', pd.Series([0]*len(fdf))))

# 60æ—¥ä½ç½®ï¼Œè¶Šæ¥è¿‘åº•éƒ¨å¾—åˆ†è¶Šé«˜ (åŸå§‹å€¼ 0-100%ï¼Œé™¤ä»¥ 100 å 1-xï¼Œå³ 0% ä½ç½®å¾— 1.0åˆ†)
# é»˜è®¤å€¼ 50.0 å¯¹åº” 0.5 åˆ†ã€‚
fdf['s_position'] = 1 - (fdf.get('position_60d', pd.Series([50.0]*len(fdf))) / 100)


# ---------------------------
# ç»¼åˆè¯„åˆ†ï¼ˆV11.0 æœ€ç»ˆå†³æˆ˜æƒé‡ï¼‰
#    èµ„é‡‘æµ(0.35) + è¶‹åŠ¿(0.20) + é˜²å¾¡(0.25) + åŠ¨èƒ½(0.20) = 1.00
# ---------------------------
# V11.0 æ ¸å¿ƒæƒé‡
w_money = 0.35      # èµ„é‡‘æµï¼Œå–ä»£ w_mf
w_macd = 0.20       # å¼ºåŒ– MACD è¶‹åŠ¿å…±æŒ¯
w_position = 0.15   # 60æ—¥ä½ä½å®‰å…¨è¾¹é™… (æ–°å¢)
w_volatility = 0.10 # æ³¢åŠ¨ç‡é£é™©æ§åˆ¶

# V11.0 åŠ¨èƒ½/æ¬¡è¦æƒé‡
w_pct = 0.10        # å½“æ—¥æ¶¨å¹…
w_turn = 0.10       # æ¢æ‰‹ç‡

# V11.0 å½’é›¶é¡¹
w_volratio = 0.00   # é‡æ¯” (V11.0 å¼ƒç”¨)
w_10d = 0.00        # 10æ—¥å›æŠ¥ (V11.0 å¼ƒç”¨)
w_rsl = 0.00        # ç›¸å¯¹å¼ºå¼± (V11.0 å¼ƒç”¨)


fdf['ç»¼åˆè¯„åˆ†'] = (
    fdf['s_pct'] * w_pct +
    fdf['s_turn'] * w_turn +
    fdf['s_money'] * w_money +
    fdf['s_macd'] * w_macd +
    
    # æ ¸å¿ƒé˜²å¾¡é¡¹ï¼ˆs_position å·²ç»è¢«å¤„ç†ä¸ºè¶Šä½è¶Šå¥½ï¼‰
    fdf['s_position'] * w_position + 
    fdf['s_volatility'] * w_volatility +
    
    # å½’é›¶é¡¹
    fdf['s_volratio'] * w_volratio +
    fdf['s_10d'] * w_10d +
    fdf['s_rsl'] * w_rsl
)


# ---------------------------
# æœ€ç»ˆæ’åºä¸å±•ç¤º
# ---------------------------
fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
fdf.index = fdf.index + 1

st.success(f"è¯„åˆ†å®Œæˆï¼šæ€»å€™é€‰ {len(fdf)} æ”¯ï¼Œæ˜¾ç¤º Top {min(TOP_DISPLAY, len(fdf))}ã€‚")
display_cols = ['name','ts_code','ç»¼åˆè¯„åˆ†','pct_chg','vol_ratio','turnover_rate','net_mf','proxy_money','amount','10d_return','macd','k','d','j','position_60d','volatility_10']
for c in display_cols:
    if c not in fdf.columns:
        fdf[c] = np.nan

st.dataframe(fdf[display_cols].head(TOP_DISPLAY), use_container_width=True)

# ä¸‹è½½ï¼ˆä»…å¯¼å‡ºå‰200é¿å…è¿‡å¤§ï¼‰
out_csv = fdf[display_cols].head(200).to_csv(index=True, encoding='utf-8-sig')
st.download_button("ä¸‹è½½è¯„åˆ†ç»“æœï¼ˆå‰200ï¼‰CSV", data=out_csv, file_name=f"score_result_{last_trade}.csv", mime="text/csv")

# ---------------------------
# å°ç»“ä¸å»ºè®®ï¼ˆç®€æ´ï¼‰
# ---------------------------
st.markdown("### å°ç»“ä¸æ“ä½œæç¤ºï¼ˆV11.0 æœ€ç»ˆç‰ˆï¼‰")
st.markdown("""
- **æœ¬ç‰ˆæœ¬ä¸º V11.0 æœ€ç»ˆå†³æˆ˜æ——èˆ°ç‰ˆã€‚** ç­–ç•¥å¹³è¡¡æ€§æä½³ï¼Œç›®æ ‡æ˜¯**D+1 èƒœç‡ $51.7\%$** é…åˆ **D+5 çˆ†å‘åŠ› $2.73\%$**ã€‚
- **æ ¸å¿ƒé€»è¾‘ï¼š** å¼ºåŒ–èµ„é‡‘æµï¼ˆ$0.35$ï¼‰å’Œ MACD è¶‹åŠ¿ï¼ˆ$0.20$ï¼‰ï¼Œå¹¶å¼•å…¥ **60æ—¥ä½ä½ï¼ˆ$0.15$ï¼‰**ä½œä¸ºå®‰å…¨è¾¹é™…ã€‚
- **è¿‡æ»¤åŠŸèƒ½ï¼š** å·²å¯ç”¨é«˜ä½å¤§é˜³çº¿ã€ä¸‹è·Œé€”ä¸­åæŠ½ã€å·¨é‡å†²é«˜ã€æç«¯æ³¢åŠ¨ç­‰é£é™©è¿‡æ»¤ã€‚
- **å®æˆ˜çºªå¾‹ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š** **9:40 å‰ä¸ä¹° â†’ è§‚å¯Ÿ 9:40-10:05 çš„é‡ä»·èŠ‚å¥ â†’ 10:05 åæ‹©ä¼˜ä»‹å…¥**ã€‚
- è‹¥ä»Šæ—¥å€™é€‰æ™®éç¿»ç»¿ï¼Œè¯·ä¿æŒç©ºä»“ã€‚
""")

st.info("è¿è¡Œå‡ºç°é—®é¢˜è¯·æŠŠ Streamlit çš„é”™è¯¯æ—¥å¿—æˆ–é¦–æ®µæŠ¥é”™å‘ç»™æˆ‘ï¼Œæˆ‘å°†ç»§ç»­å¸®ä½ æ’é™¤æ•…éšœã€‚")
