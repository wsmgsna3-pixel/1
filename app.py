# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V13.6ï¼ˆBC èåˆç‰ˆï¼‰
æ ¸å¿ƒï¼šé›†æˆ BC å¢å¼ºç‰ˆçš„ çŸ­çº¿æŒ‡æ ‡ å’Œ 4 é¡¹é«˜çº§é£é™©è¿‡æ»¤ï¼Œå¹¶é‡‡ç”¨å…¶çŸ­çº¿æƒé‡ä½“ç³»ã€‚
åŒæ—¶ä¿ç•™ V13.5 çš„ç¨³å®šå‚æ•°ä¼ é€’å’Œç¼“å­˜æœºåˆ¶ã€‚
"""
import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import joblib 
import os
import math
import time 

warnings.filterwarnings("ignore")

# ---------------------------
# å¤–éƒ¨ç¼“å­˜é…ç½® (joblib ä»…ç”¨äºå†å²æ•°æ®)
# ---------------------------
CACHE_DIR = "data_cache"
os.makedirs(CACHE_DIR, exist_ok=True)
memory = joblib.Memory(CACHE_DIR, verbose=0) 

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ï¼ˆV13.6 BC èåˆç‰ˆï¼‰", layout="wide")
st.markdown("### é€‰è‚¡ç‹ï¼ˆV13.6 BC èåˆç‰ˆï¼‰- é›†æˆé«˜çº§é£æ§ä¸çŸ­çº¿æŒ‡æ ‡") 

# ---------------------------
# é»˜è®¤å‚æ•°å®šä¹‰
# ---------------------------
DEFAULT_FINAL_POOL = 500
DEFAULT_TOP_DISPLAY = 30
DEFAULT_MIN_PRICE = 10.0
DEFAULT_MAX_PRICE = 200.0
DEFAULT_MIN_CIRC_MV_B = 40.0 # é»˜è®¤ 40 äº¿
DEFAULT_MAX_CIRC_MV_B = 500.0 # é»˜è®¤ 500 äº¿
DEFAULT_MIN_TURNOVER = 3.0 # BC å¢å¼ºç‰ˆä½¿ç”¨ 3.0%
DEFAULT_MIN_AMOUNT = 200_000_000.0 # BC å¢å¼ºç‰ˆä½¿ç”¨ 2 äº¿
DEFAULT_MA_PERIOD = 20
DEFAULT_MIN_LIST_DAYS = 180
DEFAULT_BACKTEST_DAYS = 10

# BC å¢å¼ºç‰ˆæ–°å¢çš„å‚æ•°
DEFAULT_VOL_SPIKE_MULT = 1.7
DEFAULT_HIGH_PCT_THRESHOLD = 6.0
DEFAULT_MAX_VOLATILITY_10D = 8.0 

# ---------------------------
# ä¾§è¾¹æ å‚æ•° 
# ---------------------------
with st.sidebar:
    st.header("å¯è°ƒå‚æ•°ï¼ˆV13.6 é»˜è®¤å€¼ï¼‰")
    INITIAL_TOP_N = 99999 
    
    FINAL_POOL = int(st.number_input("æ¸…æ´—åå–å‰ M è¿›å…¥è¯„åˆ†", value=DEFAULT_FINAL_POOL, step=50))
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=DEFAULT_TOP_DISPLAY, step=5))
    
    st.markdown("---")
    st.subheader("åŸºç¡€è¿‡æ»¤ (ç¡¬æ€§è¦æ±‚)")
    MIN_PRICE = float(st.number_input("æœ€ä½ä»·æ ¼ (å…ƒ)", value=DEFAULT_MIN_PRICE, step=1.0))
    MAX_PRICE = float(st.number_input("æœ€é«˜ä»·æ ¼ (å…ƒ)", value=DEFAULT_MAX_PRICE, step=10.0))
    
    # é‡ç‚¹å…³æ³¨ï¼šæµé€šå¸‚å€¼èŒƒå›´ (å¯è°ƒæ•´ä¸º 100/200)
    MIN_CIRC_MV_Billion = float(st.number_input("æœ€ä½æµé€šå¸‚å€¼ (äº¿)", value=DEFAULT_MIN_CIRC_MV_B, step=5.0)) 
    MAX_CIRC_MV_Billion = float(st.number_input("æœ€é«˜æµé€šå¸‚å€¼ (äº¿)", value=DEFAULT_MAX_CIRC_MV_B, step=50.0)) 
    
    MIN_TURNOVER = float(st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=DEFAULT_MIN_TURNOVER, step=0.1)) 
    MIN_AMOUNT = float(st.number_input("æœ€ä½æˆäº¤é¢ (å…ƒ)", value=DEFAULT_MIN_AMOUNT, step=50_000_000.0))
    
    MA_TREND_PERIOD = int(st.number_input("è¶‹åŠ¿è¿‡æ»¤ï¼šMA å‘¨æœŸ", value=DEFAULT_MA_PERIOD, step=5))
    MIN_LIST_DAYS = int(st.number_input("æ¬¡æ–°è‚¡æ’é™¤ï¼šæœ€ä½ä¸Šå¸‚å¤©æ•° (å¤©)", value=DEFAULT_MIN_LIST_DAYS, step=30))
    
    st.markdown("---")
    st.subheader("çŸ­çº¿é£æ§å‚æ•° (BC å¢å¼º)")
    
    # æ–°å¢ BC å¢å¼ºå‚æ•°
    VOL_SPIKE_MULT = float(st.number_input("å·¨é‡å†²é«˜ï¼šæ”¾é‡å€æ•°é˜ˆå€¼", value=DEFAULT_VOL_SPIKE_MULT, step=0.1))
    HIGH_PCT_THRESHOLD = float(st.number_input("å¤§é˜³çº¿/åå¼¹å®šä¹‰ (%å˜åŒ–)", value=DEFAULT_HIGH_PCT_THRESHOLD, step=0.5))
    MAX_VOLATILITY_10D = float(st.number_input("æç«¯æ³¢åŠ¨ï¼š10æ—¥æ³¢åŠ¨ std é˜ˆå€¼ (%)", value=DEFAULT_MAX_VOLATILITY_10D, step=0.5))
    
    st.markdown("---")
    
    BACKTEST_DAYS = int(st.number_input("å›æµ‹ï¼šæœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥", value=DEFAULT_BACKTEST_DAYS, step=1))
    
    st.markdown("---")
    st.caption("æç¤ºï¼šç­–ç•¥å·²å‡çº§è‡³ 'V13.6 BC èåˆç‰ˆ'ã€‚")


# ---------------------------
# Token è¾“å…¥
# ---------------------------
st.markdown("è¯·è¾“å…¥ Tushare Tokenã€‚")
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password", label_visibility="collapsed")

if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

# åˆå§‹åŒ– tushare
ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# ä¾èµ–å‡½æ•°ï¼šæ•°æ®å®‰å…¨è·å–
# ---------------------------
def safe_get(func, **kwargs):
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

# ---------------------------
# äº¤æ˜“æ—¥å†è·å– (V13.4 é€»è¾‘)
# ---------------------------
@st.cache_data(ttl=600)
def get_trade_cal_dates():
    end_date = datetime.now().strftime("%Y%m%d")
    cal_df = safe_get(
        pro.trade_cal, 
        exchange='SSE', 
        is_open='1', 
        end_date=end_date, 
        fields='cal_date'
    )
    if cal_df.empty: return []
    return cal_df['cal_date'].sort_values(ascending=False).tolist()


def find_last_trade_day_optimized():
    trade_dates = get_trade_cal_dates()
    
    if not trade_dates: return None
    
    latest_date_str = trade_dates[0]
    latest_date = datetime.strptime(latest_date_str, "%Y%m%d")
    
    # å½“å‰æ—¶é—´ï¼ˆä»¥åŒ—äº¬æ—¶é—´ç®€å•æ¨ç®—ï¼‰
    now = datetime.utcnow() + timedelta(hours=8)
    
    # åœºæ™¯ 1: Tushare è¿”å›æœªæ¥æ—¥æœŸ
    if latest_date > now.replace(hour=0, minute=0, second=0, microsecond=0):
        if len(trade_dates) > 1:
            return trade_dates[1]
        else:
            return None
            
    # åœºæ™¯ 2: Tushare è¿”å›å½“æ—¥æ—¥æœŸ
    elif latest_date.strftime("%Y%m%d") == now.strftime("%Y%m%d"):
        if now.hour >= 16: 
            return latest_date_str
        else:
            if len(trade_dates) > 1:
                return trade_dates[1]
            else:
                return None
    
    # åœºæ™¯ 3: Tushare è¿”å›å‰ä¸€ä¸ªäº¤æ˜“æ—¥
    else:
        return latest_date_str

last_trade = find_last_trade_day_optimized()

if not last_trade:
    st.error("æ— æ³•æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥ï¼Œæ£€æŸ¥ç½‘ç»œæˆ– Token æƒé™ã€‚")
    st.stop()
st.info(f"å‚è€ƒæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}")


# ----------------------------------------------------
# æŒ‰é’®æ§åˆ¶æ¨¡å— 
# ----------------------------------------------------
if 'run_selection' not in st.session_state: st.session_state['run_selection'] = False
if 'run_backtest' not in st.session_state: st.session_state['run_backtest'] = False
if 'backtest_status' not in st.session_state: 
    st.session_state['backtest_status'] = {'progress': 0.0, 'results': [], 'current_index': 0, 'total_days': 0}

col1, col2 = st.columns(2)

with col1:
    if st.button("ğŸš€ è¿è¡Œå½“æ—¥é€‰è‚¡", use_container_width=True):
        st.session_state['run_selection'] = True
        st.session_state['run_backtest'] = False
        st.session_state['backtest_status'] = {'progress': 0.0, 'results': [], 'current_index': 0, 'total_days': 0}
        st.rerun()

with col2:
    if st.button(f"âœ… è¿è¡Œå†å²å›æµ‹ ({BACKTEST_DAYS} æ—¥)", use_container_width=True):
        st.session_state['run_backtest'] = True
        st.session_state['run_selection'] = False
        if st.session_state['backtest_status']['progress'] == 1.0 or st.session_state['backtest_status']['total_days'] == 0:
             st.session_state['backtest_status'] = {'progress': 0.0, 'results': [], 'current_index': 0, 'total_days': 0}
        st.rerun()

st.markdown("---")

# ---------------------------
# è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜)
# ---------------------------
def safe_merge_pool(pool_df, other_df, cols):
    pool = pool_df.set_index('ts_code').copy()
    if other_df is None or other_df.empty:
        for c in cols: pool[c] = np.nan
        return pool.reset_index()
    if 'ts_code' not in other_df.columns:
        try: other_df = other_df.reset_index()
        except:
            for c in cols: pool[c] = np.nan
            return pool.reset_index()
    
    for c in cols:
        if c not in other_df.columns: other_df[c] = np.nan
    
    try: 
        joined = pool.join(other_df.set_index('ts_code')[cols], how='left')
    except Exception:
        for c in cols: pool[c] = np.nan
        return pool.reset_index()
    
    for c in cols:
        if c not in joined.columns: joined[c] = np.nan
        
    return joined.reset_index()

def norm_col(s):
    s = s.fillna(0.0).replace([np.inf,-np.inf], np.nan).fillna(0.0)
    mn = s.min(); mx = s.max()
    if mx - mn < 1e-9: return pd.Series([0.5]*len(s), index=s.index)
    return (s - mn) / (mx - mn)


# ---------------------------
# V13.6 å¢å¼ºï¼šæŒ‡æ ‡è®¡ç®—å’Œå½’ä¸€åŒ–
# ---------------------------
def compute_indicators(df, ma_period):
    res = {}
    if df.empty or len(df) < 3: return res
    close = df['close'].astype(float)
    high = df['high'].astype(float)
    low = df['low'].astype(float)
    vols = df['vol'].astype(float).tolist()

    # last close
    res['last_close'] = close.iloc[-1]
    
    # MA è¶‹åŠ¿
    if len(close) >= ma_period:
        res[f'ma{ma_period}'] = close.rolling(window=ma_period).mean().iloc[-1]
    else:
        res[f'ma{ma_period}'] = np.nan
        
    # MACD (12,26,9)
    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        res['macd'] = (diff - dea).iloc[-1] * 2
    else: res['macd'] = np.nan

    # KDJ (9,3,3) - V13.6 æ–°å¢
    n_kdj = 9
    if len(close) >= n_kdj:
        low_n = low.rolling(window=n_kdj).min()
        high_n = high.rolling(window=n_kdj).max()
        rsv = (close - low_n) / (high_n - low_n + 1e-9) * 100
        rsv = rsv.fillna(50)
        k = rsv.ewm(alpha=1/3, adjust=False).mean()
        d = k.ewm(alpha=1/3, adjust=False).mean()
        j = 3*k - 2*d
        res['k'] = k.iloc[-1]; res['d'] = d.iloc[-1]; res['j'] = j.iloc[-1]
    else:
        res['k'] = res['d'] = res['j'] = np.nan

    # Vol Ratio (é‡æ¯”) - V13.6 æ–°å¢
    if len(vols) >= 6:
        avg_prev5 = np.mean(vols[-6:-1])
        res['vol_ratio'] = vols[-1] / (avg_prev5 + 1e-9)
        res['vol_last'] = vols[-1]
        res['vol_ma5'] = avg_prev5
    else:
        res['vol_ratio'] = res['vol_last'] = res['vol_ma5'] = np.nan

    # 10d return - V13.6 æ–°å¢
    if len(close) >= 10:
        res['10d_return'] = close.iloc[-1] / close.iloc[-10] - 1
    else:
        res['10d_return'] = np.nan
    
    # Prev3 sum for down-then-bounce detection - V13.6 æ–°å¢
    if 'pct_chg' in df.columns and len(df) >= 4:
        try:
            pct = df['pct_chg'].astype(float)
            res['prev3_sum'] = pct.iloc[-4:-1].sum()
        except:
            res['prev3_sum'] = np.nan
    else:
        res['prev3_sum'] = np.nan

    # 10d volatility (std of last 10 pct_chg) - V13.6 æ ¸å¿ƒé£æ§æŒ‡æ ‡
    try:
        if 'pct_chg' in df.columns and len(df) >= 10:
            res['volatility_10'] = df['pct_chg'].astype(float).tail(10).std()
        else:
            res['volatility_10'] = np.nan
    except: res['volatility_10'] = np.nan
    
    return res

# ----------------------------------------------------
# æ ¸å¿ƒè¯„åˆ†å‡½æ•° (V13.6: å¢å¼ºæŒ‡æ ‡ã€è¿‡æ»¤å’Œæƒé‡)
# ----------------------------------------------------
@st.cache_data(show_spinner=False, ttl=600)
def run_scoring_for_date(trade_date, params):
    
    # V13.6 å‚æ•°å®‰å…¨è§£åŒ…
    min_price = params.get('MIN_PRICE', DEFAULT_MIN_PRICE)
    max_price = params.get('MAX_PRICE', DEFAULT_MAX_PRICE)
    min_turnover = params.get('MIN_TURNOVER', DEFAULT_MIN_TURNOVER)
    min_amount = params.get('MIN_AMOUNT', DEFAULT_MIN_AMOUNT)
    min_circ_mv_billion = params.get('MIN_CIRC_MV_Billion', DEFAULT_MIN_CIRC_MV_B)
    max_circ_mv_billion = params.get('MAX_CIRC_MV_Billion', DEFAULT_MAX_CIRC_MV_B)
    ma_trend_period = params.get('MA_TREND_PERIOD', DEFAULT_MA_PERIOD)
    min_list_days = params.get('MIN_LIST_DAYS', DEFAULT_MIN_LIST_DAYS)
    final_pool_size = params.get('FINAL_POOL', DEFAULT_FINAL_POOL) 

    # V13.6 æ–°å¢é£æ§å‚æ•°
    vol_spike_mult = params.get('VOL_SPIKE_MULT', DEFAULT_VOL_SPIKE_MULT)
    high_pct_threshold = params.get('HIGH_PCT_THRESHOLD', DEFAULT_HIGH_PCT_THRESHOLD)
    max_volatility_10d = params.get('MAX_VOLATILITY_10D', DEFAULT_MAX_VOLATILITY_10D)
    
    # 1. æ‹‰å–æ•°æ® (Daily æä¾› open/high/low/pre_close)
    daily_all = safe_get(pro.daily, trade_date=trade_date)
    daily_basic = safe_get(pro.daily_basic, trade_date=trade_date, fields='ts_code,turnover_rate,amount,total_mv,circ_mv')
    moneyflow = safe_get(pro.moneyflow, trade_date=trade_date, fields='ts_code,net_mf_amount') # å°è¯•æ‹‰å–ä¸»åŠ›å‡€æµå…¥

    if daily_all.empty: 
        if trade_date == last_trade: 
            st.error(f"è¯Šæ–­ï¼šTushare æ— æ³•è·å– {trade_date} çš„æ—¥çº¿æ•°æ®ã€‚")
        return pd.DataFrame()
    
    pool0 = daily_all.copy().reset_index(drop=True)

    # 2. åˆå¹¶åŸºæœ¬ä¿¡æ¯ 
    stock_basic = safe_get(pro.stock_basic, list_status='L', fields='ts_code,name,industry,list_date,total_mv,circ_mv')
    
    if not stock_basic.empty:
        keep = [c for c in ['ts_code','name','industry','total_mv','circ_mv','list_date'] if c in stock_basic.columns]
        try: pool0 = pool0.merge(stock_basic[keep], on='ts_code', how='left')
        except Exception: 
            pool0['name'] = pool0['ts_code']; pool0['industry'] = ''; pool0['list_date'] = '20000101'
    else: 
        pool0['name'] = pool0['ts_code']; pool0['industry'] = ''; pool0['list_date'] = '20000101'
    
    pool_merged = safe_merge_pool(pool0, daily_basic.rename(columns={'amount':'amount_db'}), ['turnover_rate','amount_db','total_mv','circ_mv'])

    # èµ„é‡‘æµå‘åˆå¹¶
    if not moneyflow.empty:
        pool_merged = safe_merge_pool(pool_merged, moneyflow, ['net_mf_amount'])
    else:
        pool_merged['net_mf_amount'] = 0.0

    
    # æ•°æ®æ¸…æ´—å’Œè½¬æ¢ 
    if 'amount' in pool_merged.columns:
        pool_merged['amount'] = pool_merged['amount'].apply(lambda amt: amt * 10000.0 if not pd.isna(amt) and amt > 0 and amt < 1e5 else amt)
    else:
        pool_merged['amount'] = pool_merged['amount_db'].apply(lambda amt: amt * 10000.0 if not pd.isna(amt) and amt > 0 and amt < 1e5 else amt)
    
    pool_merged['amount_yuan'] = pool_merged['amount']
    pool_merged['circ_mv_wan'] = pool_merged['circ_mv'].fillna(0)


    # 3. V13.6 ç¡¬æ€§è¿‡æ»¤ï¼ˆæ¸…æ´—ï¼‰
    clean_df = pool_merged.copy()
    
    # åŸºç¡€é£é™©è¿‡æ»¤ (ST, ä»·æ ¼, åŒ—äº¤æ‰€)
    clean_df = clean_df[~(
        (clean_df['close'].isna()) | 
        (clean_df['close'] < min_price) | 
        (clean_df['close'] > max_price) | 
        (clean_df['name'].str.contains('ST|é€€', case=False, na=False)) |
        (clean_df['ts_code'].str.endswith('.BJ', na=False)) 
    )]
    
    # V13.6 å¢å¼ºè¿‡æ»¤ 1: ä»Šæ—¥å¿…é¡»ä¸Šæ¶¨ï¼ˆpct_chg > 0ï¼‰
    clean_df = clean_df[~((clean_df['pct_chg'].isna()) | (clean_df['pct_chg'] < 0))]
    
    # V13.6 å¢å¼ºè¿‡æ»¤ 2: æ’é™¤ä¸€å­—æ¿ (open == high == low == pre_close)
    mask_yiziban = (clean_df['open'] == clean_df['high']) & \
                   (clean_df['high'] == clean_df['low']) & \
                   (clean_df['low'] == clean_df['pre_close']) & \
                   (clean_df['high'] > clean_df['pre_close']) # å¿…é¡»æ˜¯ä¸Šæ¶¨çš„ä¸€å­—æ¿
    clean_df = clean_df[~mask_yiziban.fillna(False)]
    
    # æ¬¡æ–°è‚¡è¿‡æ»¤ 
    current_date = datetime.strptime(trade_date, "%Y%m%d")
    clean_df['list_date'] = pd.to_datetime(clean_df['list_date'], format='%Y%m%d', errors='coerce')
    clean_df['days_since_list'] = (current_date - clean_df['list_date']).dt.days
    clean_df = clean_df[clean_df['days_since_list'].notna() & (clean_df['days_since_list'] >= min_list_days)]
    
    # æµé€šå¸‚å€¼ä¸Šä¸‹é™è¿‡æ»¤
    min_circ_mv_wan = min_circ_mv_billion * 10000.0 
    max_circ_mv_wan = max_circ_mv_billion * 10000.0 
    clean_df = clean_df[clean_df['circ_mv_wan'].notna() & 
                        (clean_df['circ_mv_wan'] >= min_circ_mv_wan) &
                        (clean_df['circ_mv_wan'] <= max_circ_mv_wan)]

    # æµåŠ¨æ€§è¿‡æ»¤
    clean_df = clean_df[clean_df['amount_yuan'].notna() & (clean_df['amount_yuan'] >= min_amount)]
    clean_df = clean_df[clean_df['turnover_rate'].notna() & (clean_df['turnover_rate'] >= min_turnover)]
    
    
    if clean_df.empty: 
        if trade_date == last_trade: st.error(f"è¯Šæ–­ï¼šæ‰€æœ‰ç¡¬æ€§è¿‡æ»¤åï¼Œå‰©ä½™è‚¡ç¥¨æ•°é‡ä¸º **0** æ”¯ã€‚è¯·æ£€æŸ¥ä¾§è¾¹æ å‚æ•°ã€‚")
        return pd.DataFrame()

    if trade_date == last_trade:
        st.info(f"è¯Šæ–­ï¼šç¡¬æ€§è¿‡æ»¤ (å·²åŒ…å«æ¬¡æ–°è‚¡ã€å¸‚å€¼æ”¶ç´§) åï¼Œå‰©ä½™è‚¡ç¥¨æ•°é‡: **{len(clean_df)}** æ”¯ï¼Œå¼€å§‹è®¡ç®—æŒ‡æ ‡...")
        
    # 4. æŒ‡æ ‡è®¡ç®—ä¸ MA è¶‹åŠ¿ç¡¬æ€§è¿‡æ»¤ (BC å¢å¼ºç‰ˆï¼šé™åˆ¶æœ€å¤š 300 æ”¯è‚¡ç¥¨æ‹‰å†å²ä»¥æé€Ÿ)
    score_pool = clean_df.sort_values('pct_chg', ascending=False).head(min(len(clean_df), 300)).copy().reset_index(drop=True)

    records = []
    # ç¼“å­˜éœ€è¦æ‹‰å–çš„å†å²å¤©æ•°ï¼š60 å¤©å³å¯è¦†ç›– MACD å’Œ 20 MA
    start_dt = datetime.strptime(trade_date, "%Y%m%d") - timedelta(days=60 * 1.5) 
    start_date_hist = start_dt.strftime("%Y%m%d")
    
    pbar = None
    if trade_date == last_trade:
        pbar = st.progress(0.0, text=f"æ­£åœ¨è®¡ç®— {len(score_pool)} æ”¯è‚¡ç¥¨çš„æŒ‡æ ‡...")

    for i, row in enumerate(score_pool.itertuples()):
        ts_code = getattr(row, 'ts_code');
        close_price = getattr(row, 'close', np.nan)
        
        # ä¼˜åŒ–ï¼šä»…ç¼“å­˜å†å²æ—¥çº¿æ•°æ®
        @memory.cache 
        def get_daily_hist(ts_code, start_date, end_date):
            return safe_get(pro.daily, ts_code=ts_code, start_date=start_date, end_date=end_date)
            
        hist = get_daily_hist(ts_code, start_date_hist, trade_date)
        
        # è®¡ç®— V13.6 å¢å¼ºæŒ‡æ ‡
        ind = compute_indicators(hist, ma_trend_period)
        ma_trend_val = ind.get(f'ma{ma_trend_period}', np.nan)
        
        # --- MA è¶‹åŠ¿ç¡¬æ€§è¿‡æ»¤ --- (ä¿ç•™)
        if not pd.isna(close_price) and not pd.isna(ma_trend_val) and (close_price < ma_trend_val):
             if pbar: pbar.progress((i + 1) / len(score_pool), text=f"æŒ‡æ ‡è®¡ç®—è¿›åº¦ï¼š[{i+1}/{len(score_pool)}]... (å·²æ’é™¤è¶‹åŠ¿å‘ä¸‹è‚¡)")
             continue 

        rec = {
            'ts_code': ts_code, 
            'pct_chg': getattr(row, 'pct_chg', np.nan),
            'turnover_rate': getattr(row, 'turnover_rate', np.nan),
            'circ_mv_wan': getattr(row, 'circ_mv_wan', np.nan),
            'amount_yuan': getattr(row, 'amount_yuan', np.nan),
            'net_mf_amount': getattr(row, 'net_mf_amount', np.nan),
            'name': getattr(row, 'name', ts_code),
            f'ma{ma_trend_period}': ma_trend_val,
            # V13.6 æ–°å¢æŒ‡æ ‡
            'last_close': ind.get('last_close', np.nan),
            'macd': ind.get('macd', np.nan), 
            'k': ind.get('k', np.nan), 'd': ind.get('d', np.nan), 'j': ind.get('j', np.nan),
            'vol_ratio': ind.get('vol_ratio', np.nan),
            'vol_last': ind.get('vol_last', np.nan),
            'vol_ma5': ind.get('vol_ma5', np.nan),
            '10d_return': ind.get('10d_return', np.nan),
            'prev3_sum': ind.get('prev3_sum', np.nan),
            'volatility_10': ind.get('volatility_10', np.nan),
        }
        records.append(rec)
        
        if pbar: pbar.progress((i + 1) / len(score_pool), text=f"æŒ‡æ ‡è®¡ç®—è¿›åº¦ï¼š[{i+1}/{len(score_pool)}]... (å·²æ’é™¤è¶‹åŠ¿å‘ä¸‹è‚¡)")
        
    fdf = pd.DataFrame(records)
    if fdf.empty: return pd.DataFrame()
    if pbar: pbar.empty()

    if trade_date == last_trade:
        st.info(f"è¯Šæ–­ï¼šé€šè¿‡ {ma_trend_period} æ—¥å‡çº¿è¶‹åŠ¿è¿‡æ»¤åï¼Œå‰©ä½™è‚¡ç¥¨æ•°é‡: **{len(fdf)}** æ”¯ï¼Œå¼€å§‹é«˜çº§é£é™©è¿‡æ»¤...")
        
    
    # 5. V13.6 é«˜çº§é£é™©è¿‡æ»¤ (BC å¢å¼ºç‰ˆ)
    try:
        before_cnt = len(fdf)
        
        # A: é«˜ä½å¤§é˜³çº¿è¿‡æ»¤ -> last_close > ma20*1.10 ä¸” pct_chg > HIGH_PCT_THRESHOLD
        if all(c in fdf.columns for c in [f'ma{ma_trend_period}','last_close','pct_chg']):
            mask_high_big = (fdf['last_close'] > fdf[f'ma{ma_trend_period}'] * 1.10) & (fdf['pct_chg'] > high_pct_threshold)
            fdf = fdf[~mask_high_big.fillna(False)]

        # B: ä¸‹è·Œé€”ä¸­åæŠ½è¿‡æ»¤ -> prev3_sum < 0 ä¸” pct_chg > HIGH_PCT_THRESHOLD
        if all(c in fdf.columns for c in ['prev3_sum','pct_chg']):
            mask_down_rebound = (fdf['prev3_sum'] < 0) & (fdf['pct_chg'] > high_pct_threshold)
            fdf = fdf[~mask_down_rebound.fillna(False)]

        # C: å·¨é‡å†²é«˜è¿‡æ»¤ -> vol_ratio è¶…è¿‡é˜ˆå€¼
        if 'vol_ratio' in fdf.columns:
            mask_vol_spike = (fdf['vol_ratio'] > vol_spike_mult)
            fdf = fdf[~mask_vol_spike.fillna(False)]

        # D: æç«¯æ³¢åŠ¨è¿‡æ»¤ -> volatility_10 > MAX_VOLATILITY_10D
        if 'volatility_10' in fdf.columns:
            mask_volatility = fdf['volatility_10'] > max_volatility_10d
            fdf = fdf[~mask_volatility.fillna(False)]

        after_cnt = len(fdf)
        if trade_date == last_trade:
            st.info(f"è¯Šæ–­ï¼šé«˜çº§é£é™©è¿‡æ»¤åï¼Œå‰©ä½™è‚¡ç¥¨æ•°é‡: **{after_cnt}** æ”¯ï¼Œå¼€å§‹è¯„åˆ†...")
    except Exception as e:
        if trade_date == last_trade: st.warning(f"é«˜çº§é£é™©è¿‡æ»¤æ¨¡å—å¼‚å¸¸ï¼Œè·³è¿‡è¿‡æ»¤ã€‚é”™è¯¯ï¼š{e}")
    
    if fdf.empty: return pd.DataFrame()


    # 6. RSLï¼ˆç›¸å¯¹å¼ºå¼±ï¼‰è®¡ç®—
    if '10d_return' in fdf.columns:
        try:
            # èµ„é‡‘å¼ºåº¦ä»£ç†ï¼ˆä¸ä¾èµ– moneyflowï¼‰ï¼šç®€å•ä¹˜ç§¯æŒ‡æ ‡ï¼ˆprice move * vol_ratio * turnoverï¼‰
            fdf['proxy_money'] = (abs(fdf['pct_chg']) + 1e-9) * fdf['vol_ratio'].fillna(0) * fdf['turnover_rate'].fillna(0)
            
            market_mean_10d = fdf['10d_return'].replace([np.inf,-np.inf], np.nan).dropna().mean()
            if np.isnan(market_mean_10d) or abs(market_mean_10d) < 1e-9:
                market_mean_10d = 1e-9
            fdf['rsl'] = fdf['10d_return'] / market_mean_10d
        except:
            fdf['rsl'] = 1.0
            fdf['proxy_money'] = 0.0
    else:
        fdf['rsl'] = 1.0
        fdf['proxy_money'] = 0.0


    # 7. å½’ä¸€åŒ–
    fdf['s_pct'] = norm_col(fdf.get('pct_chg', pd.Series([0]*len(fdf))))
    fdf['s_volratio'] = norm_col(fdf.get('vol_ratio', pd.Series([0]*len(fdf))))
    fdf['s_turn'] = norm_col(fdf.get('turnover_rate', pd.Series([0]*len(fdf))))
    
    # èµ„é‡‘å› å­ï¼šä¼˜å…ˆä½¿ç”¨ moneyflowï¼Œå¦åˆ™ä½¿ç”¨ proxy_money
    if 'net_mf_amount' in fdf.columns and fdf['net_mf_amount'].abs().sum() > 0:
        fdf['s_money'] = norm_col(fdf.get('net_mf_amount', pd.Series([0]*len(fdf))))
    else:
        fdf['s_money'] = norm_col(fdf.get('proxy_money', pd.Series([0]*len(fdf))))

    fdf['s_amount'] = norm_col(fdf.get('amount_yuan', pd.Series([0]*len(fdf))))
    fdf['s_10d'] = norm_col(fdf.get('10d_return', pd.Series([0]*len(fdf))))
    fdf['s_macd'] = norm_col(fdf.get('macd', pd.Series([0]*len(fdf))))
    fdf['s_rsl'] = norm_col(fdf.get('rsl', pd.Series([0]*len(fdf))))
    # æ³¨æ„ï¼šæ³¢åŠ¨ç‡æ˜¯è´Ÿå‘å› å­ (è¶Šä½è¶Šå¥½)ï¼Œæ‰€ä»¥ 1 - norm_col
    fdf['s_volatility'] = 1 - norm_col(fdf.get('volatility_10', pd.Series([0]*len(fdf)))) 
    
    
    # 8. ç»¼åˆè¯„åˆ†ï¼ˆBC æ··åˆæƒé‡ï¼‰- åå‘çŸ­çº¿çˆ†å‘
    w_pct = 0.18        
    w_volratio = 0.18   
    w_turn = 0.12       
    w_money = 0.14      
    w_10d = 0.12        
    w_macd = 0.06       
    w_rsl = 0.12        
    w_volatility = 0.08 

    fdf['ç»¼åˆè¯„åˆ†'] = (
        fdf['s_pct'] * w_pct +
        fdf['s_volratio'] * w_volratio +
        fdf['s_turn'] * w_turn +
        fdf['s_money'] * w_money +
        fdf['s_10d'] * w_10d +
        fdf['s_macd'] * w_macd +
        fdf['s_rsl'] * w_rsl +
        fdf['s_volatility'] * w_volatility
    )
    
    return fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).head(final_pool_size).reset_index(drop=True)


# ----------------------------------------------------
# ç®€æ˜“å›æµ‹æ¨¡å— (é€»è¾‘ä¿æŒ V13.5 ç¨³å®š)
# ----------------------------------------------------
def run_simple_backtest(days, params):
    
    HOLDING_PERIODS = [1, 3, 5]
    status = st.session_state['backtest_status']
    
    container = st.empty()
    with container.container():
        st.subheader(f"ğŸ“ˆ ç®€æ˜“å†å²å›æµ‹ç»“æœ (V13.6 BC èåˆç‰ˆ)")
        
        trade_dates_all = get_trade_cal_dates()
        
        if not trade_dates_all:
             st.error("æ— æ³•è·å–å†å²äº¤æ˜“æ—¥å†ã€‚")
             return
             
        # ç¡®ä¿å›æµ‹åŸºå‡†æ—¥æœŸæ˜¯æ­£ç¡®çš„
        if trade_dates_all[0] != last_trade and len(trade_dates_all) > 1 and trade_dates_all[1] == last_trade:
            trade_dates_all = trade_dates_all[1:]

        max_holding = max(HOLDING_PERIODS)
        trade_dates = trade_dates_all[:days + max_holding]
        trade_dates.reverse() 
        total_iterations = len(trade_dates) - max_holding 
        
        if total_iterations < 1:
            st.warning(f"äº¤æ˜“æ—¥ä¸è¶³ {max_holding + 1} å¤©ï¼Œæ— æ³•è¿›è¡Œå›æµ‹ã€‚")
            return
            
        status['total_days'] = total_iterations
        start_index = status['current_index']
        
        if start_index >= total_iterations:
             st.success(f"å›æµ‹å·²å®Œæˆã€‚ç´¯è®¡æ”¶ç›Šç‡è¯·æŸ¥çœ‹ä¸‹æ–¹ã€‚")
        else:
             st.info(f"å›æµ‹å‘¨æœŸï¼š**{trade_dates[0]}** è‡³ **{trade_dates[total_iterations-1]}**ã€‚æ­£åœ¨ä»ç¬¬ {start_index+1} å¤©ç»§ç»­...")

        pbar = st.progress(status['progress'], text=f"å›æµ‹è¿›åº¦ï¼š[{status['current_index']}/{status['total_days']}]...")
        
        # ç¡®ä¿ä¼ å…¥çš„å‚æ•°å­—å…¸æ˜¯å®Œæ•´çš„ (åŒ…å« V13.6 æ–°å¢å‚æ•°)
        score_params = {
            'MIN_PRICE': params.get('MIN_PRICE', DEFAULT_MIN_PRICE), 
            'MAX_PRICE': params.get('MAX_PRICE', DEFAULT_MAX_PRICE), 
            'MIN_TURNOVER': params.get('MIN_TURNOVER', DEFAULT_MIN_TURNOVER), 
            'MIN_AMOUNT': params.get('MIN_AMOUNT', DEFAULT_MIN_AMOUNT), 
            'MIN_CIRC_MV_Billion': params.get('MIN_CIRC_MV_Billion', DEFAULT_MIN_CIRC_MV_B),
            'MAX_CIRC_MV_Billion': params.get('MAX_CIRC_MV_Billion', DEFAULT_MAX_CIRC_MV_B),
            'MA_TREND_PERIOD': params.get('MA_TREND_PERIOD', DEFAULT_MA_PERIOD),
            'MIN_LIST_DAYS': params.get('MIN_LIST_DAYS', DEFAULT_MIN_LIST_DAYS),
            'FINAL_POOL': params.get('FINAL_POOL', DEFAULT_FINAL_POOL),
            # V13.6 æ–°å¢
            'VOL_SPIKE_MULT': params.get('VOL_SPIKE_MULT', DEFAULT_VOL_SPIKE_MULT),
            'HIGH_PCT_THRESHOLD': params.get('HIGH_PCT_THRESHOLD', DEFAULT_HIGH_PCT_THRESHOLD),
            'MAX_VOLATILITY_10D': params.get('MAX_VOLATILITY_10D', DEFAULT_MAX_VOLATILITY_10D)
        }
        
        for i in range(start_index, total_iterations):
            select_date = trade_dates[i]
            next_trade_date = trade_dates[i+1] 
            
            # ä½¿ç”¨ V13.6 è¯„åˆ†é€»è¾‘
            select_df_full = run_scoring_for_date(select_date, score_params) 

            result = {
                'é€‰è‚¡æ—¥': select_date, 
                'è‚¡ç¥¨': 'æ— ç¬¦åˆæ¡ä»¶', 
                'ä¹°å…¥ä»· (T+1 å¼€ç›˜)': np.nan, 
                'è¯„åˆ†': np.nan,
                'å¸‚å€¼ (äº¿)': np.nan
            }
            for N in HOLDING_PERIODS:
                 result[f'T+{N} æ”¶ç›Šç‡ (%)'] = 0.0
                 result[f'T+{N} å–å‡ºä»·'] = np.nan
                 
            
            if not select_df_full.empty:
                # ä»…å›æµ‹ Top 1 
                top_pick = select_df_full.iloc[0] 
                ts_code = top_pick['ts_code']
                
                max_retries = 3 
                buy_day_data = pd.DataFrame()
                for attempt in range(max_retries):
                    buy_day_data = safe_get(pro.daily, ts_code=ts_code, trade_date=next_trade_date)
                    if not buy_day_data.empty: break
                    time.sleep(1) 
                    
                buy_price = buy_day_data.iloc[0]['open'] if not buy_day_data.empty and 'open' in buy_day_data.columns else np.nan
                
                result['è‚¡ç¥¨'] = f"{top_pick.get('name', 'N/A')}({ts_code})"
                result['ä¹°å…¥ä»· (T+1 å¼€ç›˜)'] = buy_price
                result['è¯„åˆ†'] = top_pick['ç»¼åˆè¯„åˆ†']
                result['å¸‚å€¼ (äº¿)'] = top_pick['circ_mv_wan'] / 10000.0 if not pd.isna(top_pick['circ_mv_wan']) else np.nan
                
                if buy_price > 0 and not pd.isna(buy_price):
                    
                    for N in HOLDING_PERIODS:
                        sell_trade_date = trade_dates[i+N] 
                        
                        sell_day_data = safe_get(pro.daily, ts_code=ts_code, trade_date=sell_trade_date)
                        
                        if not sell_day_data.empty and 'close' in sell_day_data.columns:
                            sell_price = sell_day_data.iloc[0]['close']
                            result[f'T+{N} å–å‡ºä»·'] = sell_price
                            
                            if not pd.isna(sell_price):
                                return_pct = (sell_price / buy_price) - 1.0
                                return_pct = max(-0.10, return_pct) 
                                result[f'T+{N} æ”¶ç›Šç‡ (%)'] = return_pct * 100
                        
            status['results'].append(result)
            status['current_index'] = i + 1
            status['progress'] = (i + 1) / total_iterations
            
            pbar.progress(status['progress'], text=f"æ­£åœ¨å›æµ‹ {select_date}... [{i+1}/{total_iterations}]")
            
            if (i+1) % 2 == 0 or (i + 1) == total_iterations: 
                 st.rerun() 
        
        status['progress'] = 1.0
        status['current_index'] = total_iterations
        pbar.progress(1.0, text="å›æµ‹å®Œæˆã€‚")
        
        results_df = pd.DataFrame(status['results'])
        
        if results_df.empty:
            st.warning("å›æµ‹ç»“æœä¸ºç©ºã€‚")
            return
            
        st.markdown("---")
        st.subheader("ğŸ’¡ æœ€ç»ˆå›æµ‹æŒ‡æ ‡ï¼ˆå¤šå‘¨æœŸå¯¹æ¯”ï¼‰")
        
        cols_metrics = st.columns(len(HOLDING_PERIODS))
        
        for idx, N in enumerate(HOLDING_PERIODS):
            col_name = f'T+{N} æ”¶ç›Šç‡ (%)'
            results_df[col_name] = results_df[col_name].replace([np.inf, -np.inf], 0.0).fillna(0.0)
            cumulative_return = (results_df[col_name] / 100 + 1).product() - 1
            wins = (results_df[col_name] > 0).sum()
            total_trades = len(results_df)
            win_rate = wins / total_trades if total_trades > 0 else 0

            with cols_metrics[idx]:
                st.metric(f"ç´¯è®¡æ”¶ç›Šç‡ (T+{N})", f"{cumulative_return*100:.2f}%")
                st.caption(f"èƒœç‡: {win_rate*100:.2f}% | äº¤æ˜“æ¬¡æ•°: {total_trades}")
        
        st.markdown("---")
        st.subheader("ğŸ“‹ æ¯æ—¥äº¤æ˜“è®°å½•")
        
        display_cols = ['é€‰è‚¡æ—¥', 'è‚¡ç¥¨', 'å¸‚å€¼ (äº¿)', 'è¯„åˆ†', 'ä¹°å…¥ä»· (T+1 å¼€ç›˜)']
        for N in HOLDING_PERIODS:
            display_cols.append(f'T+{N} æ”¶ç›Šç‡ (%)')
            
        st.dataframe(results_df[display_cols], use_container_width=True)


# ----------------------------------------------------
# å®æ—¶é€‰è‚¡æ¨¡å— (V13.6)
# ----------------------------------------------------
def run_live_selection(last_trade, params):
    st.write(f"æ­£åœ¨è¿è¡Œå®æ—¶é€‰è‚¡ï¼ˆæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}ï¼‰...")
    
    # ç¡®ä¿å‚æ•°å­—å…¸æ˜¯å®Œæ•´çš„
    params_dict = {
        'MIN_PRICE': params.get('MIN_PRICE', DEFAULT_MIN_PRICE), 
        'MAX_PRICE': params.get('MAX_PRICE', DEFAULT_MAX_PRICE), 
        'MIN_TURNOVER': params.get('MIN_TURNOVER', DEFAULT_MIN_TURNOVER), 
        'MIN_AMOUNT': params.get('MIN_AMOUNT', DEFAULT_MIN_AMOUNT), 
        'MIN_CIRC_MV_Billion': params.get('MIN_CIRC_MV_Billion', DEFAULT_MIN_CIRC_MV_B),
        'MAX_CIRC_MV_Billion': params.get('MAX_CIRC_MV_Billion', DEFAULT_MAX_CIRC_MV_B),
        'MA_TREND_PERIOD': params.get('MA_TREND_PERIOD', DEFAULT_MA_PERIOD),
        'MIN_LIST_DAYS': params.get('MIN_LIST_DAYS', DEFAULT_MIN_LIST_DAYS),
        'FINAL_POOL': params.get('FINAL_POOL', DEFAULT_FINAL_POOL),
        # V13.6 æ–°å¢
        'VOL_SPIKE_MULT': params.get('VOL_SPIKE_MULT', DEFAULT_VOL_SPIKE_MULT),
        'HIGH_PCT_THRESHOLD': params.get('HIGH_PCT_THRESHOLD', DEFAULT_HIGH_PCT_THRESHOLD),
        'MAX_VOLATILITY_10D': params.get('MAX_VOLATILITY_10D', DEFAULT_MAX_VOLATILITY_10D)
    }
    
    fdf_full = run_scoring_for_date(last_trade, params_dict)

    if fdf_full.empty:
        st.error(f"æ¸…æ´—å’Œè¯„åˆ†åæ²¡æœ‰å€™é€‰ã€‚è¯·æ£€æŸ¥ç¡¬æ€§è¿‡æ»¤å‚æ•°æ˜¯å¦è¿‡äºä¸¥æ ¼ã€‚")
        st.stop()

    fdf = fdf_full.head(params.get('TOP_DISPLAY', DEFAULT_TOP_DISPLAY)).copy()
    fdf.index = fdf.index + 1

    st.success(f"è¯„åˆ†å®Œæˆï¼šæ€»å€™é€‰ {len(fdf_full)} æ”¯ï¼Œæ˜¾ç¤º Top {min(params.get('TOP_DISPLAY', DEFAULT_TOP_DISPLAY), len(fdf))}ã€‚")
    
    # è½¬æ¢ä¸ºäº¿æ˜¾ç¤º 
    fdf['æµé€šå¸‚å€¼ (äº¿)'] = fdf['circ_mv_wan'] / 10000.0
    
    # V13.6 å¢å¼ºæ˜¾ç¤ºåˆ—
    final_display_cols = [
        'name','ts_code','ç»¼åˆè¯„åˆ†','pct_chg','æµé€šå¸‚å€¼ (äº¿)','turnover_rate',
        'vol_ratio','10d_return','net_mf_amount','macd','volatility_10'
    ]
    
    # å¡«å……ç¼ºå¤±çš„åˆ—ä»¥é¿å… KeyError
    for c in final_display_cols:
        if c not in fdf.columns: fdf[c] = np.nan
    
    # è°ƒæ•´ net_mf_amount æ˜¾ç¤º
    if 'net_mf_amount' in fdf.columns:
        fdf['å‡€æµå…¥ (äº¿)'] = fdf['net_mf_amount'] / 1e8
        final_display_cols[final_display_cols.index('net_mf_amount')] = 'å‡€æµå…¥ (äº¿)'
        
    
    st.dataframe(fdf[final_display_cols], use_container_width=True, height=500)

    # ä¸‹è½½
    download_cols = [c for c in fdf_full.columns if c not in ['list_date', 'days_since_list', 'circ_mv_wan']]
    out_csv = fdf_full[download_cols].head(200).to_csv(index=True, encoding='utf-8-sig')
    st.download_button("ä¸‹è½½è¯„åˆ†ç»“æœï¼ˆå‰200ï¼‰CSV", data=out_csv, file_name=f"score_result_{last_trade}_V13_6.csv", mime="text/csv")

    st.markdown("### å°ç»“ä¸æ“ä½œæç¤ºï¼ˆV13.6 BC èåˆç‰ˆï¼‰")
    st.markdown(f"""
- **ã€å¸‚å€¼èŒƒå›´ã€‘** æµé€šå¸‚å€¼èŒƒå›´ï¼š**{params_dict['MIN_CIRC_MV_Billion']} äº¿ åˆ° {params_dict['MAX_CIRC_MV_Billion']} äº¿**ã€‚
- **ã€é£æ§å‡çº§ã€‘** é›†æˆäº† **4 é¡¹é«˜çº§çŸ­çº¿é£æ§**ï¼Œå‰”é™¤äº†é«˜ä½å¤§é˜³çº¿ã€ä¸‹è·Œåå¼¹ã€å·¨é‡å†²é«˜ã€æç«¯æ³¢åŠ¨ç­‰é£é™©æ ‡çš„ã€‚
- **ã€è¯„åˆ†æƒé‡ã€‘** é‡‡ç”¨ BC æ··åˆæƒé‡ï¼Œæ›´åå‘äº**çŸ­æœŸçˆ†å‘åŠ›**å’Œ**èµ„é‡‘é¢**ã€‚
- **ã€æ“ä½œå»ºè®®ã€‘** å»ºè®®æ‚¨å°†ä¾§è¾¹æ çš„å¸‚å€¼èŒƒå›´è°ƒæ•´ä¸ºæ‚¨éœ€è¦çš„ **100 äº¿ - 200 äº¿**ï¼Œç„¶åå†æ¬¡è¿è¡Œé€‰è‚¡ï¼Œä»¥é›†ä¸­é€‰è‚¡èŒƒå›´ã€‚
""")


# ----------------------------------------------------
# ä¸»ç¨‹åºæ§åˆ¶é€»è¾‘
# ----------------------------------------------------
# ç¡®ä¿åœ¨ä¸»ç¨‹åºä¸­æ„å»ºçš„å‚æ•°å­—å…¸æ˜¯å®Œæ•´çš„
params = {
    'FINAL_POOL': FINAL_POOL, 'TOP_DISPLAY': TOP_DISPLAY,
    'MIN_PRICE': MIN_PRICE, 'MAX_PRICE': MAX_PRICE, 'MIN_TURNOVER': MIN_TURNOVER,
    'MIN_AMOUNT': MIN_AMOUNT, 
    'MIN_CIRC_MV_Billion': MIN_CIRC_MV_Billion,
    'MAX_CIRC_MV_Billion': MAX_CIRC_MV_Billion,
    'MA_TREND_PERIOD': MA_TREND_PERIOD,
    'MIN_LIST_DAYS': MIN_LIST_DAYS,
    # V13.6 æ–°å¢å‚æ•°
    'VOL_SPIKE_MULT': VOL_SPIKE_MULT,
    'HIGH_PCT_THRESHOLD': HIGH_PCT_THRESHOLD,
    'MAX_VOLATILITY_10D': MAX_VOLATILITY_10D
}

if st.session_state.get('run_backtest', False):
    run_simple_backtest(BACKTEST_DAYS, params)
    
elif st.session_state.get('run_selection', False):
    run_live_selection(last_trade, params)
    
else:
    st.info("è¯·ç‚¹å‡»ä¸Šæ–¹çš„æŒ‰é’®å¼€å§‹è¿è¡Œã€‚")
