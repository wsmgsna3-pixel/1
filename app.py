# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V9.8 ç¨³å®šåŠ é€Ÿå›é€€ç‰ˆ (ä¿ç•™ V9.7 é€»è¾‘ + å›é€€åˆ° V9.0 ç¨³å®šæ•°æ®è·å–)

è¯´æ˜ï¼š
1. ã€ç¨³å®šå›é€€ã€‘ç§»é™¤ V9.7 çš„æ‰¹é‡å†å²æ•°æ®é¢„åŠ è½½ (bulk_fetch_daily) æœºåˆ¶ã€‚
2. ã€V9.0 ç¨³å®šæ¨¡å¼ã€‘åœ¨è¯„åˆ†å¾ªç¯ä¸­ï¼Œå›å½’ V9.0 çš„é€ä¸ªè·å–å†å²æ•°æ®æ¨¡å¼ï¼Œç¡®ä¿æ•°æ®ä¸ç¼ºå¤±ã€‚
3. ã€ç­–ç•¥é€»è¾‘ã€‘ä¿æŒ V9.7 æœ€ç»ˆé€»è¾‘ï¼šä¸¥æ ¼å¸‚å€¼é˜²å¾¡ + æé™å®½æ¾æµåŠ¨æ€§ + é£æ§å› å­æ”¹ä¸ºè½¯æ€§è¯„åˆ†ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import joblib 
import os

warnings.filterwarnings("ignore")

# ---------------------------
# å¤–éƒ¨ç¼“å­˜é…ç½® (ç”¨äºå†å²æ•°æ®)
# ---------------------------
CACHE_DIR = "data_cache"
os.makedirs(CACHE_DIR, exist_ok=True)
# joblib å°è£… Tushare æ¥å£ï¼Œå®ç°ç£ç›˜æŒä¹…åŒ–ç¼“å­˜
memory = joblib.Memory(CACHE_DIR, verbose=0)

# ---------------------------
# é¡µé¢è®¾ç½® (UI ç©ºé—´æœ€å¤§åŒ–)
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ï¼ˆV9.8 ç¨³å®šåŠ é€Ÿå›é€€ç‰ˆï¼‰", layout="wide")
st.markdown("### é€‰è‚¡ç‹ï¼ˆV9.8 ç¨³å®šåŠ é€Ÿå›é€€ç‰ˆï¼‰") 

# ---------------------------
# ä¾§è¾¹æ å‚æ•°ï¼ˆV9.8 ç­–ç•¥ï¼šæé™å®½æ¾æµåŠ¨æ€§ï¼Œä¿ç•™é£æ§å‚æ•°ç”¨äºè¯„åˆ†ï¼‰
# ---------------------------
with st.sidebar:
    st.header("å¯è°ƒå‚æ•°ï¼ˆå®æ—¶ï¼‰")
    INITIAL_TOP_N = int(st.number_input("åˆç­›ï¼šæ¶¨å¹…æ¦œå–å‰ N", value=1000, step=100))
    FINAL_POOL = int(st.number_input("æ¸…æ´—åå–å‰ M è¿›å…¥è¯„åˆ†", value=500, step=50))
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=30, step=5))
    
    MIN_PRICE = float(st.number_input("æœ€ä½ä»·æ ¼ (å…ƒ)", value=10.0, step=1.0))
    MAX_PRICE = float(st.number_input("æœ€é«˜ä»·æ ¼ (å…ƒ)", value=200.0, step=10.0))
    
    # V9.6 è°ƒæ•´ï¼šæé™å®½æ¾æµåŠ¨æ€§
    MIN_TURNOVER = float(st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=0.5, step=0.1)) 
    MIN_AMOUNT = float(st.number_input("æœ€ä½æˆäº¤é¢ (å…ƒ)", value=20_000_000.0, step=5_000_000.0)) # 2000ä¸‡
    
    # é£æ§å‚æ•°ä¿ç•™ï¼Œä½†ä»…ç”¨äºè¯„åˆ† (ä¸å†ç¡¬æ€§æ’é™¤)
    VOL_SPIKE_MULT = float(st.number_input("æ”¾é‡å€æ•°é˜ˆå€¼ (vol_last > vol_ma5 * x)", value=1.4, step=0.1)) 
    VOLATILITY_MAX = float(st.number_input("è¿‡å»10æ—¥æ³¢åŠ¨ std é˜ˆå€¼ (%)", value=6.0, step=0.5)) 
    
    HIGH_PCT_THRESHOLD = float(st.number_input("è§†ä¸ºå¤§é˜³çº¿ pct_chg (%)", value=6.0, step=0.5))
    
    BACKTEST_DAYS = int(st.number_input("å›æµ‹ï¼šæœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥", value=10, step=1))
    st.markdown("---")
    st.caption("æç¤ºï¼šç­–ç•¥å·²è°ƒæ•´è‡³ 'V9.8 ç¨³å®šå›é€€' æ¨¡å¼ï¼Œå›é€€åˆ° V9.0 çš„æ•°æ®è·å–æ–¹å¼ï¼Œé¢„è®¡è¿è¡ŒæˆåŠŸã€‚")

# ---------------------------
# Token è¾“å…¥ (ä¿ç•™)
# ---------------------------
st.markdown("è¯·è¾“å…¥ Tushare Tokenã€‚")
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password", label_visibility="collapsed")

if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

# åˆå§‹åŒ– tushare
ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# ä¾èµ–å‡½æ•°ï¼šæ•°æ®å®‰å…¨è·å–å’Œäº¤æ˜“æ—¥æŸ¥æ‰¾ (ä¿ç•™)
# ---------------------------
def safe_get(func, **kwargs):
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=600)
def find_last_trade_day(max_days=20):
    today = datetime.now().date()
    for i in range(max_days):
        d = today - timedelta(days=i)
        ds = d.strftime("%Y%m%d")
        # --- V9.8 ç¨³å®šï¼šè¿™é‡Œç¡®ä¿èƒ½æ‰¾åˆ°äº¤æ˜“æ—¥ ---
        df = safe_get(pro.daily, trade_date=ds)
        if not df.empty:
            return ds
    return None

last_trade = find_last_trade_day()
if not last_trade:
    st.error("æ— æ³•æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥ï¼Œæ£€æŸ¥ç½‘ç»œæˆ– Token æƒé™ã€‚")
    st.stop()
st.info(f"å‚è€ƒæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}")


# ----------------------------------------------------
# V9.8: ç§»é™¤ bulk_fetch_daily å‡½æ•°ï¼Œä¸å†ä½¿ç”¨æ‰¹é‡é¢„åŠ è½½
# ----------------------------------------------------


# ----------------------------------------------------
# æŒ‰é’®æ§åˆ¶æ¨¡å— (Session State æ–­ç‚¹ç»­ä¼ ) (ä¿ç•™)
# ----------------------------------------------------
if 'run_selection' not in st.session_state: st.session_state['run_selection'] = False
if 'run_backtest' not in st.session_state: st.session_state['run_backtest'] = False
if 'backtest_status' not in st.session_state: 
    # V9.8: ç§»é™¤ bulk_data ç›¸å…³çš„çŠ¶æ€
    st.session_state['backtest_status'] = {'progress': 0.0, 'results': [], 'current_index': 0, 'total_days': 0}

col1, col2 = st.columns(2)

with col1:
    if st.button("ğŸš€ è¿è¡Œå½“æ—¥é€‰è‚¡", use_container_width=True):
        st.session_state['run_selection'] = True
        st.session_state['run_backtest'] = False
        st.session_state['backtest_status'] = {'progress': 0.0, 'results': [], 'current_index': 0, 'total_days': 0}
        st.rerun()

with col2:
    if st.button(f"âœ… è¿è¡Œå†å²å›æµ‹ ({BACKTEST_DAYS} æ—¥)", use_container_width=True):
        st.session_state['run_backtest'] = True
        st.session_state['run_selection'] = False
        if st.session_state['backtest_status']['progress'] == 1.0 or st.session_state['backtest_status']['total_days'] == 0:
             st.session_state['backtest_status'] = {'progress': 0.0, 'results': [], 'current_index': 0, 'total_days': 0}
        st.rerun()

st.markdown("---")

# ---------------------------
# æŒ‡æ ‡è®¡ç®—å’Œå½’ä¸€åŒ– (ä¿ç•™)
# ---------------------------
def compute_indicators(df):
    res = {}
    if df.empty or len(df) < 3: return res
    close = df['close'].astype(float); high = df['high'].astype(float); low = df['low'].astype(float)
    try: res['last_close'] = close.iloc[-1]
    except: res['last_close'] = np.nan
    for n in (5,10,20):
        if len(close) >= n: res[f'ma{n}'] = close.rolling(window=n).mean().iloc[-1]
        else: res[f'ma{n}'] = np.nan
    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        macd_val = (diff - dea) * 2
        res['macd'] = macd_val.iloc[-1]; res['diff'] = diff.iloc[-1]; res['dea'] = dea.iloc[-1]
    else: res['macd'] = res['diff'] = res['dea'] = np.nan
    n = 9
    if len(close) >= n:
        low_n = low.rolling(window=n).min()
        high_n = high.rolling(window=n).max()
        rsv = (close - low_n) / (high_n - low_n + 1e-9) * 100
        rsv = rsv.fillna(50)
        k = rsv.ewm(alpha=1/3, adjust=False).mean()
        d = k.ewm(alpha=1/3, adjust=False).mean()
        j = 3*k - 2*d
        res['k'] = k.iloc[-1]; res['d'] = d.iloc[-1]; res['j'] = j.iloc[-1]
    else: res['k'] = res['d'] = res['j'] = np.nan
    vols = df['vol'].astype(float).tolist()
    if len(vols) >= 6:
        avg_prev5 = np.mean(vols[-6:-1])
        res['vol_ratio'] = vols[-1] / (avg_prev5 + 1e-9)
        res['vol_last'] = vols[-1]; res['vol_ma5'] = avg_prev5
    else: res['vol_ratio'] = res['vol_last'] = res['vol_ma5'] = np.nan
    if len(close) >= 10: res['10d_return'] = close.iloc[-1] / close.iloc[-10] - 1
    else: res['10d_return'] = np.nan
    if 'pct_chg' in df.columns and len(df) >= 4:
        try: res['prev3_sum'] = df['pct_chg'].astype(float).iloc[-4:-1].sum()
        except: res['prev3_sum'] = np.nan
    else: res['prev3_sum'] = np.nan
    try:
        if 'pct_chg' in df.columns and len(df) >= 10:
            res['volatility_10'] = df['pct_chg'].astype(float).tail(10).std()
        else: res['volatility_10'] = np.nan
    except: res['volatility_10'] = np.nan
    return res

def safe_merge_pool(pool_df, other_df, cols):
    pool = pool_df.set_index('ts_code').copy()
    if other_df is None or other_df.empty:
        for c in cols: pool[c] = np.nan
        return pool.reset_index()
    if 'ts_code' not in other_df.columns:
        try: other_df = other_df.reset_index()
        except:
            for c in cols: pool[c] = np.nan
            return pool.reset_index()
    for c in cols:
        if c not in other_df.columns: other_df[c] = np.nan
    try: joined = pool.join(other_df.set_index('ts_code')[cols], how='left')
    except Exception:
        for c in cols: pool[c] = np.nan
        return pool.reset_index()
    for c in cols:
        if c not in joined.columns: joined[c] = np.nan
    return joined.reset_index()

def norm_col(s):
    s = s.fillna(0.0).replace([np.inf,-np.inf], np.nan).fillna(0.0)
    mn = s.min(); mx = s.max()
    if mx - mn < 1e-9: return pd.Series([0.5]*len(s), index=s.index)
    return (s - mn) / (mx - mn)

# ----------------------------------------------------
# æ ¸å¿ƒè¯„åˆ†å‡½æ•° (V9.8ï¼šæ•°æ®è·å–é€»è¾‘å›é€€ + é€»è¾‘ä¿®æ­£ä¿ç•™)
# ----------------------------------------------------
@memory.cache # V9.0 çš„ç¼“å­˜æ˜¯åŠ åœ¨æ•´ä¸ªè¯„åˆ†å‡½æ•°ä¸Šçš„
def run_scoring_for_date(trade_date, params):
    """
    V9.8 è¯„åˆ†å‡½æ•°ï¼šå›é€€åˆ° V9.0 çš„æ•°æ®è·å–æ¨¡å¼ï¼Œä¿ç•™ V9.7 çš„é€»è¾‘ä¿®æ­£å’Œè¯Šæ–­ã€‚
    """
    
    # è§£åŒ…å‚æ•°
    initial_top_n, final_pool_limit, min_price, max_price, min_turnover, min_amount, vol_spike_mult, volatility_max, high_pct_threshold = \
        params['INITIAL_TOP_N'], params['FINAL_POOL'], params['MIN_PRICE'], params['MAX_PRICE'], \
        params['MIN_TURNOVER'], params['MIN_AMOUNT'], params['VOL_SPIKE_MULT'], \
        params['VOLATILITY_MAX'], params['HIGH_PCT_THRESHOLD']
    
    # 1. æ‹‰å–å½“æ—¥æ¶¨å¹…æ¦œåˆç­›
    daily_all = safe_get(pro.daily, trade_date=trade_date)
    daily_basic = safe_get(pro.daily_basic, trade_date=trade_date, fields='ts_code,turnover_rate,amount,total_mv,circ_mv')
    mf_raw = safe_get(pro.moneyflow, trade_date=trade_date)
    
    # --- è¯Šæ–­ 1ï¼šæ£€æŸ¥ Tushare æ•°æ®æ˜¯å¦æ‹‰å–æˆåŠŸ ---
    if daily_all.empty: 
        # Tushare pro.daily å¤±è´¥æ˜¯æœ€å¤§çš„é—®é¢˜
        st.error(f"è¯Šæ–­ï¼šTushare æ— æ³•è·å– {trade_date} çš„æ—¥çº¿æ•°æ®ï¼Œè¯·æ£€æŸ¥ Token æƒé™æˆ–ç½‘ç»œã€‚")
        return pd.DataFrame()
    
    daily_all = daily_all.sort_values("pct_chg", ascending=False).reset_index(drop=True)
    pool0 = daily_all.head(int(initial_top_n)).copy().reset_index(drop=True)

    # 2. åˆå¹¶é«˜çº§æ¥å£æ•°æ®
    stock_basic = safe_get(pro.stock_basic, list_status='L', fields='ts_code,name,industry,total_mv,circ_mv')
    moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])
    if not mf_raw.empty:
        possible = ['net_mf','net_mf_amount','net_mf_in','net_mf_out']
        col = next((c for c in possible if c in mf_raw.columns), None)
        if col: moneyflow = mf_raw[['ts_code', col]].rename(columns={col:'net_mf'}).fillna(0)
    
    if not stock_basic.empty:
        keep = [c for c in ['ts_code','name','industry','total_mv','circ_mv'] if c in stock_basic.columns]
        try: pool0 = pool0.merge(stock_basic[keep], on='ts_code', how='left')
        except Exception: pool0['name'] = pool0['ts_code']; pool0['industry'] = ''
    else: pool0['name'] = pool0['ts_code']; pool0['industry'] = ''
        
    pool_merged = safe_merge_pool(pool0, daily_basic, ['turnover_rate','amount','total_mv','circ_mv'])
    
    if moneyflow.empty: moneyflow = pd.DataFrame({'ts_code': pool_merged['ts_code'].tolist(), 'net_mf': [0.0]*len(pool_merged)})
    try: pool_merged = pool_merged.set_index('ts_code').join(moneyflow.set_index('ts_code'), how='left').reset_index()
    except: pool_merged['net_mf'] = 0.0
    pool_merged['net_mf'] = pool_merged['net_mf'].fillna(0.0)

    # --- è¯Šæ–­ 2ï¼šæ£€æŸ¥åŸå§‹æ± å¤§å° ---
    st.info(f"è¯Šæ–­ï¼šåŸå§‹æ¶¨å¹…æ¦œåˆç­›å¹¶åˆå¹¶åï¼Œè‚¡ç¥¨æ•°é‡: **{len(pool_merged)}** æ”¯ã€‚")
    
    # 3. æ¸…æ´— (åªä¿ç•™å¿…è¦çš„ç¡¬æ€§è¿‡æ»¤ï¼šä»·æ ¼ã€STã€å¸‚å€¼ã€æµåŠ¨æ€§ã€å½“æ—¥ä¸Šæ¶¨)
    
    # --- V9.8 ä¸¥æ ¼å¸‚å€¼é˜²å¾¡ (800äº¿) ---
    MAX_TOTAL_MV_YUAN = 80000000000.0 
    pool_merged['total_mv_yuan'] = pool_merged['total_mv'].apply(
        lambda tv: tv * 10000.0 if not pd.isna(tv) and tv > 1e6 else tv)
    pool_merged['amount_yuan'] = pool_merged['amount'].apply(
        lambda amt: amt * 10000.0 if not pd.isna(amt) and amt > 0 and amt < 1e5 else amt)

    clean_df = pool_merged.copy()
    
    # ä»·æ ¼ã€STã€åœç‰Œè¿‡æ»¤
    clean_df = clean_df[~(
        (clean_df['close'].isna()) | 
        (clean_df['close'] < min_price) | 
        (clean_df['close'] > max_price) | 
        (clean_df['name'].str.contains('ST|é€€', case=False, na=False))
    )]
    
    # æ¶¨è·Œå¹…è¿‡æ»¤ (å½“æ—¥ä¸Šæ¶¨)
    clean_df = clean_df[~((clean_df['pct_chg'].isna()) | (clean_df['pct_chg'] < 0))]
    
    # V9.8 å¸‚å€¼é˜²å¾¡è¿‡æ»¤ 
    clean_df = clean_df[~((clean_df['total_mv_yuan'].notna()) & (clean_df['total_mv_yuan'] > MAX_TOTAL_MV_YUAN))]

    # V9.8 æé™å®½æ¾æµåŠ¨æ€§è¿‡æ»¤ 
    clean_df = clean_df[~((clean_df['turnover_rate'].isna()) | (clean_df['turnover_rate'] < min_turnover))]
    clean_df = clean_df[~((clean_df['amount_yuan'].isna()) | (clean_df['amount_yuan'] < min_amount))]
    
    # --- è¯Šæ–­ 3ï¼šæ£€æŸ¥ç¡¬æ€§è¿‡æ»¤åçš„æ•°é‡ ---
    if clean_df.empty: 
        st.error(f"è¯Šæ–­ï¼šæ‰€æœ‰ç¡¬æ€§è¿‡æ»¤åï¼Œå‰©ä½™è‚¡ç¥¨æ•°é‡ä¸º **0** æ”¯ã€‚")
        return pd.DataFrame()

    st.info(f"è¯Šæ–­ï¼šç¡¬æ€§è¿‡æ»¤åï¼Œå‰©ä½™è‚¡ç¥¨æ•°é‡: **{len(clean_df)}** æ”¯ï¼Œå¼€å§‹è®¡ç®—æŒ‡æ ‡å¹¶è¯„åˆ†...")

    score_pool_n = min(int(final_pool_limit), 300)
    clean_df = clean_df.sort_values('pct_chg', ascending=False).head(score_pool_n).reset_index(drop=True)
    
    # 4. æŒ‡æ ‡è®¡ç®—ä¸è¯„åˆ†
    records = []
    
    # V9.8: æ¢å¤ V9.0 çš„é€ä¸ªè·å–å†å²æ•°æ®æ¨¡å¼
    start_dt = datetime.strptime(trade_date, "%Y%m%d") - timedelta(days=60 * 1.5) # 60å¤©æŒ‡æ ‡
    start_date_hist = start_dt.strftime("%Y%m%d")
    
    pbar = st.progress(0.0, text=f"æ­£åœ¨è®¡ç®— {len(clean_df)} æ”¯è‚¡ç¥¨çš„æŒ‡æ ‡...")

    for i, row in enumerate(clean_df.itertuples()):
        ts_code = getattr(row, 'ts_code'); pct_chg = getattr(row, 'pct_chg', 0.0);
        turnover_rate = getattr(row, 'turnover_rate', np.nan); net_mf = float(getattr(row, 'net_mf', 0.0));
        amount_raw = getattr(row, 'amount', np.nan)
        amount = amount_raw * 10000.0 if not pd.isna(amount_raw) and amount_raw > 0 and amount_raw < 1e5 else amount_raw
        amount = amount if not pd.isna(amount) else 0.0
        name = getattr(row, 'name', ts_code)

        # æ ¸å¿ƒï¼šV9.8 ç¨³å®šæ¨¡å¼ï¼šé€ä¸ªè·å–å†å²æ•°æ®
        hist = safe_get(pro.daily, ts_code=ts_code, start_date=start_date_hist, end_date=trade_date)
        
        ind = compute_indicators(hist)

        vol_ratio, ten_return, macd, k, d, j, vol_last, vol_ma5, prev3_sum, volatility_10, ma20, last_close = \
            ind.get('vol_ratio', np.nan), ind.get('10d_return', np.nan), ind.get('macd', np.nan), \
            ind.get('k', np.nan), ind.get('d', np.nan), ind.get('j', np.nan), \
            ind.get('vol_last', np.nan), ind.get('vol_ma5', np.nan), ind.get('prev3_sum', np.nan), ind.get('volatility_10', np.nan), ind.get('ma20', np.nan), ind.get('last_close', np.nan)

        try: proxy_money = (abs(pct_chg) + 1e-9) * (vol_ratio if not pd.isna(vol_ratio) else 0.0) * (turnover_rate if not pd.isna(turnover_rate) else 0.0)
        except: proxy_money = 0.0

        rec = {'ts_code': ts_code, 'pct_chg': pct_chg, 'turnover_rate': turnover_rate, 'net_mf': net_mf, 'amount': amount,
               'vol_ratio': vol_ratio, '10d_return': ten_return, 'macd': macd, 'k': k, 'd': d, 'j': j,
               'vol_last': vol_last, 'vol_ma5': vol_ma5, 'prev3_sum': prev3_sum, 'volatility_10': volatility_10,
               'proxy_money': proxy_money, 'name': name,
               'last_close': last_close, 'ma20': ma20}
        records.append(rec)
        
        pbar.progress((i + 1) / len(clean_df), text=f"æŒ‡æ ‡è®¡ç®—è¿›åº¦ï¼š[{i+1}/{len(clean_df)}]...")
        
    fdf = pd.DataFrame(records)
    if fdf.empty: return pd.DataFrame()
    pbar.empty()

    # 5. é£é™©è¿‡æ»¤ (V9.8 ä¿®æ­£ï¼šå°†æ‰€æœ‰é£æ§ç¡¬æ€§è¿‡æ»¤é€»è¾‘ç§»é™¤ï¼Œä»…ä¿ç•™åˆ°è¯„åˆ†é˜¶æ®µ)
    # 6. RSL & å½’ä¸€åŒ– (é€»è¾‘ä¸å˜)
    if '10d_return' in fdf.columns:
        try:
            market_mean_10d = fdf['10d_return'].replace([np.inf,-np.inf], np.nan).dropna().mean()
            fdf['rsl'] = fdf['10d_return'] / (market_mean_10d if abs(market_mean_10d) >= 1e-9 else 1e-9)
        except: fdf['rsl'] = 1.0
    else: fdf['rsl'] = 1.0

    fdf['s_pct'] = norm_col(fdf.get('pct_chg', pd.Series([0]*len(fdf))))
    fdf['s_volratio'] = norm_col(fdf.get('vol_ratio', pd.Series([0]*len(fdf))))
    fdf['s_turn'] = norm_col(fdf.get('turnover_rate', pd.Series([0]*len(fdf))))
    fdf['s_money'] = norm_col(fdf.get('net_mf', pd.Series([0]*len(fdf)))) if fdf['net_mf'].abs().sum() > 0 else norm_col(fdf.get('proxy_money', pd.Series([0]*len(fdf))))
    fdf['s_amount'] = norm_col(fdf.get('amount', pd.Series([0]*len(fdf))))
    fdf['s_10d'] = norm_col(fdf.get('10d_return', pd.Series([0]*len(fdf))))
    fdf['s_macd'] = norm_col(fdf.get('macd', pd.Series([0]*len(fdf))))
    fdf['s_rsl'] = norm_col(fdf.get('rsl', pd.Series([0]*len(fdf))))
    
    fdf['s_volatility'] = 1 - norm_col(fdf.get('volatility_10', pd.Series([0]*len(fdf))))

    # 7. ç»¼åˆè¯„åˆ† (V9.0 æƒé‡è°ƒæ•´ï¼šæé™é˜²å¾¡ï¼šw_turn (0.35), w_volatility (0.25))
    w_pct, w_volratio, w_turn, w_money, w_10d, w_macd, w_rsl, w_volatility = 0.05, 0.10, 0.35, 0.10, 0.05, 0.10, 0.05, 0.25
    
    fdf['ç»¼åˆè¯„åˆ†'] = (fdf['s_pct'] * w_pct + fdf['s_volratio'] * w_volratio + fdf['s_turn'] * w_turn + fdf['s_money'] 
        * w_money + fdf['s_10d'] * w_10d + fdf['s_macd'] * w_macd + fdf['s_rsl'] * w_rsl + fdf['s_volatility'] * w_volatility)
    
    return fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)


# ----------------------------------------------------
# ç®€æ˜“å›æµ‹æ¨¡å— (V9.8ï¼šç§»é™¤æ‰¹é‡æ•°æ®ä¾èµ–)
# ----------------------------------------------------
def run_simple_backtest(days, params):
    status = st.session_state['backtest_status']
    
    container = st.empty()
    with container.container():
        st.subheader("ğŸ“ˆ ç®€æ˜“å†å²å›æµ‹ç»“æœ")
        
        # 1. è·å–äº¤æ˜“æ—¥å†
        trade_dates_df = safe_get(pro.trade_cal, exchange='SSE', is_open='1', end_date=find_last_trade_day(), fields='cal_date')
        if trade_dates_df.empty:
            st.error("æ— æ³•è·å–å†å²äº¤æ˜“æ—¥å†ã€‚")
            return

        trade_dates = trade_dates_df['cal_date'].sort_values(ascending=False).head(days + 1).tolist()
        trade_dates.reverse() 
        total_iterations = len(trade_dates) - 1
        
        if total_iterations < 1:
            st.warning("äº¤æ˜“æ—¥ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå›æµ‹ã€‚")
            return
            
        status['total_days'] = total_iterations
        
        # V9.8: ç§»é™¤æ•°æ®é¢„åŠ è½½é€»è¾‘
        start_index = status['current_index']
        
        if start_index >= total_iterations:
             st.success(f"å›æµ‹å·²å®Œæˆã€‚ç´¯è®¡æ”¶ç›Šç‡è¯·æŸ¥çœ‹ä¸‹æ–¹ã€‚")
        else:
             st.info(f"å›æµ‹å‘¨æœŸï¼š**{trade_dates[0]}** è‡³ **{trade_dates[-2]}**ã€‚æ­£åœ¨ä»ç¬¬ {start_index+1} å¤©ç»§ç»­...")

        pbar = st.progress(status['progress'], text=f"å›æµ‹è¿›åº¦ï¼š[{status['current_index']}/{status['total_days']}]...")
        
        # 4. å‚æ•°æ‰“åŒ…
        params_dict = {
            'INITIAL_TOP_N': params['INITIAL_TOP_N'], 'FINAL_POOL': params['FINAL_POOL'], 'MIN_PRICE': params['MIN_PRICE'], 
            'MAX_PRICE': params['MAX_PRICE'], 'MIN_TURNOVER': params['MIN_TURNOVER'], 'MIN_AMOUNT': params['MIN_AMOUNT'], 
            'VOL_SPIKE_MULT': params['VOL_SPIKE_MULT'], 'VOLATILITY_MAX': params['VOLATILITY_MAX'], 
            'HIGH_PCT_THRESHOLD': params['HIGH_PCT_THRESHOLD']
        }
        
        for i in range(start_index, total_iterations):
            select_date = trade_dates[i]
            next_trade_date = trade_dates[i+1]
            
            # æ ¸å¿ƒæ­¥éª¤ï¼šè°ƒç”¨ V9.8 è¯„åˆ†å‡½æ•°ï¼Œæ— éœ€ä¼ å…¥ bulk_data
            select_df_full = run_scoring_for_date(select_date, params_dict) 

            # T+1 æ”¶ç›Šè®¡ç®—é€»è¾‘ (ä¸å˜)
            return_pct = 0.0
            buy_price, sell_price = np.nan, np.nan

            if select_df_full.empty:
                result = {'é€‰è‚¡æ—¥': select_date, 'è‚¡ç¥¨': 'æ— ç¬¦åˆæ¡ä»¶', 'T+1 æ”¶ç›Šç‡': 0.0, 'ä¹°å…¥ä»· (T+1 å¼€ç›˜)': np.nan, 'å–å‡ºä»· (T+1 æ”¶ç›˜)': np.nan, 'è¯„åˆ†': np.nan}
            else:
                top_pick = select_df_full.iloc[0] 
                ts_code = top_pick['ts_code']
                
                next_day_data = safe_get(pro.daily, ts_code=ts_code, trade_date=next_trade_date)
                

                if not next_day_data.empty and 'open' in next_day_data.columns and 'close' in next_day_data.columns:
                    buy_price = next_day_data.iloc[0]['open']
                    sell_price = next_day_data.iloc[0]['close']
                    
                    if buy_price > 0 and not pd.isna(sell_price):
                        return_pct = (sell_price / buy_price) - 1.0

                result = {
                    'é€‰è‚¡æ—¥': select_date,
                    'è‚¡ç¥¨': f"{top_pick.get('name', 'N/A')}({ts_code})",
                    'T+1 æ”¶ç›Šç‡': return_pct * 100,
                    'ä¹°å…¥ä»· (T+1 å¼€ç›˜)': buy_price,
                    'å–å‡ºä»· (T+1 æ”¶ç›˜)': sell_price,
                    'è¯„åˆ†': top_pick['ç»¼åˆè¯„åˆ†']
                }

            # 5. æ›´æ–°çŠ¶æ€å’Œè¿›åº¦æ¡
            status['results'].append(result)
            status['current_index'] = i + 1
            status['progress'] = (i + 1) / total_iterations
            
            pbar.progress(status['progress'], text=f"æ­£åœ¨å›æµ‹ {select_date}... [{i+1}/{total_iterations}]")
            
            if (i+1) % 2 == 0: 
                 st.rerun() 
        
        status['progress'] = 1.0
        status['current_index'] = total_iterations
        pbar.progress(1.0, text="å›æµ‹å®Œæˆã€‚")
        
        # 6. ç»“æœå±•ç¤º (ä¸å˜)
        results_df = pd.DataFrame(status['results'])
        
        if results_df.empty:
            st.warning("å›æµ‹ç»“æœä¸ºç©ºã€‚")
            return
            
        results_df['T+1 æ”¶ç›Šç‡'] = results_df['T+1 æ”¶ç›Šç‡'].replace([np.inf, -np.inf], 0.0).fillna(0.0)
        cumulative_return = (results_df['T+1 æ”¶ç›Šç‡'] / 100 + 1).product() - 1
        wins = (results_df['T+1 æ”¶ç›Šç‡'] > 0).sum()
        total_trades = len(results_df)
        win_rate = wins / total_trades if total_trades > 0 else 0

        st.markdown("---")
        st.subheader("ğŸ’¡ æœ€ç»ˆå›æµ‹æŒ‡æ ‡")
        colA, colB, colC = st.columns(3)
        colA.metric("ç´¯è®¡æ”¶ç›Šç‡ (T+1)", f"{cumulative_return*100:.2f}%")
        colB.metric("èƒœç‡", f"{win_rate*100:.2f}%")
        colC.metric("äº¤æ˜“æ¬¡æ•°", f"{total_trades}")
        
        st.subheader("ğŸ“‹ æ¯æ—¥äº¤æ˜“è®°å½•")
        st.dataframe(results_df, use_container_width=True)

# ----------------------------------------------------
# å®æ—¶é€‰è‚¡æ¨¡å— (V9.8ï¼šç§»é™¤æ‰¹é‡æ•°æ®ä¾èµ–)
# ----------------------------------------------------
def run_live_selection(last_trade, params):
    st.write(f"æ­£åœ¨è¿è¡Œå®æ—¶é€‰è‚¡ï¼ˆæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}ï¼‰...")
    
    # V9.8: ç§»é™¤é¢„åŠ è½½é€»è¾‘

    # 5. è°ƒç”¨ V9.8 è¯„åˆ†
    params_dict = {
        'INITIAL_TOP_N': params['INITIAL_TOP_N'], 'FINAL_POOL': params['FINAL_POOL'], 'MIN_PRICE': params['MIN_PRICE'], 
        'MAX_PRICE': params['MAX_PRICE'], 'MIN_TURNOVER': params['MIN_TURNOVER'], 'MIN_AMOUNT': params['MIN_AMOUNT'], 
        'VOL_SPIKE_MULT': params['VOL_SPIKE_MULT'], 'VOLATILITY_MAX': params['VOLATILITY_MAX'], 
        'HIGH_PCT_THRESHOLD': params['HIGH_PCT_THRESHOLD']
    }
    # V9.8: åªä¼ å‚æ•°
    fdf_full = run_scoring_for_date(last_trade, params_dict)

    if fdf_full.empty:
        st.error("æ¸…æ´—å’Œè¯„åˆ†åæ²¡æœ‰å€™é€‰ã€‚è¯·å‚è€ƒä¸Šæ–¹çš„è¯Šæ–­ä¿¡æ¯ï¼Œæ£€æŸ¥æ˜¯ Tushare API é—®é¢˜è¿˜æ˜¯è¿‡æ»¤æ¡ä»¶è¿‡äºä¸¥æ ¼ã€‚")
        st.stop()

    fdf = fdf_full.head(params['TOP_DISPLAY']).copy()
    fdf.index = fdf.index + 1

    st.success(f"è¯„åˆ†å®Œæˆï¼šæ€»å€™é€‰ {len(fdf_full)} æ”¯ï¼Œæ˜¾ç¤º Top {min(params['TOP_DISPLAY'], len(fdf))}ã€‚")
    display_cols = ['name','ts_code','ç»¼åˆè¯„åˆ†','pct_chg','vol_ratio','turnover_rate','net_mf','proxy_money','amount','10d_return','macd','k','d','j','rsl','volatility_10']
    for c in display_cols:
        if c not in fdf.columns: fdf[c] = np.nan

    st.dataframe(fdf[display_cols], use_container_width=True)

    out_csv = fdf_full[display_cols].head(200).to_csv(index=True, encoding='utf-8-sig')
    st.download_button("ä¸‹è½½è¯„åˆ†ç»“æœï¼ˆå‰200ï¼‰CSV", data=out_csv, file_name=f"score_result_{last_trade}.csv", mime="text/csv")

    st.markdown("### å°ç»“ä¸æ“ä½œæç¤ºï¼ˆç®€æ´ï¼‰")
    st.markdown("""
- **ã€ç­–ç•¥é£æ ¼ã€‘** æœ¬ç‰ˆæœ¬ä¸º **V9.8 ç¨³å®šå›é€€ç‰ˆ**ï¼ŒåŒæ—¶æ‹¥æœ‰ V9.0 çš„æ•°æ®è·å–ç¨³å®šæ€§ï¼Œä»¥åŠ V9.7 çš„ç­–ç•¥é˜²å¾¡ä¿®æ­£ã€‚
- **ã€é£æ§æç¤ºã€‘** é£æ§æŒ‡æ ‡ï¼ˆæ³¢åŠ¨ç‡ã€æ”¾é‡å€æ•°ç­‰ï¼‰å·²å…¨éƒ¨çº³å…¥**è¯„åˆ†ä½“ç³»**ã€‚
- **ã€é‡è¦çºªå¾‹ã€‘** 9:40 å‰ä¸ä¹° â†’ è§‚å¯Ÿ 9:40-10:05 çš„é‡ä»·èŠ‚å¥ â†’ 10:05 åæ‹©ä¼˜ä»‹å…¥ã€‚
""")


# ----------------------------------------------------
# ä¸»ç¨‹åºæ§åˆ¶é€»è¾‘ (ä¿ç•™)
# ----------------------------------------------------
params = {
    'INITIAL_TOP_N': INITIAL_TOP_N, 'FINAL_POOL': FINAL_POOL, 'TOP_DISPLAY': TOP_DISPLAY,
    'MIN_PRICE': MIN_PRICE, 'MAX_PRICE': MAX_PRICE, 'MIN_TURNOVER': MIN_TURNOVER,
    'MIN_AMOUNT': MIN_AMOUNT, 'VOL_SPIKE_MULT': VOL_SPIKE_MULT, 'VOLATILITY_MAX': VOLATILITY_MAX,
    'HIGH_PCT_THRESHOLD': HIGH_PCT_THRESHOLD
}

if st.session_state.get('run_backtest', False):
    run_simple_backtest(BACKTEST_DAYS, params)
    
elif st.session_state.get('run_selection', False):
    run_live_selection(last_trade, params)
    
else:
    st.info("è¯·ç‚¹å‡»ä¸Šæ–¹çš„æŒ‰é’®å¼€å§‹è¿è¡Œã€‚")
