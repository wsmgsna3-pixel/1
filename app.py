# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V11.0 æœ€ç»ˆå†³æˆ˜ç­–ç•¥ï¼šV9.0 æ¡†æ¶ + å¼ºåŒ– MACD è¶‹åŠ¿å…±æŒ¯ç‰ˆ
æ›´æ–°è¯´æ˜ï¼š
1. ã€**ç­–ç•¥ç²¾è°ƒ V11.0**ã€‘ï¼šæ ¸å¿ƒå˜åŠ¨ï¼š
   - ç›®æ ‡ï¼šä»¥ V9.0 ä¸ºåŸºç¡€ï¼Œç²¾å‡†ä¿®å¤ D+3 å‘¨æœŸä½èƒœç‡é—®é¢˜ã€‚
   - **MACD (w_macd)** ä» 0.10 å¤§å¹…æå‡è‡³ **0.20** (å¼ºåŒ–ä¸­æœŸè¶‹åŠ¿å…±æŒ¯ï¼Œç­›é€‰èƒ½æŒç»­èµ°é«˜ 3-5 å¤©çš„è‚¡ç¥¨)ã€‚
   - **å½“æ—¥æ¶¨å¹… (w_pct)** å’Œ **æ¢æ‰‹ç‡ (w_turn)** ä» 0.15 é™è‡³ **0.10** (ä¸º MACD è…¾å‡ºæƒé‡)ã€‚
   - **èµ„é‡‘æµ (w_mf)**ã€**60æ—¥ä½ç½® (w_position)** å’Œ **æ³¢åŠ¨ç‡ (w_volatility)** æƒé‡ç»´æŒ V9.0 æ°´å¹³ï¼Œä¿æŒæ ¸å¿ƒåŠ¨åŠ›å’Œé˜²å¾¡æ€§ã€‚

   æ–°æƒé‡ç»“æ„ï¼šèµ„é‡‘æµ(0.35) + è¶‹åŠ¿(0.20) + é˜²å¾¡(0.25) + åŠ¨èƒ½(0.20) = 1.00
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import time
warnings.filterwarnings("ignore")

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
[span_0](start_span)st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V11.0 æœ€ç»ˆå†³æˆ˜ç­–ç•¥", layout="wide")[span_0](end_span)
[span_1](start_span)st.title("é€‰è‚¡ç‹ Â· V11.0 æœ€ç»ˆå†³æˆ˜ç­–ç•¥ï¼ˆV9.0 æ¡†æ¶ + å¼ºåŒ– MACD è¶‹åŠ¿å…±æŒ¯ç‰ˆï¼‰")[span_1](end_span)
[span_2](start_span)st.markdown("ğŸ¯ **V11.0 ç­–ç•¥ï¼šåœ¨ $\mathbf{V9.0}$ çš„åŸºç¡€ä¸Šï¼Œå°† $\mathbf{MACD}$ æƒé‡æå‡åˆ° $\mathbf{0.20}$ï¼Œç›®æ ‡æ˜¯å·©å›º $\mathbf{D+1}$ èƒœç‡ï¼Œå¹¶çªç ´ $\mathbf{D+3}$ èƒœç‡åˆ° $\mathbf{50\%}$ã€‚**")[span_2](end_span)

# ---------------------------
# å…¨å±€å˜é‡åˆå§‹åŒ–
# ---------------------------
pro = None

# ---------------------------
# è¾…åŠ©å‡½æ•° (å…³é”®ä¼˜åŒ–ç‚¹ 1ï¼šç§»é™¤ 0.5 ç§’å¼ºåˆ¶ç­‰å¾…)
# ---------------------------
@st.cache_data(ttl=3600*12)
def safe_get(func_name, **kwargs):
    """å®‰å…¨è°ƒç”¨ Tushare APIï¼Œç§»é™¤ 0.5s å¼ºåˆ¶ç­‰å¾…ï¼Œæ”¹ä¸º 0.06s ä»¥ç¬¦åˆ 1000æ¬¡/åˆ†é¢‘æ¬¡"""
    global pro
    if pro is None:
        [span_3](start_span)return pd.DataFrame(columns=['ts_code'])[span_3](end_span)
    func = getattr(pro, func_name)
    try:
        df = func(**kwargs)
        [span_4](start_span)if df is None or (isinstance(df, pd.DataFrame) and df.empty):[span_4](end_span)
            time.sleep(0.06) # 1000æ¬¡/åˆ†é’Ÿ ç›¸å½“äº 0.06ç§’/æ¬¡
            [span_5](start_span)return pd.DataFrame(columns=['ts_code'])[span_5](end_span)
        time.sleep(0.06) # 1000æ¬¡/åˆ†é’Ÿ ç›¸å½“äº 0.06ç§’/æ¬¡
        return df
    except Exception as e:
        time.sleep(0.06) # 1000æ¬¡/åˆ†é’Ÿ ç›¸å½“äº 0.06ç§’/æ¬¡
        return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    """è·å– num_days ä¸ªäº¤æ˜“æ—¥ä½œä¸ºé€‰è‚¡æ—¥"""
    [span_6](start_span)start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 2)).strftime("%Y%m%d")[span_6](end_span)
    [span_7](start_span)cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)[span_7](end_span)
    [span_8](start_span)if cal.empty or 'is_open' not in cal.columns:[span_8](end_span)
        [span_9](start_span)st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œè¯·æ£€æŸ¥ Token æˆ– Tushare æƒé™ã€‚")[span_9](end_span)
        return []
    [span_10](start_span)trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)[span_10](end_span)
    [span_11](start_span)trade_days_df = trade_days_df[trade_days_df['cal_date'] <= end_date_str][span_11](end_span)
    [span_12](start_span)return trade_days_df['cal_date'].head(num_days).tolist()[span_12](end_span)

@st.cache_data(ttl=3600*24)
def get_adj_factor(ts_code, start_date, end_date):
    [span_13](start_span)df = safe_get('adj_factor', ts_code=ts_code, start_date=start_date, end_date=end_date)[span_13](end_span)
    [span_14](start_span)if df.empty or 'adj_factor' not in df.columns: return pd.DataFrame()[span_14](end_span)
    [span_15](start_span)df['adj_factor'] = pd.to_numeric(df['adj_factor'], errors='coerce').fillna(0)[span_15](end_span)
    [span_16](start_span)df = df.set_index('trade_date').sort_index()[span_16](end_span)
    return df['adj_factor']

@st.cache_data(ttl=3600*12)
def get_qfq_data_v4(ts_code, start_date, end_date, adj_factor_series=None):
    """
    è·å–å•ä¸ªè‚¡ç¥¨çš„å‰å¤æƒæ•°æ®ã€‚åœ¨æ‰¹é‡æ¨¡å¼ä¸‹ï¼Œadj_factor_series ä¼šé¢„å…ˆä¼ å…¥ã€‚
    """
    [span_17](start_span)daily_df = safe_get('daily', ts_code=ts_code, start_date=start_date, end_date=end_date)[span_17](end_span)
    [span_18](start_span)if daily_df.empty: return pd.DataFrame()[span_18](end_span)
    [span_19](start_span)daily_df = daily_df.set_index('trade_date').sort_index()[span_19](end_span)
    
    if adj_factor_series is None:
        [span_20](start_span)adj_factor_series = get_adj_factor(ts_code, start_date, end_date)[span_20](end_span)

    [span_21](start_span)if adj_factor_series.empty: return pd.DataFrame()[span_21](end_span)
    
    [span_22](start_span)df = daily_df.merge(adj_factor_series.rename('adj_factor'), left_index=True, right_index=True, how='left')[span_22](end_span)
    [span_23](start_span)df = df.dropna(subset=['adj_factor'])[span_23](end_span)
    [span_24](start_span)if df.empty: return pd.DataFrame()[span_24](end_span)
    
    # ç¡®ä¿ adj_factor åœ¨åˆå¹¶åå­˜åœ¨ä¸”æ˜¯ Series
    if 'adj_factor' not in df.columns: return pd.DataFrame()

    [span_25](start_span)latest_adj_factor = df['adj_factor'].iloc[-1][span_25](end_span)
    [span_26](start_span)for col in ['open', 'high', 'low', 'close', 'pre_close']:[span_26](end_span)
        if col in df.columns:
            [span_27](start_span)if latest_adj_factor > 1e-9:[span_27](end_span)
                [span_28](start_span)df[col + '_qfq'] = df[col] * df['adj_factor'] / latest_adj_factor[span_28](end_span)
            else:
                [span_29](start_span)df[col + '_qfq'] = df[col][span_29](end_span)
    [span_30](start_span)df = df.reset_index().rename(columns={'trade_date': 'trade_date_str'})[span_30](end_span)
    [span_31](start_span)df['trade_date'] = pd.to_datetime(df['trade_date_str'], format='%Y%m%d')[span_31](end_span)
    [span_32](start_span)df = df.sort_values('trade_date').set_index('trade_date_str')[span_32](end_span)
    [span_33](start_span)for col in ['open', 'high', 'low', 'close']:[span_33](end_span)
        [span_34](start_span)df[col] = df[col + '_qfq'][span_34](end_span)
    [span_35](start_span)return df[['open', 'high', 'low', 'close', 'vol']].copy()[span_35](end_span)

# ----------------------------------------------------
# å…³é”®ä¼˜åŒ–ç‚¹ 2.1ï¼šæ‰¹é‡è·å–æ‰€æœ‰å†å²æ•°æ®
# ----------------------------------------------------
def get_bulk_history_and_adj(ts_codes, selection_date):
    """
    æ‰¹é‡è·å–æ‰€æœ‰å€™é€‰è‚¡çš„å†å² (120å¤©) å’Œæœªæ¥ (15å¤©) æ•°æ®ï¼Œ
    å¹¶è·å–å¤æƒå› å­ã€‚

    è¿”å›: {ts_code: {'hist': pd.DataFrame, 'adj_factor': pd.Series}}
    """
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    # å†å²æ•°æ® (120 å¤©)
    start_hist = (d0 - timedelta(days=120 * 2)).strftime("%Y%m%d") # é¢„ç•™æ—¶é—´
    end_hist = selection_date

    # æœªæ¥æ•°æ® (15 å¤©)
    start_future = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_future = (d0 + timedelta(days=15)).strftime("%Y%m%d")

    # 1. æ‰¹é‡è·å–å¤æƒå› å­ (æ•ˆç‡æ›´é«˜)
    # Tushare adj_factor æ¥å£ä¸æ”¯æŒæ‰¹é‡ï¼Œä»éœ€å¾ªç¯è°ƒç”¨
    adj_map = {
        ts_code: get_adj_factor(ts_code, start_hist, end_future)
        for ts_code in ts_codes
    }

    # 2. æ‰¹é‡è·å–å†å²å’Œæœªæ¥è¡Œæƒ…æ•°æ®
    data_map = {}
    for ts_code in ts_codes:
        adj_factor_series = adj_map.get(ts_code)
        
        # è·å–åŒ…å«é€‰è‚¡æ—¥åŠä»¥å‰çš„å†å²æ•°æ®ï¼ˆç”¨äºæŒ‡æ ‡è®¡ç®—ï¼‰
        hist_df = get_qfq_data_v4(ts_code, start_hist, end_hist, adj_factor_series=adj_factor_series)
        
        # è·å–é€‰è‚¡æ—¥ä»¥åçš„æœªæ¥ä»·æ ¼æ•°æ®ï¼ˆç”¨äºå›æµ‹æ”¶ç›Šè®¡ç®—ï¼‰
        future_df = get_qfq_data_v4(ts_code, start_future, end_future, adj_factor_series=adj_factor_series)
        
        data_map[ts_code] = {
            'hist_data': hist_df, # åŒ…å«é€‰è‚¡æ—¥å½“æ—¥æ•°æ®
            'future_data': future_df # é€‰è‚¡æ—¥åç¬¬ä¸€å¤©å¼€å§‹
        }
        
    return data_map

# ----------------------------------------------------
# å…³é”®ä¼˜åŒ–ç‚¹ 2.2ï¼šä½¿ç”¨é¢„åŠ è½½çš„æ•°æ®è®¡ç®—æŒ‡æ ‡
# ----------------------------------------------------
def get_future_prices_optimized(ts_code, selection_date, preloaded_data, days_ahead=[1, 3, 5]):
    """ä½¿ç”¨é¢„åŠ è½½çš„æœªæ¥æ•°æ®è®¡ç®—æ”¶ç›Šç‡"""
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    results = {}
    
    # è·å–é€‰è‚¡å½“æ—¥çš„æ”¶ç›˜ä»·ï¼ˆä½œä¸ºè®¡ç®—æ”¶ç›Šçš„åŸºå‡†ä»·ï¼‰
    # åœ¨ hist_data ä¸­è·å–é€‰è‚¡æ—¥çš„æ”¶ç›˜ä»·
    hist = preloaded_data.get('hist_data', pd.DataFrame())
    future = preloaded_data.get('future_data', pd.DataFrame())

    if hist.empty or 'close' not in hist.columns:
        for n in days_ahead: results[f'Return_D{n}'] = np.nan
        return results
    
    selection_price_adj = hist['close'].iloc[-1]
    
    if future.empty or 'close' not in future.columns:
        for n in days_ahead: results[f'Return_D{n}'] = np.nan
        return results

    [span_36](start_span)future['close'] = pd.to_numeric(future['close'], errors='coerce')[span_36](end_span)
    [span_37](start_span)future = future.dropna(subset=['close'])[span_37](end_span)
    [span_38](start_span)future = future.reset_index(drop=True)[span_38](end_span)

    for n in days_ahead:
        col_name = f'Return_D{n}'
        if len(future) >= n:
            future_price = future.iloc[n-1]['close']
            if pd.notna(selection_price_adj) and selection_price_adj > 1e-9:
                [span_39](start_span)results[col_name] = (future_price / selection_price_adj - 1) * 100[span_39](end_span)
            else:
                [span_40](start_span)results[col_name] = np.nan[span_40](end_span)
        else:
            [span_41](start_span)results[col_name] = np.nan[span_41](end_span)
    return results


def compute_indicators_optimized(ts_code, preloaded_data):
    """ä½¿ç”¨é¢„åŠ è½½çš„å†å²æ•°æ®è®¡ç®— MACD, 60æ—¥ä½ç½®ç­‰æŒ‡æ ‡"""
    df = preloaded_data.get('hist_data', pd.DataFrame())
    res = {}
    [span_42](start_span)if df.empty or len(df) < 3 or 'close' not in df.columns: return res[span_42](end_span)
    
    # ç¡®ä¿åªä½¿ç”¨ 120 å¤©çš„æ•°æ®è¿›è¡ŒæŒ‡æ ‡è®¡ç®—
    df = df.tail(120)

    [span_43](start_span)df['close'] = pd.to_numeric(df['close'], errors='coerce').astype(float)[span_43](end_span)
    [span_44](start_span)df['low'] = pd.to_numeric(df['low'], errors='coerce').astype(float)[span_44](end_span)
    [span_45](start_span)df['high'] = pd.to_numeric(df['high'], errors='coerce').astype(float)[span_45](end_span)
    [span_46](start_span)df['vol'] = pd.to_numeric(df['vol'], errors='coerce').fillna(0)[span_46](end_span)
    [span_47](start_span)df['pct_chg'] = df['close'].pct_change().fillna(0) * 100[span_47](end_span)
    close = df['close']
    [span_48](start_span)res['last_close'] = close.iloc[-1][span_48](end_span)
    
    # MACD è®¡ç®—
    if len(close) >= 26:
        [span_49](start_span)ema12 = close.ewm(span=12, adjust=False).mean()[span_49](end_span)
        [span_50](start_span)ema26 = close.ewm(span=26, adjust=False).mean()[span_50](end_span)
        [span_51](start_span)diff = ema12 - ema26[span_51](end_span)
        [span_52](start_span)dea = diff.ewm(span=9, adjust=False).mean()[span_52](end_span)
        [span_53](start_span)res['macd_val'] = ((diff - dea) * 2).iloc[-1][span_53](end_span)
    [span_54](start_span)else: res['macd_val'] = np.nan[span_54](end_span)
        
    # é‡æ¯”è®¡ç®—
    vols = df['vol'].tolist()
    if len(vols) >= 6 and vols[-6:-1] and np.mean(vols[-6:-1]) > 1e-9:
        [span_55](start_span)res['vol_ratio'] = vols[-1] / np.mean(vols[-6:-1])[span_55](end_span)
    [span_56](start_span)else: res['vol_ratio'] = np.nan[span_56](end_span)
        
    # 10æ—¥å›æŠ¥ã€æ³¢åŠ¨ç‡è®¡ç®—
    [span_57](start_span)res['10d_return'] = close.iloc[-1]/close.iloc[-10] - 1 if len(close)>=10 and close.iloc[-10]!=0 else 0[span_57](end_span)
    [span_58](start_span)res['volatility'] = df['pct_chg'].tail(10).std() if len(df)>=10 else 0[span_58](end_span)
    
    # 60æ—¥ä½ç½®è®¡ç®—
    [span_59](start_span)if len(df) >= 60:[span_59](end_span)
        [span_60](start_span)hist_60 = df.tail(60)[span_60](end_span)
        [span_61](start_span)min_low = hist_60['low'].min()[span_61](end_span)
        [span_62](start_span)max_high = hist_60['high'].max()[span_62](end_span)
        [span_63](start_span)current_close = hist_60['close'].iloc[-1][span_63](end_span)
        
        [span_64](start_span)if max_high == min_low: res['position_60d'] = 50.0[span_64](end_span)
        [span_65](start_span)else: res['position_60d'] = (current_close - min_low) / (max_high - min_low) * 100[span_65](end_span)
    [span_66](start_span)else: res['position_60d'] = np.nan[span_66](end_span)
    
    return res

# ----------------------------------------------------


# ----------------------------------------------------
# ä¾§è¾¹æ å‚æ•° (å®šä¹‰ BACKTEST_DAYS ç­‰å˜é‡)
# ----------------------------------------------------
with st.sidebar:
    st.header("æ¨¡å¼ä¸æ—¥æœŸé€‰æ‹©")
    [span_67](start_span)backtest_date_end = st.date_input("é€‰æ‹©**å›æµ‹ç»“æŸæ—¥æœŸ**", value=datetime.now().date(), max_value=datetime.now().date())[span_67](end_span)
    [span_68](start_span)BACKTEST_DAYS = int(st.number_input("**è‡ªåŠ¨å›æµ‹å¤©æ•° (N)**", value=20, step=1, min_value=1, max_value=50, help="ç¨‹åºå°†è‡ªåŠ¨å›æµ‹æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥ã€‚å»ºè®®è®¾ç½®ä¸º 20 å¤©ä»¥è·å¾—æ›´å¯é çš„ç»Ÿè®¡æ•°æ®ã€‚"))[span_68](end_span)
    
    st.markdown("---")
    st.header("æ ¸å¿ƒå‚æ•°")
    [span_69](start_span)FINAL_POOL = int(st.number_input("æœ€ç»ˆå…¥å›´è¯„åˆ†æ•°é‡ (M)", value=10, step=1, min_value=1))[span_69](end_span)
    [span_70](start_span)TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=10, step=1))[span_70](end_span)
    [span_71](start_span)TOP_BACKTEST = int(st.number_input("å›æµ‹åˆ†æ Top K", value=3, step=1, min_value=1))[span_71](end_span)
    
    st.markdown("---")
    st.header("ğŸ›’ çµæ´»è¿‡æ»¤æ¡ä»¶")
    [span_72](start_span)MIN_PRICE = st.number_input("æœ€ä½è‚¡ä»· (å…ƒ)", value=10.0, step=0.5, min_value=0.1)[span_72](end_span)
    [span_73](start_span)MAX_PRICE = st.number_input("æœ€é«˜è‚¡ä»· (å…ƒ)", value=300.0, step=5.0, min_value=1.0)[span_73](end_span)
    [span_74](start_span)MIN_TURNOVER = st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=2.0, step=0.5, min_value=0.1)[span_74](end_span)
    [span_75](start_span)MIN_CIRC_MV_BILLIONS = st.number_input("æœ€ä½æµé€šå¸‚å€¼ (äº¿å…ƒ)", value=20.0, step=1.0, min_value=1.0, help="ä¾‹å¦‚ï¼šè¾“å…¥ 20 ä»£è¡¨æµé€šå¸‚å€¼å¿…é¡»å¤§äºç­‰äº 20 äº¿å…ƒã€‚")[span_75](end_span)
    [span_76](start_span)MIN_AMOUNT_MILLIONS = st.number_input("æœ€ä½æˆäº¤é¢ (äº¿å…ƒ)", value=0.6, step=0.1, min_value=0.1)[span_76](end_span)
    [span_77](start_span)MIN_AMOUNT = MIN_AMOUNT_MILLIONS * 100000000[span_77](end_span)

# ---------------------------
# Token è¾“å…¥ä¸åˆå§‹åŒ–
# ---------------------------
[span_78](start_span)TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")[span_78](end_span)
if not TS_TOKEN:
    [span_79](start_span)st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")[span_79](end_span)
    st.stop()
[span_80](start_span)ts.set_token(TS_TOKEN)[span_80](end_span)
[span_81](start_span)pro = ts.pro_api()[span_81](end_span)

# ---------------------------
# æ ¸å¿ƒå›æµ‹é€»è¾‘å‡½æ•°
# ---------------------------
def run_backtest_for_a_day(last_trade, TOP_BACKTEST, FINAL_POOL, MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, MIN_CIRC_MV_BILLIONS):
    """ä¸ºå•ä¸ªäº¤æ˜“æ—¥è¿è¡Œé€‰è‚¡å’Œå›æµ‹é€»è¾‘"""
    
    # 1. æ‹‰å–å…¨å¸‚åœº Daily æ•°æ® (çœç•¥åˆå¹¶å’Œè¿‡æ»¤çš„é‡å¤ä»£ç )
    [span_82](start_span)daily_all = safe_get('daily', trade_date=last_trade)[span_82](end_span)
    [span_83](start_span)if daily_all.empty or 'ts_code' not in daily_all.columns: return pd.DataFrame(), f"æ•°æ®ç¼ºå¤±æˆ–æ‹‰å–å¤±è´¥ï¼š{last_trade}"[span_83](end_span)

    [span_84](start_span)pool_raw = daily_all.reset_index(drop=True)[span_84](end_span)
    [span_85](start_span)stock_basic = safe_get('stock_basic', list_status='L', fields='ts_code,name,list_date')[span_85](end_span)
    [span_86](start_span)REQUIRED_BASIC_COLS = ['ts_code','turnover_rate','amount','total_mv','circ_mv'][span_86](end_span)
    [span_87](start_span)daily_basic = safe_get('daily_basic', trade_date=last_trade, fields=','.join(REQUIRED_BASIC_COLS))[span_87](end_span)
    [span_88](start_span)mf_raw = safe_get('moneyflow', trade_date=last_trade)[span_88](end_span)
    pool_merged = pool_raw.copy()

    [span_89](start_span)if not stock_basic.empty and 'name' in stock_basic.columns:[span_89](end_span)
        [span_90](start_span)pool_merged = pool_merged.merge(stock_basic[['ts_code','name','list_date']], on='ts_code', how='left')[span_90](end_span)
    else:
        [span_91](start_span)pool_merged['name'] = pool_merged['ts_code'][span_91](end_span)
        [span_92](start_span)pool_merged['list_date'] = '20000101'[span_92](end_span)
        
    if not daily_basic.empty:
        [span_93](start_span)cols_to_merge = [c for c in REQUIRED_BASIC_COLS if c in daily_basic.columns][span_93](end_span)
        [span_94](start_span)if 'amount' in pool_merged.columns and 'amount' in cols_to_merge:[span_94](end_span)
            [span_95](start_span)pool_merged = pool_merged.drop(columns=['amount'])[span_95](end_span)
        [span_96](start_span)pool_merged = pool_merged.merge(daily_basic[cols_to_merge], on='ts_code', how='left')[span_96](end_span)
    
    [span_97](start_span)moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])[span_97](end_span)
    if not mf_raw.empty:
        [span_98](start_span)possible = ['net_mf','net_mf_amount','net_mf_in'][span_98](end_span)
        for c in possible:
            if c in mf_raw.columns:
                [span_99](start_span)moneyflow = mf_raw[['ts_code', c]].rename(columns={c:'net_mf'}).fillna(0)[span_99](end_span)
                break            
    if not moneyflow.empty:
        [span_100](start_span)pool_merged = pool_merged.merge(moneyflow, on='ts_code', how='left')[span_100](end_span)
        
    [span_101](start_span)pool_merged['net_mf'] = pool_merged['net_mf'].fillna(0)[span_101](end_span)
    [span_102](start_span)pool_merged['turnover_rate'] = pool_merged['turnover_rate'].fillna(0)[span_102](end_span)
   
    # 3. æ‰§è¡Œç¡¬æ€§æ¡ä»¶è¿‡æ»¤
    [span_103](start_span)df = pool_merged.copy()[span_103](end_span)
    [span_104](start_span)df['close'] = pd.to_numeric(df['close'], errors='coerce')[span_104](end_span)
    [span_105](start_span)df['turnover_rate'] = pd.to_numeric(df['turnover_rate'], errors='coerce').fillna(0)[span_105](end_span)
    [span_106](start_span)df['amount'] = pd.to_numeric(df['amount'], errors='coerce').fillna(0) * 1000 # è½¬æ¢ä¸ºä¸‡å…ƒ[span_106](end_span)
    [span_107](start_span)df['circ_mv_billion'] = pd.to_numeric(df['circ_mv'], errors='coerce').fillna(0) / 10000[span_107](end_span)
    [span_108](start_span)df['name'] = df['name'].astype(str)[span_108](end_span)
    
    # è¿‡æ»¤ ST è‚¡/é€€å¸‚è‚¡/åŒ—äº¤æ‰€/æ¬¡æ–°è‚¡
    [span_109](start_span)mask_st = df['name'].str.contains('ST|é€€', case=False, na=False)[span_109](end_span)
    [span_110](start_span)df = df[~mask_st][span_110](end_span)
    [span_111](start_span)mask_bj = df['ts_code'].str.startswith('92')[span_111](end_span)
    [span_112](start_span)df = df[~mask_bj][span_112](end_span)
    [span_113](start_span)TODAY = datetime.strptime(last_trade, "%Y%m%d")[span_113](end_span)
    [span_114](start_span)MIN_LIST_DAYS = 120[span_114](end_span)
    [span_115](start_span)df['list_date_dt'] = pd.to_datetime(df['list_date'], format='%Y%m%d', errors='coerce')[span_115](end_span)
    [span_116](start_span)df['days_listed'] = (TODAY - df['list_date_dt']).dt.days[span_116](end_span)
    [span_117](start_span)mask_cyb_kcb = df['ts_code'].str.startswith(('30','68'))[span_117](end_span)
    [span_118](start_span)mask_new = df['days_listed'] < MIN_LIST_DAYS[span_118](end_span)
    [span_119](start_span)df = df[~((mask_cyb_kcb) & (mask_new))][span_119](end_span)

    # è¿‡æ»¤ä»·æ ¼
    [span_120](start_span)mask_price = (df['close'] >= MIN_PRICE) & (df['close'] <= MAX_PRICE)[span_120](end_span)
    [span_121](start_span)df = df[mask_price][span_121](end_span)
    # è¿‡æ»¤æµé€šå¸‚å€¼
    [span_122](start_span)mask_circ_mv = df['circ_mv_billion'] >= MIN_CIRC_MV_BILLIONS[span_122](end_span)
    [span_123](start_span)df = df[mask_circ_mv][span_123](end_span)
    # è¿‡æ»¤æ¢æ‰‹ç‡
    [span_124](start_span)mask_turn = df['turnover_rate'] >= MIN_TURNOVER[span_124](end_span)
    [span_125](start_span)df = df[mask_turn][span_125](end_span)
    # è¿‡æ»¤æˆäº¤é¢
    [span_126](start_span)mask_amt = df['amount'] * 1000 >= MIN_AMOUNT[span_126](end_span)
    [span_127](start_span)df = df[mask_amt][span_127](end_span)
    
    [span_128](start_span)df = df.reset_index(drop=True)[span_128](end_span)

    if len(df) == 0: return pd.DataFrame(), f"è¿‡æ»¤åæ— è‚¡ç¥¨ï¼š{last_trade}"

    # 4. é´é€‰å†³èµ›åå• (åŸºäºå½“æ—¥æ¶¨å¹…å’Œæ¢æ‰‹ç‡çš„æ··åˆåˆç­›)
    limit_pct = int(FINAL_POOL * 0.7)
    df_pct = df.sort_values('pct_chg', ascending=False).head(limit_pct).copy()
    limit_turn = FINAL_POOL - len(df_pct)
    existing_codes = set(df_pct['ts_code'])
    df_turn = df[~df['ts_code'].isin(existing_codes)].sort_values('turnover_rate', ascending=False).head(limit_turn).copy()
    [span_129](start_span)final_candidates = pd.concat([df_pct, df_turn]).reset_index(drop=True)[span_129](end_span)
    
    # =================================================================================
    # ğŸš¨ å…³é”®ä¼˜åŒ–ç‚¹ 2.3ï¼šæ‰¹é‡è·å–å†å²æ•°æ®å’Œæœªæ¥æ”¶ç›Šæ•°æ®ï¼Œä»£æ›¿å¾ªç¯å†…çš„ API è°ƒç”¨
    # =================================================================================
    final_ts_codes = final_candidates['ts_code'].tolist()
    preloaded_data_map = get_bulk_history_and_adj(final_ts_codes, last_trade)
 
    # 5. æ·±åº¦è¯„åˆ† (ä½¿ç”¨é¢„åŠ è½½çš„æ•°æ®)
    records = []
    for row in final_candidates.itertuples():
        ts_code = row.ts_code
        preloaded_data = preloaded_data_map.get(ts_code, {})
        
        rec = {
            'ts_code': ts_code, 'name': getattr(row, 'name', ts_code),
            'Close': getattr(row, 'close', np.nan),
            'Circ_MV (äº¿)': getattr(row, 'circ_mv_billion', np.nan),
            [span_130](start_span)'Pct_Chg (%)': getattr(row, 'pct_chg', 0),[span_130](end_span)
            'turnover': getattr(row, 'turnover_rate', 0),
            'net_mf': getattr(row, 'net_mf', 0)
        }
        
        # ä½¿ç”¨ä¼˜åŒ–åçš„å‡½æ•°ï¼Œä¸å†å‘èµ· API è°ƒç”¨
        ind = compute_indicators_optimized(ts_code, preloaded_data)
        rec.update({
            'vol_ratio': ind.get('vol_ratio', 0), 'macd': ind.get('macd_val', 0),
            [span_131](start_span)'10d_return': ind.get('10d_return', 0),[span_131](end_span)
            'volatility': ind.get('volatility', 0), 'position_60d': ind.get('position_60d', np.nan)
        })
        
        # ä½¿ç”¨ä¼˜åŒ–åçš„å‡½æ•°ï¼Œä¸å†å‘èµ· API è°ƒç”¨
        future_returns = get_future_prices_optimized(ts_code, last_trade, preloaded_data)
        rec.update({
            'Return_D1 (%)': future_returns.get('Return_D1', np.nan),
            [span_132](start_span)'Return_D3 (%)': future_returns.get('Return_D3', np.nan),[span_132](end_span)
            'Return_D5 (%)': future_returns.get('Return_D5', np.nan),
        })

        records.append(rec)
    
    [span_133](start_span)fdf = pd.DataFrame(records)[span_133](end_span)
    [span_134](start_span)if fdf.empty: return pd.DataFrame(), f"è¯„åˆ†åˆ—è¡¨ä¸ºç©ºï¼š{last_trade}"[span_134](end_span)

    # 6. å½’ä¸€åŒ–ä¸ V11.0 ç­–ç•¥ç²¾è°ƒè¯„åˆ†
    def normalize(series):
        [span_135](start_span)series_nn = series.dropna()[span_135](end_span)
        [span_136](start_span)if series_nn.max() == series_nn.min(): return pd.Series([0.5] * len(series), index=series.index)[span_136](end_span)
        [span_137](start_span)return (series - series_nn.min()) / (series_nn.max() - series_nn.min() + 1e-9)[span_137](end_span)

    [span_138](start_span)fdf['s_pct'] = normalize(fdf['Pct_Chg (%)'])[span_138](end_span)
    [span_139](start_span)fdf['s_turn'] = normalize(fdf['turnover'])[span_139](end_span)
    [span_140](start_span)fdf['s_vol'] = normalize(fdf['vol_ratio'])[span_140](end_span)
    [span_141](start_span)fdf['s_mf'] = normalize(fdf['net_mf'])[span_141](end_span)
    [span_142](start_span)fdf['s_macd'] = normalize(fdf['macd'])[span_142](end_span)
    [span_143](start_span)fdf['s_trend'] = normalize(fdf['10d_return'])[span_143](end_span)
    [span_144](start_span)fdf['s_volatility'] = normalize(fdf['volatility'])[span_144](end_span)
    [span_145](start_span)fdf['s_position'] = fdf['position_60d'] / 100[span_145](end_span)
    
    # ----------------------------------------------------------------------------------
    # ğŸš¨ V11.0 æœ€ç»ˆå†³æˆ˜ç­–ç•¥ï¼šV9.0 æ¡†æ¶ + å¼ºåŒ– MACD è¶‹åŠ¿å…±æŒ¯ç‰ˆ
    
    # æ ¸å¿ƒæƒé‡ï¼šèµ„é‡‘æµï¼Œå æ¯” 35%
    [span_146](start_span)w_mf = 0.35[span_146](end_span) # 35% - èµ„é‡‘æµ (æ ¸å¿ƒåŠ¨åŠ›ï¼Œä¿æŒ V9.0)

    # åŠ¨èƒ½æƒé‡ï¼šå½“æ—¥åŠ¨èƒ½ï¼Œå æ¯” 20%
    [span_147](start_span)w_pct = 0.10[span_147](end_span) # 10% - å½“æ—¥æ¶¨å¹… (å‰Šå¼±)
    [span_148](start_span)w_turn = 0.10[span_148](end_span) # 10% - æ¢æ‰‹ç‡ (å‰Šå¼±)
    
    # é˜²å¾¡æƒé‡ï¼šå®‰å…¨è¾¹é™…ä¸æ³¢åŠ¨æ§åˆ¶ï¼Œå æ¯” 25%
    [span_149](start_span)w_position = 0.15[span_149](end_span) # 15% - 60æ—¥ä½ç½® (ä¿æŒ V9.0)
    [span_150](start_span)w_volatility = 0.10[span_150](end_span) # 10% - æ³¢åŠ¨ç‡ (ä¿æŒ V9.0)
 
    # è¶‹åŠ¿æƒé‡ï¼šä¸­æœŸè¶‹åŠ¿ï¼Œå æ¯” 20%
    [span_151](start_span)w_macd = 0.20[span_151](end_span) # 20% - MACD (**å¤§å¹…å¼ºåŒ–ï¼Œç›®æ ‡æ”¹å–„ D+3**)
    
    # å½»åº•å½’é›¶é¡¹
    [span_152](start_span)w_vol = 0.00[span_152](end_span) # 0% - é‡æ¯”
    [span_153](start_span)w_trend = 0.00[span_153](end_span) # 0% - 10æ—¥å›æŠ¥
    
    # Sum: 0.35+0.10+0.10+0.15+0.10+0.20 = 1.00
    
    score = (
        [span_154](start_span)fdf['s_pct'] * w_pct + fdf['s_turn'] * w_turn +[span_154](end_span)
        [span_155](start_span)fdf['s_mf'] * w_mf +[span_155](end_span)
        [span_156](start_span)fdf['s_macd'] * w_macd +[span_156](end_span)
        
        # å¼•å…¥é˜²å¾¡ï¼š60æ—¥ä½ç½®è¶Šä½è¶Šå¥½ (1-s_position)ï¼Œæ³¢åŠ¨ç‡è¶Šä½è¶Šå¥½ (1-s_volatility)
        (1 - fdf['s_position']) * [span_157](start_span)w_position +[span_157](end_span)
        (1 - fdf['s_volatility']) * [span_158](start_span)w_volatility +[span_158](end_span)
        
        # å½’é›¶é¡¹
        [span_159](start_span)fdf['s_vol'] * w_vol +[span_159](end_span)
        fdf['s_trend'] * w_trend     
    )
    [span_160](start_span)fdf['ç»¼åˆè¯„åˆ†'] = score * 100[span_160](end_span)
    [span_161](start_span)fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)[span_161](end_span)
    [span_162](start_span)fdf.index += 1[span_162](end_span)
    # ----------------------------------------------------------------------------------


    return fdf.head(TOP_BACKTEST).copy(), None

# ---------------------------
# ä¸»è¿è¡Œå— (ä¿æŒä¸å˜)
# ---------------------------
if st.button(f"ğŸš€ å¼€å§‹ {BACKTEST_DAYS} æ—¥è‡ªåŠ¨å›æµ‹"):
    
    [span_163](start_span)st.warning("âš ï¸ **V11.0 ç‰ˆæœ¬å·²æ›´æ¢ä¸º V9.0 æ¡†æ¶ + å¼ºåŒ– MACD è¶‹åŠ¿å…±æŒ¯ç­–ç•¥ï¼Œç›®æ ‡æ˜¯çªç ´ D+3 èƒœç‡ã€‚**")[span_163](end_span)
   
    [span_164](start_span)trade_days_str = get_trade_days(backtest_date_end.strftime("%Y%m%d"), BACKTEST_DAYS)[span_164](end_span)
    if not trade_days_str:
        [span_165](start_span)st.error("æ— æ³•è·å–äº¤æ˜“æ—¥åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥æ—¥æœŸæˆ– Tokenã€‚")[span_165](end_span)
        st.stop()
    
    [span_166](start_span)st.header(f"ğŸ“ˆ æ­£åœ¨è¿›è¡Œ {BACKTEST_DAYS} ä¸ªäº¤æ˜“æ—¥çš„å›æµ‹...")[span_166](end_span)
    
    results_list = []
    total_days = len(trade_days_str)
    
    [span_167](start_span)progress_text = st.empty()[span_167](end_span)
    [span_168](start_span)my_bar = st.progress(0)[span_168](end_span)
    
    for i, trade_date in enumerate(trade_days_str):
        [span_169](start_span)progress_text.text(f"ğŸš€ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{total_days} ä¸ªäº¤æ˜“æ—¥ï¼š{trade_date}")[span_169](end_span)
      
        daily_result_df, error = run_backtest_for_a_day(
            trade_date, TOP_BACKTEST, FINAL_POOL, MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, MIN_CIRC_MV_BILLIONS
        [span_170](start_span))
        
        if error:
            st.warning(f"è·³è¿‡ {trade_date}ï¼š{error}")[span_170](end_span)
        elif not daily_result_df.empty:
            [span_171](start_span)daily_result_df['Trade_Date'] = trade_date[span_171](end_span)
            [span_172](start_span)results_list.append(daily_result_df)[span_172](end_span)
            
        [span_173](start_span)my_bar.progress((i + 1) / total_days)[span_173](end_span)

    [span_174](start_span)progress_text.text("âœ… å›æµ‹å®Œæˆï¼Œæ­£åœ¨æ±‡æ€»ç»“æœ...")[span_174](end_span)
    [span_175](start_span)my_bar.empty()[span_175](end_span)
    
    if not results_list:
        [span_176](start_span)st.error("æ‰€æœ‰äº¤æ˜“æ—¥çš„å›æµ‹å‡å¤±è´¥æˆ–æ— ç»“æœã€‚")[span_176](end_span)
        st.stop()
        
    [span_177](start_span)all_results = pd.concat(results_list)[span_177](end_span)
    
    [span_178](start_span)st.header(f"ğŸ“Š æœ€ç»ˆå¹³å‡å›æµ‹ç»“æœ (Top {TOP_BACKTEST}ï¼Œå…± {total_days} ä¸ªäº¤æ˜“æ—¥)")[span_178](end_span)
    
    [span_179](start_span)for n in [1, 3, 5]:[span_179](end_span)
        [span_180](start_span)col = f'Return_D{n} (%)'[span_180](end_span)
        
        [span_181](start_span)filtered_returns = all_results.copy()[span_181](end_span)
        [span_182](start_span)valid_returns = filtered_returns.dropna(subset=[col])[span_182](end_span)

        if not valid_returns.empty:
            [span_183](start_span)avg_return = valid_returns[col].mean()[span_183](end_span)
            [span_184](start_span)hit_rate = (valid_returns[col] > 0).sum() / len(valid_returns) * 100 if len(valid_returns) > 0 else 0.0[span_184](end_span)
            [span_185](start_span)total_count = len(valid_returns)[span_185](end_span)
        else:
            [span_186](start_span)avg_return = np.nan[span_186](end_span)
            [span_187](start_span)hit_rate = 0.0[span_187](end_span)
            [span_188](start_span)total_count = 0[span_188](end_span)
            
        st.metric(f"Top {TOP_BACKTEST}ï¼šD+{n} å¹³å‡æ”¶ç›Š / å‡†ç¡®ç‡", 
            [span_189](start_span)f"{avg_return:.2f}% / {hit_rate:.1f}%",[span_189](end_span)
            [span_190](start_span)help=f"æ€»æœ‰æ•ˆæ ·æœ¬æ•°ï¼š{total_count}ã€‚**V11.0 å·²åº”ç”¨ V9.0 æ¡†æ¶ + å¼ºåŒ– MACD è¶‹åŠ¿å…±æŒ¯ç­–ç•¥ã€‚**")[span_190](end_span)

    [span_191](start_span)st.header("ğŸ“‹ æ¯æ—¥å›æµ‹è¯¦æƒ… (Top K æ˜ç»†)")[span_191](end_span)
    
    display_cols = ['Trade_Date', 'name', 'ts_code', 'ç»¼åˆè¯„åˆ†', 
                    'Close', 'Pct_Chg (%)', 'Circ_MV (äº¿)',
                    [span_192](start_span)'Return_D1 (%)', 'Return_D3 (%)', 'Return_D5 (%)'][span_192](end_span)
    
    st.dataframe(all_results[display_cols].sort_values('Trade_Date', ascending=False), use_container_width=True)
